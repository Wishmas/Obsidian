# Матрицы
## Линейная независимость
Систему векторов называют **линейно зависимой**, если хотя бы один из её векторов линейно выражается через все остальные.

Если ни один вектор системы не является линейной комбинацией остальных векторов, то систему называют **линейно независимой**.

Из векторов линейно зависимой можно составить `нетривиальную комбинацию`, равную 0. Если система линейно независима, то составить такую комбинацию не получится.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013163401.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013164255.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013164328.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013171858.png)<br>
Так, если в двухмерном пространстве есть система из 3 векторов, но она всегда линейно независима, поскольку третий вектор всегда можно представить как линейную комбинацию двух других:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013172057.png)<br>
Итак, проверить линейную (не)зависимость системы можно одним из способов:
- через пропорциональность координат векторов;
- через количество векторов в системе;
- через сумму векторов.
## Базис

Зная одну линейно независимую систему векторов, можно создать бесконечное количество других систем. Векторы можно заменять на другие, коллинеарные им, так что линейна (не)зависимость при этом не нарушится.

Введем несколько определений:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013180309.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013180435.png)<br>
Любой вектор можно **преобразовать в единичный**. Для этого нужно просто **разделить вектор на его длину**:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013180812.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013181120.png)<br>
Нормирование векторов влияет только на их длину, при этом линейная (не)зависимость системы векторов сохраняется.

Число, соответствующее **максимальному количеству линейно независимых векторов в пространстве**, называют **размерностью векторного пространства**. Это число совпадает с количеством координат вектора.

Если система векторов линейно независима и любой вектор линейного пространства L линейно выражается через векторы этой системы, то такая система - **базис этого линейного пространства**

Или:

**Базис векторного пространства** — система линейно независимых векторов, число векторов в которой равно размерности векторного пространства. Векторы этой системы называют **базисными**.

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013184056.png)<br>
Базис из ортогональных единичных векторов называют **ортонормированным**. Обычно векторы $\overline i$, $\overline j$ используют именно для обозначения ортонормированных базисов.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241013184353.png)<br>
Коэффициенты разложения $k_1$,$k_2$ являются **координатами вектора** в данном базисе.<br>
Именно эти коэффициенты и перечисляют в скобках через запятую, когда записывают координаты вектора.<br>
Запись выше называется **разложением вектора** $\overline a$ по базису {$\overline i$,$\overline j$}.

Базис существует в любом конечномерном пространстве, и любое такое пространство имеет бесконечное количество разных базисов.

Базисные векторы могу и иметь разную длину или не быть ортогональными. Важно только, чтобы их **количество соответствовало размерности линейного пространства**, а также, чтобы все они были **линейно независимы**.

## Понятие матрицы

**Матрица** — это прямоугольная таблица чисел (**элементов матрицы**).<br>
В общем виде матрица записывается так:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241015215735.png)<br>
Каждый элемент матрицы обозначают двумя числами: **первое** — **номер строки**, в которой он расположен, **второе** — **номер столбца**.

**Вектор-строка** — это матрица, в которой 1 строка и n столбцов, то есть матрица размера 1×n.<br>
**Вектор-столбец** — это матрица, в которой 1 столбец и n строк. Её размер — n×1.

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241015220127.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241015220151.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241015220213.png)<br>
Главная и побочная диагонали есть только у квадратных матриц!

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241015220233.png)

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241015221011.png)<br>
**Элементарные преобразования:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241015221105.png)<br>
К элементарным преобразованиям относятся:
- Умножение строки на ненулевое число;
- Перестановка двух строк;
- Прибавление к одной строке матрицы другой её строки.<br>
При помощи элементарных преобразований любую матрицу можно превратить в **трапециевидную**:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241015222759.png)

**Транспонирование матрицы:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241015223035.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241015223039.png)

**Умножение матрицы на скаляр:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017204451.png)<br>
**Сложение матриц:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017204534.png)<br>
Складывать можно только матрицы одного размера.

**Нулевая матрица** — это матрица, все элементы которой равны нулю. Её обозначают буквой O.

В операциях с участием нескольких матриц должен соблюдаться следующий **порядок действий:**
1. Транспонирование.
2. Умножение на скаляр.
3. Сложение матриц.

**Умножение вектора-строки на матрицу:**<br>
Умножение вектора на матрицу даёт новый вектор. Он состоит из скалярных произведений этого вектора со столбцами матрицы.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017214401.png)<br>
В полученном произведении будет столько же строк, сколько в векторе, и столько же столбцов, сколько в матрице.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017214637.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017214803.png)

В качестве частного случая умножения матрицы на вектор может выступать скалярное умножение двух векторов. Для этого нужно лишь записать один вектор как строку, а другой - как столбец:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017215554.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017215641.png)<br>
В отличие от произведения вектора и матрицы, скалярное произведение двух векторов **коммутативно**:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017215605.png)

**Умножение матрицы на вектор-столбец:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017220320.png)<br>
Строки матрицы по очереди умножают на вектор. В результате получается вектор-столбец с количеством элементов, равным числу строк матрицы.

**Алгоритм матричного умножения** выглядит так:
1. Проверить, что количество строк и столбцов совпадает.
2. Преобразовать вектор в матрицу.
3. Выполнить умножение.

**Линейные преобразования**<br>
Вкратце умножение вектора и матрицы выглядит так: берём вектор, находим его произведение с матрицей и получаем новый вектор. В итоге у нас два вектора, связанных одной матрицей, — старый и новый. Причём для каждого вектора существует единственный новый вектор, который получится в результате данного умножения.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017224419.png)<br>
Например:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017224609.png)<br>
Линейные преобразования удобно записывать в виде матриц:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017224951.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017225312.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017225250.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017225326.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017225259.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017225356.png)<br>
Также матрицы преобразования можно использовать для **перехода из пространства одной размерности в пространство другой размерности**.<br>
Например, прямоугольная матрица — 3×2 позволяет перейти из 2D в 3D:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017231706.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017231738.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017231745.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017231815.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017231831.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241017231834.png)

**Умножение матрицы на матрицу:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020124613.png)<br>
Допустим, мы умножили A на B и получили результат C. Его элемент $c[1,1]$​ — это скалярное произведение первой строки матрицы A и первого столбца матрицы B, элемент $c[1,2]$​ — скалярное произведение первой строки матрицы A и второго столбца матрицы B. И так далее. Часто результат C записывают просто как AB.![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020124937.png)<br>
 Если матрица  _A_  содержит  _m_  строк, а матрица  _B_  содержит  _n_ столбцов, то произведение  _AB_  представляет собой матрицу  _С_  размера  _m × n_.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020125004.png)<br>
Произведение матриц в общем случае некоммутативно!<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020130853.png)<br>
Перестановочными бывают только квадратные матрицы одного и того же размера.<br>
Нулевая и единичная матрицы будут перестановочными с любой матрицей соответствующего размера.<br>
**Свойства матричного произведения:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020133355.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020133457.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020133521.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020133602.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020133659.png)
## Определитель и обратная матрица

Матрицей, обратной матрице _A_, называется матрица $A^{-1}$, для которой выполняется условие:<br>
$A*A^{-1} = A^{-1}*A = E$,<br>
где E - единичная матрица того же порядка, что и матрица _A_.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020192016.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020192140.png)<br>
**Обратные матрицы существуют только для квадратных!**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020201619.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020201703.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020202026.png)

Частные случаи:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020191219.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020191253.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241020191332.png)<br>
Однако, чтобы получить обратную матрицу произвольной матрицы, приходится прибегать к другим средствам.

**Применение для решения системы линейных уравнений:**<br>
В обще виде систему линейных уравнений можно изобразить в матричном виде так:<br>
$$\begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\\a_{31} & a_{32} & a_{33}\end{pmatrix}*\begin{pmatrix} x_{11}\\x_{21}\\x_{31}\end{pmatrix}=\begin{pmatrix} b_{11}\\b_{21}\\b_{31}\end{pmatrix}$$<br>
Где:<br>
$a_{ij}$ - коэффициенты системы<br>
$b_{ij}$ - свободные члены<br>
$x_{ij}$ - система неизвестных (переменные)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241126195842.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241126213822.png)

**Система линейных уравнений (СЛУ)** — это система, каждое уравнение в которой линейное. В линейных уравнениях могут быть только переменные первой степени, умноженные на коэффициенты, и свободные коэффициенты. Если в системе хотя бы одно уравнение нелинейное, то и вся система не является системой линейных уравнений.

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241126201652.png)<br>
Сделать вывод о несовместности можно, если при решении возникает явное противоречие. Например, если в ходе преобразований получается, что 1=2.<br>
Кроме того:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241126213750.png)

**Типы СЛУ:**
1. Система линейных уравнений называется **однородной**, если все её свободные члены равны нулю.
2. Если в системе линейных уравнений хотя бы один из свободных членов отличен от нуля, то такая система называется **неоднородной**.

Решить систему уравнений — значит найти все её решения или доказать, что их нет.

Если для системы уравнений выполняется условие, что она квадратная (то есть количество уравнений совпадает с количеством неизвестных) и невырожденная (то есть ее определитель не равен 0), то она называется **Крамеровской**.

Чтобы решить **Крамеровскую систему уравнений** матричным методом, нужно умножить обратную матрицу коэффициентов на столбец свободных членов<br>
$X=A^{-1}*B$

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241128215706.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241128220216.png)

**Общее решение СЛУ:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241128222445.png)<br>
В недоопределенной системе всегда или нет решений, или бесконечное число решений.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241128223017.png)<br>
В переопределенной системе в большинстве случаев или нет решений, или бесконечное число решений, кроме случаев, когда ее при помощи линейных преобразований получается свести к определенной.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241128224612.png)<br>
**Метод Гаусса:**<br>
Чтобы решить систему линейных уравнений с помощью метода Гаусса, необходимо:
1. Выполнить последовательность элементарных преобразований, чтобы привести матрицу к ступенчатому виду.
2. Получится система, в которой каждое следующее уравнение имеет на одну неизвестную меньше, чем предыдущее. 
3. Теперь нужно решить полученную систему методом подстановки, начиная с нижнего уравнения и постепенно двигаясь наверх.<br>
*Например:*<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241128225548.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241128225612.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241128225652.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241128225710.png)

Для случаев с бесконечным числом решений вводится понятие **общего решения**:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241129181246.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241129181342.png)<br>
Свободные переменные обозначаются через параметры, а главные переменные выражаются через эти параметры. Количество главных переменных равняется значению ранга, то есть количеству ненулевых строк. Свободная переменная может быть одна или их может быть несколько.

Чтобы определить, какие переменные будут главными, надо найти в строках ступенчатой матрицы первые ненулевые значения. *Например:*<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241129181859.png)<br>
Свободными переменными становятся все остальные. Здесь свободной переменной будет $x_4$.<br>
Теперь можно вернуться обратно к системе и решить её. Обычно при поиске общего решения переменные не оставляют в их первоначальном обозначении, а заменяют на другие буквы, обозначающие параметры. Обозначим $x_4$​ за параметр t:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241129182057.png)<br>
Тогда решением системы будет вектор:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241129182134.png)<br>
Теперь, подставляя разные значения t, можно получить любое количество новых решений.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241129182154.png)


**СЛУ можно использовать для избавления от мультиколлинеарности.**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241126205838.png)<br>
То есть можно взять несколько признаков, между которыми предполагается зависимость:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241126205943.png)<br>
Решить для них систему уравнений с нулевым вектором свободных членов:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241126210021.png)<br>
Если найдется хоть одно ненулевое решение, то признаки линейно зависимы.

**Введение понятия определителя:**<br>
Векторы — это стороны или рёбра фигур. В зависимости от размерности матрицы, векторы могут образовывать отрезок, параллелограмм или параллелепипед.

Если умножить векторы одной фигуры на матрицу линейных преобразований, то они перейдут в векторы новой фигуры. При этом характеристики фигуры (длина, площадь или объём) масштабируются на коэффициент, равный той же характеристике новой фигуры с учётом ориентации.

Этот коэффициент зависит от матрицы линейного преобразования и называется **определителем матрицы**.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022205249.png)<br>
Определитель матрицы _1×1_ равен её единственному элементу.

Чтобы вычислить определитель матрицы _2×2_ , нужно:
1. Найти произведение элементов главной диагонали.
2. Найти произведение элементов побочной диагонали.
3. Вычесть из первого произведения второе.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022205432.png)

Для вычисления определителя матрицы _3x3_ существует несколько способов.<br>
**1. По правилу Саррюса:**
1. Дописать справа от матрицы два её первых столбца.
2. Посчитать произведение элементов для трёх главных диагоналей. Затем найти сумму произведений.
3. Посчитать произведение элементов для трёх побочных диагоналей. Найти сумму.
4. Вычесть из суммы произведений главных диагоналей сумму произведений побочных.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022214442.png)

**2. Через Минор и алгебраическое дополнение:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022214921.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022214950.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022215039.png)<br>
Например:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022215635.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022215642.png)

**Определитель любой квадратной матрицы можно** **разложить по первой строке**. Для этого нужно:
1. Найти алгебраические дополнения элементов первой строки.
2. Умножить элементы первой строки на их алгебраические дополнения.
3. Сложить получившиеся произведения.

Для матрицы _3×3_ формула выглядит так:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022215514.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022215750.png)<br>
Раскладывать именно по первой строке не обязательно. Обычно, выбирают ту строку или тот столбец, в которых больше нулей, чтобы сократить количество вычислений.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022220204.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022220241.png)


**Свойства определителя:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022210102.png)<br>
Если поменять строки матрицы на столбцы, то её определитель не изменится.

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022210138.png)<br>
Если поменять местами пару строк, а потом пару столбцов, к определителю вернётся исходный знак. Такие преобразования эквивалентны, и они могут упростить вычисления определителя.

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022210237.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022210406.png)

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022210439.png)<br>
Определитель обратной матрицы и определитель исходной матрицы взаимно обратны.


![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241022210520.png)<br>
Определитель произведения матриц равен произведению их определителей.

**Вырожденные матрицы:**

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024201015.png)<br>
Матрицы, состоящие из линейно зависимых векторов, — всегда вырожденные.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024201153.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024201208.png)<br>
Если матрица линейного преобразования вырожденная, она переводит векторы пространства в его подпространство меньшей размерности. Базисный квадрат превращается не в параллелограмм, а в отрезок; базисный куб — не в параллелепипед, а в параллелограмм или отрезок.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024202649.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024202736.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024202814.png)

**Свойства вырожденной матрицы:**
1. Вырожденная матрица остаётся вырожденной после транспонирования.
2. Вырожденная матрица остаётся вырожденной после умножения на скаляр.
3. Произведение вырожденной матрицы и любой матрицы того же размера даёт вырожденную матрицу.
4. Если матрица вырожденная, то система $Ax=0$ имеет ненулевые решения.

Н-р:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024203544.png)<br>
Для любой невырожденной матрицы единственными корнями такого уравнения будут нули. Следовательно:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024203711.png)<br>
Все эти свойства равноправны, то есть для каждой вырожденной матрицы выполняются одновременно.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024203802.png)

**Вычисление обратной матрицы при помощи определителя:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024221255.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241024221526.png)

**Образ и прообраз:**<br>
Любую точку плоскости однозначно определяет радиус-вектор.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241026142317.png)<br>
При применении к радиус-вектору матрицы линейных преобразований, определяемая им точка (Z) также переходит в новое положение (W).<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241026142441.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241026142600.png)

**Матрица перехода:**<br>
В линейном пространстве может существовать бесконечно много базисов. Между ними можно перемещаться, используя матрицу перехода:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241026145231.png)<br>
Матрица перехода содержит разложение векторов нового базиса в старом базисе **по столбцам**.<br>
То есть для матрицы перехода $T_{v->w}$ справедливо выражение:<br>
$X_w=X_v*T_{v->w}$<br>
Матрицей перехода из _W_ в _V_ будет являться $T^{-1}$ .<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241026145247.png)<br>
Таким образом, мы из координат одного базиса, получаем те же координаты в другом базисе.

Также может возникнуть задача получить в новом базисе линейное преобразование, аналогичное линейному преобразованию в старом базисе:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241026150248.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241026150424.png)

**Ранг матрицы:**<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241126213436.png)<br>
При это транспонирование не влияет на ранг матрицы, следовательно, его можно считать и для столбцов.<br>
*Например:*<br>
Имеем матрицу:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241126213521.png)<br>
С помощью элементарных преобразований приведём матрицу к ступенчатому виду:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241126213534.png)<br>
Одна строка стала полностью нулевой. В таком случае говорят, что она уничтожилась. Получается, что с помощью двух строк мы смогли выразить третью. Вот и линейная зависимость.<br>
Следовательно, это матрица **2-го ранга**.

## Собственные векторы и SVD

Возьмем набор векторов $\vec{a},\vec{b},\vec{c},\vec{d}$ и умножим их на матрицу линейного преобразования:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209222210.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209222213.png)<br>
Можно заметить, что вектор $\vec{c}$ изменил длину, но остался на той же прямой, как будто мы не преобразовали его матрицей, а просто умножили на скаляр.

Оказывается, у любой матрицы можно найти хотя бы один **вектор, который после действия на него линейного преобразования останется лежать на той же прямой.**<br>
В данном случае, таким будет любой вектор, лежащий на одной прямой с вектором $\vec{c}$.

Такое семейство векторов у матрицы может быть даже не одно. Например, у матрицы из примера есть ещё одно семейство векторов, остающихся на своей оси после преобразования:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209222634.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209222638.png)

Такие векторы называют **собственными векторами** линейного преобразования.<br>
Каждый собственный вектор связан со скаляром — коэффициентом растяжения или сжатия. Этот скаляр называют **собственным значением** или собственным числом линейного преобразования.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209222801.png)<br>
Из этого определения можно вывести формулу:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209223858.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209224015.png)

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209224135.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209224139.png)<br>
Если матрица диагональная, то элементы её главной диагонали равны собственным значениям.

Зная собственные значения, можно найти **собственные вектора** так:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209225323.png)<br>
Все подходящие векторы будут лежать на прямой $x=−1.5y$.

Для упрощения вычислений можно воспользоваться формулой:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209231735.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241209232756.png)

**Матричные разложения:**<br>
Единичный квадрат определён четырьмя равными векторами, концы которых являются его вершинами.<br>
Можно взять и любое другое количество векторов. Возьмём три и получим треугольник, пять — пятиугольник, шесть — шестиугольник, семь — семиугольник и так далее.<br>
Если взять бесконечное количество равных векторов с началом в одной точке, можно получить окружность.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211214654.png)  ![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211214703.png)

Известно, что невырожденная матрица 2×2 превращает единичный квадрат в параллелограмм. Аналогичным образом матрица 2×2 преобразовывает единичную окружность в эллипс.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211215000.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211215745.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211215618.png)<br>
Линия, проходящая через фокусы эллипса, называется **большой осью**, а линия, перпендикулярная ей — **малой осью**. Сумма расстояний от любой точки эллипса до его фокусов равна длине большой оси.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211215730.png)

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211215903.png)<br>
Примеры симметричных матриц:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211215918.png)   ![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211215925.png)   ![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211215931.png)<br>
Свойства симметричных матриц:
1. Симметричная матрица совпадает с собой же транспонированной. 
2. Если окружность преобразована симметричной матрицей, то осями полученного эллипса будут прямые, на которых расположены собственные векторы матрицы.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211220303.png)<br>
*Например:*<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211220326.png)   ![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211220335.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211220348.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211220355.png)<br>
Получились два вектора, которые лежат на осях эллипса:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211220403.png)

Далее будем рассматривать **матрицы, из собственных векторов которых можно построить базис**. Это возможно только тогда, когда количество линейно независимых собственных векторов матрицы совпадает с размерностью пространства.

Чтобы упростить и ускорить вычисления матриц большой размерности, исходную матрицу представляют в виде произведения более простых матриц. Чаще всего матрицы-множители имеют особые свойства (например, являются диагональными или симметричными) или меньшую размерность. Такое представление матрицы в виде произведения других называется **матричным разложением**, или факторизацией.

**Спектральное разложение:**<br>
Спектральное разложение используют для вывода других разложений. Оно основано на собственных векторах матрицы и работает только для тех матриц, собственные векторы которых образуют базис.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211224538.png)<br>
Порядок собственных значений в $Λ$ согласуется с порядком собственных векторов в $Q$.<br>
Так как можно составить бесконечное количество матриц собственных векторов, заменяя их на коллинеарные, то и спектральных разложений можно получить бесконечное количество.

*Например:*<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211225309.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211225315.png)   ![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211225336.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211225328.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211225412.png)

Ещё одна ценность спектрального разложения — это связь между исходной и обратной матрицей с помощью собственных значений и векторов.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211232311.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211232356.png)<br>
Итак, у нас получился математический матричный набор.
- Зная матрицу, можно вычислить её собственные значения и векторы, и обратную матрицу тоже.
- Зная собственные значения и векторы, можно вычислить матрицу и обратную ей.
- Зная обратную матрицу, также можно получить всё остальное.

Для симметричных матриц отдельно выделяют **спектральное разложение** с **ортонормированным базисом**.<br>
Базисные векторы ортонормированного базиса **ортогональны друг другу и имеют длину, равную единице**.<br>
Значит, нам нужны собственные единичные векторы. Чтобы их получить, нужно **нормировать** имеющиеся у нас векторы, то есть **поделить их координаты на длину вектора**.

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211234550.png)<br>
Из определения можно вывести замечательное свойство, которое поможет упростить спектральное разложение:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211235227.png)<br>
Получается, что поскольку собственные векторы симметричной матрицы ортогональны, то её спектральное разложение можно записать так:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241211235306.png)<br>
Такую запись иногда называют нормальной формой матрицы.<br>
Получается, если матрица симметрична, то её собственные векторы ортогональны, и спектральное разложение для неё превращается в нормальную форму.

Количество собственных значений квадратной матрицы зависит от её размерности.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212182822.png)<br>
Однако не обязательно все эти значения будут различными и действительными. **Тут возможны три случая:**
1) У матрицы n различных действительных собственных значений и ровно n линейно независимых собственных векторов.
2) У матрицы нет действительных собственных значений (при попытке найти получается отрицательный дискриминант). Собственные числа у такой матрицы будут в множестве комплексных чисел.
3) У матрицы есть совпадающие собственные значения.<br>
**В последнем случае возможно два варианта:**
* Количество линейно независимых собственных векторов совпадает с количеством повторений собственного значения.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212183140.png)
* Количество линейно независимых собственных векторов не совпадает с количеством повторений собственного значения.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212183301.png)

**Сингулярное разложение:**

Спектральное разложение помогает упростить вычислительные операции с матрицами. Но увы, оно работает далеко не для всех матриц.<br>
Если невозможно найти пару линейно независимых собственных векторов, составить матрицу, обратную к матрице собственных векторов, не получится, а значит, не получится и определить и спектральное разложение.

Любой круг можно превратить в любой эллипс, применив к нему три действия: **вращение**, **масштабирование** и ещё одно **вращение**. Все эти действия можно задать матрицами линейных преобразований.<br>
Так мы подходим к идее, что любую матрицу можно представить в виде произведения трёх матриц: **двух матриц вращения** и **диагональной матрицы, которая отвечает за масштабирование**.

В общем виде такое разложение записывают так:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212192206.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212192425.png)<br>
Аббревиатура SVD расшифровывается как Singular Value Decomposition, что переводится с английского как «разложение по сингулярным числам».<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212193612.png)

У квадратной матрицы размера n×n есть n сингулярных чисел $σ_i$, и каждому такому числу соответствует своя пара из левого $u_i$​ и правого $v_i$​ сингулярных векторов. Именно эти векторы и записаны в матрицах  и V по столбцам.

При преобразовании окружности с помощью произведения матриц, действия применяются справа налево. Напомним, что преобразование матрицей поворота мы определяли как поворот против часовой стрелки. Поэтому единичный круг трансформируется в следующем порядке:
1) поворот против часовой стрелки матрицей $V^T$
2) растяжение и сжатие матрицей $Σ$
3) поворот против часовой стрелки матрицей $U$.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212194324.png)

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212195242.png)<br>
Аналогично:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212195345.png)<br>
Следовательно:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212195358.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212195407.png)<br>
Можно идти разными путями при поиске нужных пар сингулярных векторов, однако для корректной работы алгоритма правильно будет рассчитывать сначала $V$ и $Σ$, а потом получать $U$ из формулы разложения:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212200449.png)<br>
Получаем такой **алгоритм построения сингулярного разложения матрицы** A:
1) Найти собственные числа матрицы $A^TA$.
2) Отсортировать их по убыванию. Составить матрицу $Σ$.
3) Найти собственные векторы матрицы $A^TA$. Из них составить матрицу правых сингулярных векторов $V$.
4) Вычислить матрицу левых сингулярных векторов по формуле: $U=AVΣ^{−1}$.
5) Из полученных матриц составить сингулярное разложение: $A=U⋅Σ⋅V^T$.

Достоинство сингулярного разложения в том, что оно работает с совершенно любыми матрицами: и вырожденными, и невырожденными, и квадратными, и прямоугольными.<br>
Если нам нужно разложить прямоугольную матрицу $A_{m×n}$, то количество сингулярных значений равно меньшему из чисел m и n. Остальные строки или столбцы диагональной матрицы будут нулевыми.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241212210725.png)

**Сжатие матриц:**

Сжатие изображений — одно из базовых и наглядных применений SVD. Идея состоит в том, чтобы описать картинку меньшим количеством чисел и при этом сохранить максимальное количество информации.

Сингулярные числа и векторы имеют важную интерпретацию:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241218213429.png)
- Если модуль сингулярного числа большой, то соответствующий сингулярный вектор вносит большой вклад в представление матрицы.
- Если модуль сингулярного числа мал, то и вклад соответствующего сингулярного вектора менее значителен.
- Если сингулярное число равно нулю, то и соответствующие ему векторы никак не влияют на исходную матрицу.<br>
Последнее позволяет перейти к **компактной записи** SVD:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241218213725.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241218213818.png)<br>
Полученная матрица Σ хранит сингулярные значения матрицы X, упорядоченные по убыванию модулей. U и V состоят из сингулярных векторов исходной матрицы. Эти векторы содержат информацию о её столбцах и строках и упорядочены соответственно сингулярным числам в Σ.

Разберём на примере сжатия картинки гвинейской свинки:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241218214741.png)<br>
Это чёрно-белая картинка. Её описывает матрица X, элементы которой обозначают яркость пикселей на соответствующих позициях. Размер матрицы — 402×584. Матрицу этой картинки, как и любую другую, можно факторизовать, то есть разложить в произведение трёх матриц с помощью SVD.
* В матрице Σ важно, что сингулярные числа на главной диагонали уменьшаются.
* В матрицах U и V важно то, что порядок сингулярных векторов в них соответствует порядку сингулярных чисел в Σ.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241218214950.png)<br>
 Далее будем отбрасывать наименее значимые сингулярные векторы и смотреть, как будет изменяться картинка:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241218215215.png)<br>
  Каждая пара сингулярных векторов (правый и левый) соответствует компоненте исходной картинки. Исходное изображение — это сумма этих компонент.<br>
  ![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241218215245.png)<br>
  ![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241218215358.png)<br>
Смысл названия в том, то мы «усекаем» матрицы U, Σ и V, то есть уменьшаем их, чтобы получить приближение исходной матрицы.

Чтобы численно оценить степень искажения от сжатия можно, например, посчитать **MSE** между оригинальной картинкой и ее приближением. Однако существуют и другие, более подходящие метрики.<br>
На картинке человек видит не отдельные пиксели, а группы пикселей. На этом факте основана метрика **SSIM** (Structural Similarity Index Measure), или индекс структурного сходства.<br>
Чтобы вычислить метрику и оценить сходство двух картинок, действуют так:
1. Обе картинки одинаковым образом разделяют на маленькие квадратики.
2. Соответствующие квадратики двух исходных изображений сравнивают друг с другом. SSIM учитывает среднюю яркость пикселей в квадратиках, разброс значений пикселей, а также то, насколько похоже изменяются значения пикселей внутри квадратиков. В результате сравнения для каждого квадратика получается число от −1 до +1, которое описывает степень совпадения картинок в этом квадратике. Значение метрики +1 означает полное совпадение картинок.
3. Числа по всем квадратикам усредняют и получают общую оценку схожести картинок — так же в диапазоне −1 до +1.

**Латентный семантический анализ:**

**Latent Semantic Analysis** - это метод обработки информации на естественном языке, с помощью которого слова переводят в векторы.

Технология представляет набор документов и слов в них в виде набора векторов. Это помогает определить, похожи ли документы. Сходные по тематике соответствуют близким векторам, различные — далёким.

Метод выделяет группы похожих слов, и даже если в документе нет конкретного слова, но есть близкое к нему, то это учтётся и повлияет на вектор этого документа.

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221142447.png)<br>
Базовый вариант LSA состоит из трёх шагов:
1. Подготовить данные к анализу;
2. Собрать матрицу встречаемости слов;
3. Сформировать эмбеддинги слов и документов.

**Подготовка данных:**<br>
На этом этапе удаляют знаки препинания и слова, которые не несут много смысла. Например, отбрасывают: предлоги, союзы, часто употребляемые слова («всегда», «никогда», «например», «более», «наконец» и другие), слова, которые встречаются только в одном документе.<br>
В итоге в каждом документе остаются только значимые слова. Их приводят к начальным формам. Так мы помогаем компьютеру унифицировать слова, которые могут отличаться только окончаниями или суффиксами. Программа теперь будет считать, что, например, «увлекательный» и «увлекательнейшего» — это одно и то же слово.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221142822.png)

**Составление матрицы:**<br>
Все значимые слова из всех документов объединяют в один список. Затем строят матрицу встречаемости слов:
- Её строки соответствуют словам,
- Столбцы — документам,
- Элемент на пересечении строки и столбца показывает, сколько раз слово встречается в документе.<br>
Визуализируем часть такой матрицы. Для большей наглядности часто используют не числа, а цвет. На иллюстрации оттенок ячейки показывает количество повторений слова в документе. Белый цвет означает, что слово в документе не встречается. Чем темнее ячейка, тем чаще встречается слово.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221142957.png)

**Формирование топиков:**<br>
Простейшая идея — использовать столбцы матрицы встречаемости слов как векторы, описывающие документы. Векторы будут близки, если в них много близких координат. Это значит, что документы будут похожи, если в них много одинаковых слов и их количество примерно одинаково.

Однако описывать документы столбцами из матрицы встречаемости слов имеет большой недостаток — в анализе не учитываются слова, близкие по смыслу и теме. Из-за этого похожие объекты могут интерпретироваться алгоритмом как различающиеся.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221143505.png)

Для решения этой проблемы задействуется SVD. Разберёмся, как составить векторы слов. Факторизуем матрицу встречаемости слов:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221143814.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221152341.png)<br>
Получается, слово соответствует строке матрицы X, а каждая строка этой матрицы задаётся строкой матрицы U. Поэтому можно предположить, что векторное описание i-го слова — это i-я строка U.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221152413.png)<br>
Каждый сингулярный вектор имеет свой «вес» и несёт определённое количество информации от исходной матрицы:
- Сингулярные векторы, которые соответствуют маленьким сингулярным значениям, хранят мало информации.
- Векторы, которые соответствуют большим значениям, — много.<br>
Чтобы учесть это, умножим матрицу U на матрицу Σ. Так каждый сингулярный вектор умножится на свой вес. В результате значения в информативных векторах станут больше, а в малоинформативных — меньше.<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221152610.png)<br>
Следовательно:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221152727.png)<br>
Считают, что каждый сингулярный вектор соответствует группе слов, которые появляются друг с другом. Эти группы слов изначально неизвестны, то есть скрыты. Отсюда идёт и название метода: latent переводится с английского как «скрытый».<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221152845.png)<br>
Полученные векторы часто усекают и рассматривают не всю строку матрицы U, а только ту её часть, которая содержит элементы наиболее значимых сингулярных векторов. Это позволяет отбросить лишние детали и уменьшить число искомых топиков.<br>
Затем рассчитывают расстояния между векторами слов и находят близкие по смыслу слова.

**Векторы документов:**<br>
Точно такие же рассуждения можно провести с векторами документов и матрицей $V^T$:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221153735.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221153852.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221153856.png)<br>
Следовательно:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221153907.png)<br>
Аналогично случаю со словами, сингулярные векторы объединяют документы в топики — те же самые, что и в матрице U.

Транспонированные векторы документов и векторы слов имеют один размер, значит, они находятся в одном векторном пространстве, так что их можно сравнивать. Например, можно найти ближайший к слову документ. Это позволяет делать полноценные текстовые запросы, например, усредняя векторы слов в запросе и находя наиболее близкий к полученному вектору документ.

*Пример:*<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221154746.png)<br>
Составим матрицу встречаемости слов:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221154757.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221154810.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221154818.png)<br>
Эта матрица описывает слова и топики, в которых они встречаются. Например, первый топик получился про огурцы и дачную тематику, потому что такой набор слов входит в соответствующие отзывы. Даже если слово встречалось только в одном документе, оно всё равно может проявить себя в одном из топиков. Например, слово `лопата` было только в одном отзыве, но проявило себя в первом топике. Это произошло потому, что рядом со словом `лопата` было слово `дача`, оно используется в отзыве со словом `вкусный`, которое, в свою очередь, используется в отзывах со словами `огурец`, `горьковатый`, `немного`, `отстой`. Таким образом, участие в общих документах «связывает» слова в топики.

![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221154900.png)<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221154907.png)<br>
Зададим слово `огурец` и найдём наиболее подходящий к нему документ. Для этого вычислим L2​-расстояние между вектором слова и всеми векторами документов в базе:<br>
![](../Вложения/Линейная%20алгебра/Pasted%20image%2020241221154944.png)<br>
По полученным расстояниям выбирают наиболее близкий к слову документ. В примере это `Огурцы не понравились, они не свежие.






## Дискретные случайные величины

**Элементарное событие** - это подмножество пространства исходов случайного эксперимента, которое состоит только из одного элемента.

**Пространство элементарных событий** - множество ${\displaystyle \Omega}$ всех взаимно или попарно исключающих друг друга исходов случайного эксперимента, которые вместе образуют полную группу событий.

**Событие** - произвольное подмножество пространства элементарных событий ${\displaystyle \Omega}$.

Если монета бросается дважды, $\displaystyle \Omega = \{HH, HT, TH, TT\}$, $H$ для орла, а $T$ для решетки, то элементарные события: $\{HH\}, \{HT\}, \{TH\}, \{TT\}$.

**Случайная величина** - это измеримая функция, заданная на каком-либо вероятностном пространстве.

**Пространства элементарных событий** (**исходов**) бывают **конечные**, **счётные** и **несчётные**. 
**Конечные** и **счётные** пространства называют **дискретными**. Случайную величину, определённую на таком пространстве, тоже называют **дискретной**.
Случайные величины, определённые на **несчётных** пространствах исходов, называют **непрерывными**.

![[Pasted image 20241225170941.png]]

Каждому элементу пространства исходов функция $X$ присваивает одно из значений $x_1, …, x_n​$. Случайная величина — такая же функция, разница только в том, что аргументы случайной величины — не числа, а объекты из пространства исходов. А значения случайной величины — это обычные числа.

![[Pasted image 20241225173006.png]]
![[Pasted image 20241225173106.png]]
То есть, вероятность, что случайная величина X примет значение x, равна сумме вероятностей исходов, для которых $X(ω)=x$.

**Свойства вероятности:**
![[Pasted image 20241225174237.png]]

**Распределение случайной величины** - это набор вероятностей, с которыми она принимает те или иные значения:
![[Pasted image 20241225180833.png]]
**Многоугольником распределения вероятностей** данной величины называют ломаную, звенья которой соединяют соседние точки $(x_i,p_i)$.
![[Pasted image 20241225181152.png]]
![[Pasted image 20241226193148.png]]
![[Pasted image 20241226193305.png]]
![[t42ti1VAYkY.jpg]]
![[DGclUvgDusU.jpg]]

**Математическое ожидание дискретной СВ:**
![[Pasted image 20241225182332.png]]
Свойства математических ожиданий:
![[t1MDShTGxks.jpg]]

**Дисперсия дискретной СВ:**
Дисперсия показывает, насколько отклоняется случайная величина от своего среднего значения: чем больше у случайной величины значений, далёких от среднего как в меньшую, так и в большую сторону, тем больше дисперсия.
![[Pasted image 20241225184851.png]]
Свойства дисперсии:
![[SmV03Hv8-pI.jpg]]

Из-за того, что при вычислениях мы возводим значения в квадрат, дисперсия измеряется в единицах в квадрате — в отличие от математического ожидания. Например, если $X$ — это количество рублей, то дисперсия будет в рублях в квадрате.

На практике это решают извлечением корня из дисперсии, чтобы вернуться в размерность $X$. Поэтому часто можно встретить величину $\sqrt{Var(X)}$ — она называется **стандартным отклонением** для случайной величины $X$.

### Распределение Бернулли

![[Pasted image 20241226201044.png]]
![[Pasted image 20241226201726.png]]
![[Pasted image 20241226202125.png]]
Распределение Бернулли часто строят для целой совокупности случайных величин. Это позволяет описать серию повторяющихся экспериментов с двумя исходами. Можно комбинировать случайные величины Бернулли вместе, чтобы получать более сложные распределения.

**Биномиальное распределение:**
Возьмем серию из $n$ одинаковых и независимых друг от друга испытаний Бернулли. Вероятность успеха в каждом испытании одинакова и равна $p$, а результат одного испытания не влияет на результат последующих. 

Получается последовательность $\omega=(x_1,x_2,..,x_n)$, где каждый $x_i$ - успех или неудача. Тогда наше вероятностное пространство - это всевозможные последовательности успехов и неудач.

Теперь рассмотрим случайную величину, равную **количеству успехов** в такой серии испытаний. Распределение вероятностей этой случайной величины называется **Биномиальное распределение**.
![[Pasted image 20241226205025.png]]
![[Pasted image 20241226224020.png]]
![[Pasted image 20241226230313.png]]

**Геометрическое распределение:**
Пускай эксперимент проводится ровно до тех пор, пока случайная величина не примет интересующее нас значение в первый раз. В этом случае нас будет интересовать номер попытки, при которой «успех» наконец сменит «неуспех» — или наоборот.
Тогда случайная величина, которая возникает при моделировании подобных экспериментов, имеет геометрическое распределение.
![[Pasted image 20241226231150.png]]
![[Pasted image 20241226231512.png]]
![[Pasted image 20241226231821.png]]
Следовательно, мы можем построить распределение вероятностей первого успеха в схеме Бернулли на k-ом испытании:
![[Pasted image 20241226231924.png]]
![[Pasted image 20241226232453.png]]

**Равномерное распределение:**
Иногда вероятности исходов предполагают равными. Например, так делают для простоты или в случае, когда нет другой информации. Для случайной величины также можно рассматривать распределение с равными вероятностями значений.
![[Pasted image 20241227205610.png]]
![[Pasted image 20241227205715.png]]
![[Pasted image 20241227205718.png]]
![[Pasted image 20241227211150.png]]

**Распределение Пуассона:**
Если нас интересует количество одинаковых событий, случившихся за определённый отрезок времени, лучше всего подойдет распределение Пуассона. Оно похоже на биномиальное, но здесь нет $n$ попыток — вместо них временной интервал.
![[Pasted image 20241227211813.png]]
![[Pasted image 20241227211902.png]]
![[Pasted image 20241227212326.png]]
![[Pasted image 20241227212333.png]]
![[Pasted image 20241227212339.png]]
На иллюстрациях видно, что с увеличением параметра μ вершина распределения смещается вправо, а разброс значений увеличивается.

Теорема Пуассона применяется в случаях, когда $n$ велико, а $p$ наоборот небольшое. Это связано с тем, что для таких случаев использовать биномиальное распределение неудобно - цифры получаются слишком большими. 

![[Pasted image 20241227213537.png]]

## Совместное распределение

Случайные величины, которые относятся к одному эксперименту, как правило, влияют друг на друга. Чтобы отследить и описать зависимость между такими величинами, нам понадобится совместное распределение.

**Дискретное совместное распределение двух случайных величин**, определённых на одном пространстве исходов, — это закон, который приписывает определённую вероятность каждой паре значений.
![[Pasted image 20250102120948.png]]
![[Pasted image 20250102120959.png]]

![[Pasted image 20250102121357.png]]
![[Pasted image 20250102121502.png]]

![[Pasted image 20250102121648.png]]
То есть, если нам известно только совместное распределение H и G, мы можем вывести из него распределение, например, случайной величины H.
![[Pasted image 20250102121815.png]]
Чтобы найти частное распределение H, достаточно для каждого возможного значения этой величины просуммировать все значения в строке:
![[Pasted image 20250102121841.png]]
И вероятность каждого значения H — это сумма вероятностей трёх несовместных событий.
![[Pasted image 20250102121908.png]]

![[Pasted image 20250102122214.png]]

**Независимость случайных величин:**

По совместному распределению двух случайных величин можно установить, влияет ли значение одной на вероятность значения другой.
![[Pasted image 20250102122401.png]]
Или:
![[Pasted image 20250102122609.png]]
*Например:*
![[Pasted image 20250102122702.png]]

Построить совместное распределение, имея частное, возможно только для независимых случайных величин.

**Математическое ожидание для двух случайных величин:**

Совместное распределение двух случайных величин может помочь в поиске математического ожидания комбинации этих величин. Комбинацией величин может быть их сумма, разность, минимум или максимум из них или другая функция от двух величин.

![[Pasted image 20250102124033.png]]
![[Pasted image 20250102124041.png]]
То есть, чтобы найти математическое ожидание для функции от нескольких случайных величин, достаточно рассчитать все возможные значения этой функции и суммировать их с учётом вероятностей.
На основе этого правила можно выразить важное свойство математического ожидания:
![[Pasted image 20250102124217.png]]
![[Pasted image 20250102124333.png]]
Это свойство удобно тем, что оно работает как для зависимых, так и для независимых случайных величин.

**Дисперсия суммы случайных величин:**

Используя свойства математического ожидания выше, можно вывести свойство для дисперсии:
![[Pasted image 20250102135530.png]]
![[Pasted image 20250102135554.png]]
 
Для **независимых величин** дисперсия суммы равная сумме дисперсий.

Для **зависимых величин** дисперсию суммы нельзя посчитать как сумму их дисперсий. Вместо этого используют формулу, которая получается из определения:
 ![[Pasted image 20250102140302.png]]
 Получается, чтобы найти дисперсию суммы, надо к сумме дисперсий дважды прибавить дополнительное слагаемое $E[(X−E[X])(Y−E[Y])]$.
 Это слагаемое имеет свое название - **ковариация**.

**Ковариация:**

![[Pasted image 20250102140805.png]]
Или:
![[Pasted image 20250102144130.png]]

Ковариация является мерой связи двух случайных величин. Она может принимать значения $(-\infty,+\infty)$. Важен её знак: она больше, меньше или равна нулю.

**Положительное** значение ковариации говорит вот о чём: если X приняла значение больше среднего, то с большей вероятностью Y примет значение, большее среднего. И наоборот: если X приняла значение меньше $E[X]$, то с большей вероятностью Y примет значение, меньшее $E[Y]$.

**Отрицательная** ковариация означает, что если X примет значение, превышающее математическое ожидание X, то с большей вероятностью значение Y будет ниже среднего. И наоборот: если X примет значение меньше математического ожидания X, то с большей вероятностью значение Y будет выше среднего.

Недостаток ковариации в том, что она сильно зависит от единиц измерения. Эту зависимость в точности описывает следующее правило:
![[Pasted image 20250102150915.png]]
![[Pasted image 20250102150926.png]]
По этой причине, ковариация плохо подходит для оценки силы взаимодействия случайных величин.

**Корреляция:**

Итак, ковариация помогает понять направление связи между двумя случайными величинами, но не подходит для того, чтобы оценить силу этой связи. Поэтому на практике чаще используют другую величину, похожую на ковариацию, — **коэффициент корреляции**.

![[Pasted image 20250102151707.png]]
При смене единиц измерения коэффициент корреляции не меняется, потому что, в отличие от ковариации, он является безразмерной характеристикой:
![[Pasted image 20250102152741.png]]

Коэффициент корреляции принимает значения от −1 до 1, чем выгодно отличается от ковариации. Значения коэффициента ограничены с двух сторон, и поэтому их легче интерпретировать. Поэтому пары случайных величин можно сравнивать не только по направлению их связи, но и по силе этой связи.

На практике значение коэффициента корреляции интерпретируют так:
![[Pasted image 20250102153723.png]]

$ρ(X, Y)$ принимает максимальное и минимальное значения в случае, когда $Y(ω)=a⋅X(ω)+b$ для любого $ω∈Ω$. Дело в том, что коэффициент отражает силу **линейной связи** между случайными величинами, то есть близость к такому линейному соотношению.

Если же зависимость между случайными величинами задана каким-то более сложным, нелинейным образом, то корреляция будет близка к нулю или равна ему.

Между понятиями независимости и некоррелированности есть важная взаимосвязь:
![[Pasted image 20250102160320.png]]
Если случайные величины некоррелированные, это не значит, что они не связаны. Между ними всё равно может быть зависимость, просто нелинейная.
![[Pasted image 20250102161358.png]]
## Условная вероятность 

**Условная вероятность** - это **вероятность события** A **при условии (наступления) события** B. Ее обозначают $P(A∣B)$.
$P(A∣B)$ — это доля исходов из A в общем количестве B:
![[Pasted image 20250103133020.png]]
До введения условия мы рассматриваем вероятности событий A и B относительно всего множества исходов Ω. На рисунке это белый квадрат слева. Интересующие нас исходы лежат на пересечении $A∩B$. После того как ввели новое условие, часть исходов можно отбросить — пространство допустимых исходов сузилось до B.
Из этого определения можно вывести формулу:
![[Pasted image 20250103133222.png]]
![[Pasted image 20250103133302.png]]
Условную вероятность для случайной величины X при условии ${Y=y_0​}$ можно записать так:
![[Pasted image 20250103133602.png]]

Если преобразовать формулу, можно получить **вероятность пересечения** двух событий:
![[Pasted image 20250103135919.png]]
![[Pasted image 20250103135926.png]]
Таким образом, подсчёт вероятности можно разложить на две части:
1) найти вероятность $Y=y$;
2) найти вероятность, что $X=x$ при условии $Y=y$.
Зачастую это проще, чем сразу искать вероятность $X=x∩Y=y$.

Также можно определить условную функцию распределения:
![[Pasted image 20250103135237.png]]

**Формула полной вероятности:**

**Дерево вероятностей** - это дерево, **вершины** которого отображают события и связаны друг с другом **ветвями**. Корневая, то есть самая левая, вершина отражает событие с вероятностью 1. Остальные вершины показывают, как это событие разбивается на другие, несовместные.
![[Pasted image 20250103141216.png]]
Связанная с какой-либо вершиной вероятность — это шансы, что событие произойдёт после того, как случилось событие из родительской вершины.
**Сумма вероятностей** на всех рёбрах, исходящих из одной вершины, **всегда равна единице**.

*Например:*
![[Pasted image 20250103141512.png]]
![[Pasted image 20250103141516.png]]
По дереву вероятностей видно, что событие «Макс успел на автобус» состоит из нескольких частей. Связать их воедино поможет **формула полной вероятности**:

**![[Pasted image 20250103141610.png]]
![[Pasted image 20250103141615.png]]
Теорема Байеса:

Теорема позволяет выяснить вероятность события при условии, что произошло связанное с ним другое событие.

Она позволяет рассчитать вероятность события, если причину и следствие поменять местами. Например, мы знаем распространенность симптома среди больных и здоровых. Значит, мы можем вычислить вероятность заболевания от наличия симптома.

![[Pasted image 20250103142638.png]]
![[Pasted image 20250103142758.png]]
Простая запись:
![[Pasted image 20250103143816.png]]
Здесь $P(B)$ - полная вероятность события $B$, включающая все возможные условные вероятности, а $P(A)*P(B|A)$ - отдельный интересующий нас случай, являющийся одной из составляющих этой полной вероятности. 

*Например:*
![[Pasted image 20250103150415.png]]
Здесь $P(H_1),P(H_2)$ - это **априорные** (оцененные **до** испытания) вероятности, а $P(H_2|A)$ - это **апостериорная** (оцененная **после** испытания) вероятность того же события, пересчитанная в связи «со вновь открывшимися обстоятельствами» – с учётом того факта, что событие $A$ **достоверно произошло**.

**Условное математическое ожидание:**

**Условное матожидание** — это среднее значение случайной величины при выполнении некоторого условия или при реализации какого-то события. В качестве условия тут выступает фиксированное значение случайной величины, которая может быть связана с данной.

![[Pasted image 20250103151144.png]]

## Непрерывные случайные величины

Если рассматривать график функции распределения **дискретной** случайной величины, можно заметить, что он всегда будет иметь ступенчатую форму со скачком между разными дискретными значениями:
![[Pasted image 20250104161401.png]]
Если начать уплотнять такой график и постепенно уменьшать разницу между дискретными значениями, размер скачка будет постепенно стремиться к нулю, и график станет похож на график **непрерывной** функции:
![[Pasted image 20250104161549.png]]
Тогда функцию распределения можно приравнять к соответствующей непрерывной функции и работать с описываемым распределением не как с дискретным, а как с **непрерывным**.

![[Pasted image 20250104161811.png]]
Для произвольной непрерывной случайной величины $Q$ множество значений функции распределения $FQ(x)$ должно полностью включать интервал $(0, 1)$ и при этом быть непрерывным.
![[Pasted image 20250104162131.png]]

Идея такая — то, что выглядит непрерывным, можно считать непрерывным. Пробег машины, концентрация, рост — эти величины интуитивно кажутся непрерывными. Множество возможных исходов здесь зависит только от точности приборов или наших знаний о мире. Конечно, замена многоступенчатой функции на непрерывный аналог приводит к ошибке. Но эта ошибка настолько мала, что в реальных задачах практически незаметна.

**Функция распределения непрерывной СВ:**

Функция распределения для непрерывной случайной величины задаётся так же, как и для дискретной. По определению:
![[Pasted image 20250104163050.png]]
**Свойства** функции распределения непрерывной СВ:
1. ![[Pasted image 20250104163336.png]]         ![[Pasted image 20250104163356.png]]
2. $F_X​(x)$ ограничена нулём снизу и единицей сверху;
3. $F_X​(x)$ — неубывающая функция;
4. $F_X​(x)$ является непрерывной функцией на всей прямой тогда и только тогда, когда случайная величина непрерывна. Это значит, что:
	- У непрерывной случайной величины функция распределения непрерывна;
	- Если функция распределения непрерывна, то и соответствующая ей случайная величина тоже непрерывна.
	
Если функция не удовлетворяет хотя бы одному из этих свойств, то она не может быть функцией распределения непрерывной случайной величины.

**Функция плотности распределения:**

**Функция плотности распределения** - это аналог функции вероятности дискретных случайных величин для непрерывных случайных величин. Эта функция тоже показывает, сколько вероятности собрано в точке (или в исходе, соответствующем этой точке), но делает это немного другим способом:
![[Pasted image 20250107121217.png]]
Иначе говоря, $F_X(x)$ является первообразной для $f_X(x)$.
![[Pasted image 20250107121552.png]]
В этой формуле используется x в качестве верхнего предела для того, чтобы из всего множества первообразных, которые мы могли получить с помощью этого интеграла, оставить только одну.
![[Pasted image 20250107122721.png]]
![[Pasted image 20250107123223.png]]
![[Pasted image 20250107123254.png]]
![[Pasted image 20250107124525.png]]
*Следовательно:*
Вероятность того, что непрерывная случайная величина попадёт в интервал, не зависит от того, включены ли границы в этот интервал или нет. Граница интервала — это одна точка, вероятность того, что случайная величина примет именно это значение, равна нулю.
![[Pasted image 20250107124714.png]]
![[Pasted image 20250107124852.png]]
Получается, значение функции плотности $f_X​(x_0​)$ **прямо пропорционально** вероятности попадания значения $X$ в достаточно малую окрестность точки $x_0$. Функция плотности не показывает напрямую вероятность того, что случайная величина приняла конкретное значение. Но тем не менее с её помощью сравнивают вероятности различных значений с оговоркой, что речь идёт не о конкретных значениях, а о достаточно малых областях вокруг них.

Сформулируем в общем виде:
- Если нужно вычислить вероятность попадания случайной величины в **интервал**, то пригодится **функция распределения**.
- Если нужно вычислить вероятность в точке (если точнее, в **бесконечно малой области вокруг точки**), то поможет функция **плотности распределения**.

**Математическое ожидание и дисперсия непрерывных СВ:**

Если случайная величина X непрерывная, то её **математическое ожидание** вычисляют с помощью функции плотности:
![[Pasted image 20250107134357.png]]

Определения **дисперсии** без изменений переносятся и на непрерывные случайные величины. Если расписать их через интеграл плотности, получится формула дисперсии для непрерывных случайных величин:
![[Pasted image 20250107141059.png]]
![[Pasted image 20250107141143.png]]
Обычно если $f(x)$ — простая функция, то используют первую. А если $f(x)$ является довольно сложной функцией, то удобнее вторая формула.

### Непрерывное равномерное распределение

![[Pasted image 20250108115839.png]]
*Например:*
10-метровый провод повреждён, но в какой именно точке — неизвестно. Видно, что на первых двух метрах всё в порядке, как и на последних трёх. А оставшаяся, средняя часть провода скрыта за плинтусом.
![[Pasted image 20250108115951.png]]
![[Pasted image 20250108115955.png]]

![[Pasted image 20250108120134.png]]
![[Pasted image 20250108120238.png]]

**Функция распределения непрерывной равномерной СВ:**
![[Pasted image 20250108120942.png]]
![[Pasted image 20250108121036.png]]
**Математическое ожидание и дисперсия непрерывно распределенной равномерной величины:**
![[Pasted image 20250108132748.png]]

### Экспоненциальное распределение

![[Pasted image 20250108123344.png]]
В этом распределении параметром является величина $λ$. Именно она отвечает за то, как будет выглядеть данное распределение:
![[Pasted image 20250108123525.png]]
Параметр $λ$ определяет начальную точку на оси $Y$, из которой выходит график функции плотности распределения, а также скорость уменьшения значения функции. Чем больше $λ$, тем выше начальная точка на оси $Y$, но и тем быстрее уменьшается значение функции.

**Функция распределения экспоненциально распределённой величины:**
![[Pasted image 20250108123810.png]]
**Математическое ожидание и дисперсия экспоненциально распределённой величины:**
![[Pasted image 20250108130258.png]]
Выводятся из общей формулы путем интегрирования.

**Применение:**
Чаще всего экспоненциальным распределением описывают различные процессы, непрерывные во времени, но с которыми рано или поздно должно что-то случиться. Это может быть горение лампочки (спойлер: она перегорит) или распад атома (спойлер: он распадётся).

### Нормальное распределение

![[Pasted image 20250108134209.png]]
График плотности нормального распределения выглядит как колокол. Значения по центру колокола наиболее вероятные, а при отдалении от центра влево или вправо вероятность уменьшается с одинаковой скоростью в обе стороны, но при этом всюду отлична от нуля:
![[Pasted image 20250108134914.png]]
![[Pasted image 20250108134950.png]]

**Функция распределения нормального распределения:**
![[Pasted image 20250108135341.png]]
Этот интеграл не берется стандартными способами, однако его значение можно вычислять приближенно.
![[Pasted image 20250108135603.png]]
![[Pasted image 20250108135618.png]]

**Математическое ожидание и дисперсия нормально распределенной величины:**
![[Pasted image 20250108140111.png]]
![[Pasted image 20250108140117.png]]
Получается, что математическое ожидание нормального распределения равно $μ$, а дисперсия равна $σ^2$. Именно эти величины являются параметрами. 

**Стандартное нормальное распределение:**
![[Pasted image 20250108140637.png]]
Из формулы в определении следует, что:

$\large E(X)=0$

$\large Var[X]=1$

Стандартное нормальное распределение используют в случаях, когда нужно **избавиться от размерности** исходной случайной величины:
![[Pasted image 20250108140913.png]]
![[Pasted image 20250108141002.png]]
Переход, который приводит случайные нормальные величины с произвольными значениями параметров к одному стандартному виду, называется **стандартизацией**.

### Совместное распределение непрерывных случайных величин

Совместная функция распределения непрерывных величин выглядит так же, как она выглядит для дискретных:
![[Pasted image 20250109180359.png]]
Функция совместного распределения двух случайных величин обладает несколькими свойствами:
* Функция распределения $F(x, y)$ есть неубывающая функция от обоих своих аргументов:
![[Pasted image 20250109180744.png]]
* Если $x$ **или** $y$ обращаются в $−∞$, то функция распределения равна нулю:
![[Pasted image 20250109180844.png]]
* Если $x$ **и** $y$ обращаются в $+∞$, то функция распределения равна единице:
![[Pasted image 20250109180948.png]]

### Функция плотности совместного распределения:

![[Pasted image 20250109190631.png]]
Для наличия производной необходимо, чтобы функция была непрерывная. А значит, в этом случае $F_{X,Y}(x, y)$ вынуждена быть непрерывной.

**Функция совместной плотности** — это функция двух переменных, её график трёхмерный. Получается, она показывает, какая часть вероятности сосредоточена в бесконечно малом квадрате вокруг конкретной точки.
![[Pasted image 20250109192222.png]]

**Свойства функции плотности совместного распределения:**
* Совместная плотность распределения является всюду неотрицательной функцией.
![[Pasted image 20250109192442.png]]
* **Объём** под поверхностью функции плотности совместного распределения равен 1.
Чтобы вычислить **объем** под поверхностью объемной фигуры, используют **двойные интегралы**:
![[Pasted image 20250109192714.png]]
Двойной интеграл часто означает, что сначала происходит интегрирование по одной переменной в некотором интервале, а потом — по обновлённой функции в некотором интервале.
Пока мы интегрируем по одной переменной, нужно считать другие константами и не обращать на них внимания.
Последовательность интегрирования не влияет на результат: можно интегрировать в том порядке, какой больше нравится.

*Например:
![[Pasted image 20250109192848.png]]
![[Pasted image 20250109192906.png]]

![[Pasted image 20250109193515.png]]
![[Pasted image 20250109193520.png]]
![[Pasted image 20250109193528.png]]
![[Pasted image 20250109193534.png]]

* Двойной интеграл в бесконечных пределах плотности совместного распределения двух непрерывных случайных величин равен 1:
![[Pasted image 20250109194234.png]]

![[Pasted image 20250109194427.png]]

**Плотность распределения каждой компоненты совместного распределения:**
Польза плотности совместного распределения заключается в том, что по её функции $f_{X,Y}(x,y)$ можно найти плотность распределения каждой величины $X$ и $Y$ по отдельности: $f_X(x)$, $f_Y(y)$.

Если $f_{X,Y}(x,y)$ является плотностью совместного распределения случайных величин $X$ и $Y$, то:
![[Pasted image 20250109194837.png]]

**Независимость непрерывных случайных величин:**
![[Pasted image 20250109195840.png]]
Или:
![[Pasted image 20250109195851.png]]

**Ковариация двух непрерывных случайных величин:**
![[Pasted image 20250109201802.png]]
Свойства ковариации непрерывных величин не отличаются от тех, что были в дискретном случае:
![[Pasted image 20250109201933.png]]

**Корреляция двух непрерывных случайных величин:**
![[Pasted image 20250109205253.png]]
Свойства:
![[Pasted image 20250109205319.png]]

### Условная вероятность для непрерывных случайных величин

Формула для дискретных случайных величин:
![[Pasted image 20250110140527.png]] 
Аналог для непрерывных случайных величин:
![[Pasted image 20250110140611.png]]
Иными словами, если нам известно совместное распределение $X$ и $Y$ и какое-то конкретное значение $y$ случайной величины $Y$, то по формуле можно найти плотность распределения $X$ при условии, что событие $Y=y$ уже случилось.

*Например:*
![[Pasted image 20250110141738.png]]
![[Pasted image 20250110141749.png]]
![[Pasted image 20250110141802.png]]
![[Pasted image 20250110141807.png]]

**Условное математическое ожидание:**
![[Pasted image 20250110143008.png]]

**Формула полной вероятности:**
Как и в случае с дискретными случайными величинами формула полной вероятности позволяет вычислить вероятность события $A$, когда известны его вероятности при условии выполнения события $B$. То есть, зная все условные вероятности события $A$, можно вычислить безусловную вероятность $A$.
![[Pasted image 20250110144932.png]]

**Формула Байеса для непрерывных случайных величин:**
Как в дискретном, так и в непрерывном случае формулы Байеса помогают пересчитать вероятность события при условии каких-нибудь новых данных.
Байес меняет вероятность с учётом факторов, но число факторов может расти бесконечно, поэтому финальной вероятности мы никогда не получим. Несмотря на это, каждая новая вероятность приближает нас к точному значению:
![[Pasted image 20250110173220.png]]


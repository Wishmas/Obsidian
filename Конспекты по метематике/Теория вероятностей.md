## Дискретные случайные величины

**Элементарное событие** - это подмножество пространства исходов случайного эксперимента, которое состоит только из одного элемента.

**Пространство элементарных событий** - множество ${\displaystyle \Omega}$ всех взаимно или попарно исключающих друг друга исходов случайного эксперимента, которые вместе образуют полную группу событий.

**Событие** - произвольное подмножество пространства элементарных событий ${\displaystyle \Omega}$.

Если монета бросается дважды, $\displaystyle \Omega = \{HH, HT, TH, TT\}$, $H$ для орла, а $T$ для решетки, то элементарные события: $\{HH\}, \{HT\}, \{TH\}, \{TT\}$.

**Случайная величина** - это измеримая функция, заданная на каком-либо вероятностном пространстве.

**Пространства элементарных событий** (**исходов**) бывают **конечные**, **счётные** и **несчётные**.<br>
**Конечные** и **счётные** пространства называют **дискретными**. Случайную величину, определённую на таком пространстве, тоже называют **дискретной**.<br>
Случайные величины, определённые на **несчётных** пространствах исходов, называют **непрерывными**.

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241225170941.png)

Каждому элементу пространства исходов функция $X$ присваивает одно из значений $x_1, …, x_n​$. Случайная величина — такая же функция, разница только в том, что аргументы случайной величины — не числа, а объекты из пространства исходов. А значения случайной величины — это обычные числа.

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241225173006.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241225173106.png)<br>
То есть, вероятность, что случайная величина X примет значение x, равна сумме вероятностей исходов, для которых $X(ω)=x$.

**Свойства вероятности:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241225174237.png)

**Распределение случайной величины** - это набор вероятностей, с которыми она принимает те или иные значения:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241225180833.png)<br>
**Многоугольником распределения вероятностей** данной величины называют ломаную, звенья которой соединяют соседние точки $(x_i,p_i)$.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241225181152.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226193148.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226193305.png)<br>
![](../Вложения/Теория%20вероятностей/t42ti1VAYkY.jpg)<br>
![](../Вложения/Теория%20вероятностей/DGclUvgDusU.jpg)

**Математическое ожидание дискретной СВ:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241225182332.png)<br>
Свойства математических ожиданий:<br>
![](../Вложения/Теория%20вероятностей/t1MDShTGxks.jpg)

**Дисперсия дискретной СВ:**<br>
Дисперсия показывает, насколько отклоняется случайная величина от своего среднего значения: чем больше у случайной величины значений, далёких от среднего как в меньшую, так и в большую сторону, тем больше дисперсия.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241225184851.png)<br>
Свойства дисперсии:<br>
![](../Вложения/Теория%20вероятностей/SmV03Hv8-pI.jpg)

Из-за того, что при вычислениях мы возводим значения в квадрат, дисперсия измеряется в единицах в квадрате — в отличие от математического ожидания. Например, если $X$ — это количество рублей, то дисперсия будет в рублях в квадрате.

На практике это решают извлечением корня из дисперсии, чтобы вернуться в размерность $X$. Поэтому часто можно встретить величину $\sqrt{Var(X)}$ — она называется **стандартным отклонением** для случайной величины $X$.

### Распределение Бернулли

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226201044.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226201726.png)<br>
![](../Вложения/Теория%20вероятностей/file-20251104192710893.png)<br>
Распределение Бернулли часто строят для целой совокупности случайных величин. Это позволяет описать серию повторяющихся экспериментов с двумя исходами. Можно комбинировать случайные величины Бернулли вместе, чтобы получать более сложные распределения.

**Биномиальное распределение:**<br>
Возьмем серию из $n$ одинаковых и независимых друг от друга испытаний Бернулли. Вероятность успеха в каждом испытании одинакова и равна $p$, а результат одного испытания не влияет на результат последующих. 

Получается последовательность $\omega=(x_1,x_2,..,x_n)$, где каждый $x_i$ - успех или неудача. Тогда наше вероятностное пространство - это всевозможные последовательности успехов и неудач.

Теперь рассмотрим случайную величину, равную **количеству успехов** в такой серии испытаний. Распределение вероятностей этой случайной величины называется **Биномиальное распределение**.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226205025.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226224020.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226230313.png)

**Геометрическое распределение:**<br>
Пускай эксперимент проводится ровно до тех пор, пока случайная величина не примет интересующее нас значение в первый раз. В этом случае нас будет интересовать номер попытки, при которой «успех» наконец сменит «неуспех» — или наоборот.<br>
Тогда случайная величина, которая возникает при моделировании подобных экспериментов, имеет геометрическое распределение.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226231150.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226231512.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226231821.png)<br>
Следовательно, мы можем построить распределение вероятностей первого успеха в схеме Бернулли на k-ом испытании:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226231924.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241226232453.png)

**Равномерное распределение:**<br>
Иногда вероятности исходов предполагают равными. Например, так делают для простоты или в случае, когда нет другой информации. Для случайной величины также можно рассматривать распределение с равными вероятностями значений.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241227205610.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241227205715.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241227205718.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241227211150.png)

**Распределение Пуассона:**<br>
Если нас интересует количество одинаковых событий, случившихся за определённый отрезок времени, лучше всего подойдет распределение Пуассона. Оно похоже на биномиальное, но здесь нет $n$ попыток — вместо них временной интервал.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241227211813.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241227211902.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241227212326.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241227212333.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241227212339.png)<br>
На иллюстрациях видно, что с увеличением параметра μ вершина распределения смещается вправо, а разброс значений увеличивается.

Теорема Пуассона применяется в случаях, когда $n$ велико, а $p$ наоборот небольшое. Это связано с тем, что для таких случаев использовать биномиальное распределение неудобно - цифры получаются слишком большими. 

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020241227213537.png)

## Совместное распределение

Случайные величины, которые относятся к одному эксперименту, как правило, влияют друг на друга. Чтобы отследить и описать зависимость между такими величинами, нам понадобится совместное распределение.

**Дискретное совместное распределение двух случайных величин**, определённых на одном пространстве исходов, — это закон, который приписывает определённую вероятность каждой паре значений.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102120948.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102120959.png)

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102121357.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102121502.png)

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102121648.png)<br>
То есть, если нам известно только совместное распределение H и G, мы можем вывести из него распределение, например, случайной величины H.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102121815.png)<br>
Чтобы найти частное распределение H, достаточно для каждого возможного значения этой величины просуммировать все значения в строке:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102121841.png)<br>
И вероятность каждого значения H — это сумма вероятностей трёх несовместных событий.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102121908.png)

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102122214.png)

**Независимость случайных величин:**

По совместному распределению двух случайных величин можно установить, влияет ли значение одной на вероятность значения другой.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102122401.png)<br>
Или:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102122609.png)<br>
*Например:*<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102122702.png)

Построить совместное распределение, имея частное, возможно только для независимых случайных величин.

**Математическое ожидание для двух случайных величин:**

Совместное распределение двух случайных величин может помочь в поиске математического ожидания комбинации этих величин. Комбинацией величин может быть их сумма, разность, минимум или максимум из них или другая функция от двух величин.

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102124033.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102124041.png)<br>
То есть, чтобы найти математическое ожидание для функции от нескольких случайных величин, достаточно рассчитать все возможные значения этой функции и суммировать их с учётом вероятностей.<br>
На основе этого правила можно выразить важное свойство математического ожидания:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102124217.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102124333.png)<br>
Это свойство удобно тем, что оно работает как для зависимых, так и для независимых случайных величин.

**Дисперсия суммы случайных величин:**

Используя свойства математического ожидания выше, можно вывести свойство для дисперсии:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102135530.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102135554.png)
 
Для **независимых величин** дисперсия суммы равная сумме дисперсий.

Для **зависимых величин** дисперсию суммы нельзя посчитать как сумму их дисперсий. Вместо этого используют формулу, которая получается из определения:<br>
 ![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102140302.png)<br>
 Получается, чтобы найти дисперсию суммы, надо к сумме дисперсий дважды прибавить дополнительное слагаемое $E[(X−E[X])(Y−E[Y])]$.<br>
 Это слагаемое имеет свое название - **ковариация**.

**Ковариация:**

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102140805.png)<br>
Или:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102144130.png)

Ковариация является мерой связи двух случайных величин. Она может принимать значения $(-\infty,+\infty)$. Важен её знак: она больше, меньше или равна нулю.

**Положительное** значение ковариации говорит вот о чём: если X приняла значение больше среднего, то с большей вероятностью Y примет значение, большее среднего. И наоборот: если X приняла значение меньше $E[X]$, то с большей вероятностью Y примет значение, меньшее $E[Y]$.

**Отрицательная** ковариация означает, что если X примет значение, превышающее математическое ожидание X, то с большей вероятностью значение Y будет ниже среднего. И наоборот: если X примет значение меньше математического ожидания X, то с большей вероятностью значение Y будет выше среднего.

Недостаток ковариации в том, что она сильно зависит от единиц измерения. Эту зависимость в точности описывает следующее правило:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102150915.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102150926.png)<br>
По этой причине, ковариация плохо подходит для оценки силы взаимодействия случайных величин.

**Корреляция:**

Итак, ковариация помогает понять направление связи между двумя случайными величинами, но не подходит для того, чтобы оценить силу этой связи. Поэтому на практике чаще используют другую величину, похожую на ковариацию, — **коэффициент корреляции**.

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102151707.png)<br>
При смене единиц измерения коэффициент корреляции не меняется, потому что, в отличие от ковариации, он является безразмерной характеристикой:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102152741.png)

Коэффициент корреляции принимает значения от −1 до 1, чем выгодно отличается от ковариации. Значения коэффициента ограничены с двух сторон, и поэтому их легче интерпретировать. Поэтому пары случайных величин можно сравнивать не только по направлению их связи, но и по силе этой связи.

На практике значение коэффициента корреляции интерпретируют так:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102153723.png)

$ρ(X, Y)$ принимает максимальное и минимальное значения в случае, когда $Y(ω)=a⋅X(ω)+b$ для любого $ω∈Ω$. Дело в том, что коэффициент отражает силу **линейной связи** между случайными величинами, то есть близость к такому линейному соотношению.

Если же зависимость между случайными величинами задана каким-то более сложным, нелинейным образом, то корреляция будет близка к нулю или равна ему.

Между понятиями независимости и некоррелированности есть важная взаимосвязь:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102160320.png)<br>
Если случайные величины некоррелированные, это не значит, что они не связаны. Между ними всё равно может быть зависимость, просто нелинейная.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250102161358.png)
## Условная вероятность 

**Условная вероятность** - это **вероятность события** A **при условии (наступления) события** B. Ее обозначают $P(A∣B)$.<br>
$P(A∣B)$ — это доля исходов из A в общем количестве B:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103133020.png)<br>
До введения условия мы рассматриваем вероятности событий A и B относительно всего множества исходов Ω. На рисунке это белый квадрат слева. Интересующие нас исходы лежат на пересечении $A∩B$. После того как ввели новое условие, часть исходов можно отбросить — пространство допустимых исходов сузилось до B.<br>
Из этого определения можно вывести формулу:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103133222.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103133302.png)<br>
Условную вероятность для случайной величины X при условии ${Y=y_0​}$ можно записать так:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103133602.png)

Если преобразовать формулу, можно получить **вероятность пересечения** двух событий:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103135919.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103135926.png)<br>
Таким образом, подсчёт вероятности можно разложить на две части:
1) найти вероятность $Y=y$;
2) найти вероятность, что $X=x$ при условии $Y=y$.<br>
Зачастую это проще, чем сразу искать вероятность $X=x∩Y=y$.

Также можно определить условную функцию распределения:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103135237.png)

**Формула полной вероятности:**

**Дерево вероятностей** - это дерево, **вершины** которого отображают события и связаны друг с другом **ветвями**. Корневая, то есть самая левая, вершина отражает событие с вероятностью 1. Остальные вершины показывают, как это событие разбивается на другие, несовместные.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103141216.png)<br>
Связанная с какой-либо вершиной вероятность — это шансы, что событие произойдёт после того, как случилось событие из родительской вершины.<br>
**Сумма вероятностей** на всех рёбрах, исходящих из одной вершины, **всегда равна единице**.

*Например:*<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103141512.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103141516.png)<br>
По дереву вероятностей видно, что событие «Макс успел на автобус» состоит из нескольких частей. Связать их воедино поможет **формула полной вероятности**:

**![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103141610.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103141615.png)<br>
Теорема Байеса:

Теорема позволяет выяснить вероятность события при условии, что произошло связанное с ним другое событие.

Она позволяет рассчитать вероятность события, если причину и следствие поменять местами. Например, мы знаем распространенность симптома среди больных и здоровых. Значит, мы можем вычислить вероятность заболевания от наличия симптома.

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103142638.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103142758.png)<br>
Простая запись:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103143816.png)<br>
Здесь $P(B)$ - полная вероятность события $B$, включающая все возможные условные вероятности, а $P(A)*P(B|A)$ - отдельный интересующий нас случай, являющийся одной из составляющих этой полной вероятности. 

*Например:*<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103150415.png)<br>
Здесь $P(H_1),P(H_2)$ - это **априорные** (оцененные **до** испытания) вероятности, а $P(H_2|A)$ - это **апостериорная** (оцененная **после** испытания) вероятность того же события, пересчитанная в связи «со вновь открывшимися обстоятельствами» – с учётом того факта, что событие $A$ **достоверно произошло**.

**Условное математическое ожидание:**

**Условное матожидание** — это среднее значение случайной величины при выполнении некоторого условия или при реализации какого-то события. В качестве условия тут выступает фиксированное значение случайной величины, которая может быть связана с данной.

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250103151144.png)

## Непрерывные случайные величины

Если рассматривать график функции распределения **дискретной** случайной величины, можно заметить, что он всегда будет иметь ступенчатую форму со скачком между разными дискретными значениями:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250104161401.png)<br>
Если начать уплотнять такой график и постепенно уменьшать разницу между дискретными значениями, размер скачка будет постепенно стремиться к нулю, и график станет похож на график **непрерывной** функции:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250104161549.png)<br>
Тогда функцию распределения можно приравнять к соответствующей непрерывной функции и работать с описываемым распределением не как с дискретным, а как с **непрерывным**.

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250104161811.png)<br>
Для произвольной непрерывной случайной величины $Q$ множество значений функции распределения $FQ(x)$ должно полностью включать интервал $(0, 1)$ и при этом быть непрерывным.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250104162131.png)

Идея такая — то, что выглядит непрерывным, можно считать непрерывным. Пробег машины, концентрация, рост — эти величины интуитивно кажутся непрерывными. Множество возможных исходов здесь зависит только от точности приборов или наших знаний о мире. Конечно, замена многоступенчатой функции на непрерывный аналог приводит к ошибке. Но эта ошибка настолько мала, что в реальных задачах практически незаметна.

**Функция распределения непрерывной СВ:**

Функция распределения для непрерывной случайной величины задаётся так же, как и для дискретной. По определению:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250104163050.png)<br>
**Свойства** функции распределения непрерывной СВ:
1. ![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250104163336.png)         ![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250104163356.png)
2. $F_X​(x)$ ограничена нулём снизу и единицей сверху;
3. $F_X​(x)$ — неубывающая функция;
4. $F_X​(x)$ является непрерывной функцией на всей прямой тогда и только тогда, когда случайная величина непрерывна. Это значит, что:
	- У непрерывной случайной величины функция распределения непрерывна;
	- Если функция распределения непрерывна, то и соответствующая ей случайная величина тоже непрерывна.
	
Если функция не удовлетворяет хотя бы одному из этих свойств, то она не может быть функцией распределения непрерывной случайной величины.

**Функция плотности распределения:**

**Функция плотности распределения** - это аналог функции вероятности дискретных случайных величин для непрерывных случайных величин. Эта функция тоже показывает, сколько вероятности собрано в точке (или в исходе, соответствующем этой точке), но делает это немного другим способом:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107121217.png)<br>
Иначе говоря, $F_X(x)$ является первообразной для $f_X(x)$.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107121552.png)<br>
В этой формуле используется x в качестве верхнего предела для того, чтобы из всего множества первообразных, которые мы могли получить с помощью этого интеграла, оставить только одну.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107122721.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107123223.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107123254.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107124525.png)<br>
*Следовательно:*<br>
Вероятность того, что непрерывная случайная величина попадёт в интервал, не зависит от того, включены ли границы в этот интервал или нет. Граница интервала — это одна точка, вероятность того, что случайная величина примет именно это значение, равна нулю.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107124714.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107124852.png)<br>
Получается, значение функции плотности $f_X​(x_0​)$ **прямо пропорционально** вероятности попадания значения $X$ в достаточно малую окрестность точки $x_0$. Функция плотности не показывает напрямую вероятность того, что случайная величина приняла конкретное значение. Но тем не менее с её помощью сравнивают вероятности различных значений с оговоркой, что речь идёт не о конкретных значениях, а о достаточно малых областях вокруг них.

Сформулируем в общем виде:
- Если нужно вычислить вероятность попадания случайной величины в **интервал**, то пригодится **функция распределения**.
- Если нужно вычислить вероятность в точке (если точнее, в **бесконечно малой области вокруг точки**), то поможет функция **плотности распределения**.

**Математическое ожидание и дисперсия непрерывных СВ:**

Если случайная величина X непрерывная, то её **математическое ожидание** вычисляют с помощью функции плотности:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107134357.png)

Определения **дисперсии** без изменений переносятся и на непрерывные случайные величины. Если расписать их через интеграл плотности, получится формула дисперсии для непрерывных случайных величин:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107141059.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250107141143.png)<br>
Обычно если $f(x)$ — простая функция, то используют первую. А если $f(x)$ является довольно сложной функцией, то удобнее вторая формула.

### Непрерывное равномерное распределение

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108115839.png)<br>
*Например:*<br>
10-метровый провод повреждён, но в какой именно точке — неизвестно. Видно, что на первых двух метрах всё в порядке, как и на последних трёх. А оставшаяся, средняя часть провода скрыта за плинтусом.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108115951.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108115955.png)

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108120134.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108120238.png)

**Функция распределения непрерывной равномерной СВ:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108120942.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108121036.png)<br>
**Математическое ожидание и дисперсия непрерывно распределенной равномерной величины:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108132748.png)

### Экспоненциальное распределение

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108123344.png)<br>
В этом распределении параметром является величина $λ$. Именно она отвечает за то, как будет выглядеть данное распределение:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108123525.png)<br>
Параметр $λ$ определяет начальную точку на оси $Y$, из которой выходит график функции плотности распределения, а также скорость уменьшения значения функции. Чем больше $λ$, тем выше начальная точка на оси $Y$, но и тем быстрее уменьшается значение функции.

**Функция распределения экспоненциально распределённой величины:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108123810.png)<br>
**Математическое ожидание и дисперсия экспоненциально распределённой величины:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108130258.png)<br>
Выводятся из общей формулы путем интегрирования.

**Применение:**<br>
Чаще всего экспоненциальным распределением описывают различные процессы, непрерывные во времени, но с которыми рано или поздно должно что-то случиться. Это может быть горение лампочки (спойлер: она перегорит) или распад атома (спойлер: он распадётся).

### Нормальное распределение

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108134209.png)<br>
График плотности нормального распределения выглядит как колокол. Значения по центру колокола наиболее вероятные, а при отдалении от центра влево или вправо вероятность уменьшается с одинаковой скоростью в обе стороны, но при этом всюду отлична от нуля:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108134914.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108134950.png)

**Функция распределения нормального распределения:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108135341.png)<br>
Этот интеграл не берется стандартными способами, однако его значение можно вычислять приближенно.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108135603.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108135618.png)

**Математическое ожидание и дисперсия нормально распределенной величины:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108140111.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108140117.png)<br>
Получается, что математическое ожидание нормального распределения равно $μ$, а дисперсия равна $σ^2$. Именно эти величины являются параметрами. 

**Стандартное нормальное распределение:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108140637.png)<br>
Из формулы в определении следует, что:

$\large E(X)=0$

$\large Var[X]=1$

Стандартное нормальное распределение используют в случаях, когда нужно **избавиться от размерности** исходной случайной величины:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108140913.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250108141002.png)<br>
Переход, который приводит случайные нормальные величины с произвольными значениями параметров к одному стандартному виду, называется **стандартизацией**.

### Совместное распределение непрерывных случайных величин

Совместная функция распределения непрерывных величин выглядит так же, как она выглядит для дискретных:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109180359.png)<br>
Функция совместного распределения двух случайных величин обладает несколькими свойствами:
* Функция распределения $F(x, y)$ есть неубывающая функция от обоих своих аргументов:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109180744.png)
* Если $x$ **или** $y$ обращаются в $−∞$, то функция распределения равна нулю:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109180844.png)
* Если $x$ **и** $y$ обращаются в $+∞$, то функция распределения равна единице:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109180948.png)

### Функция плотности совместного распределения:

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109190631.png)<br>
Для наличия производной необходимо, чтобы функция была непрерывная. А значит, в этом случае $F_{X,Y}(x, y)$ вынуждена быть непрерывной.

**Функция совместной плотности** — это функция двух переменных, её график трёхмерный. Получается, она показывает, какая часть вероятности сосредоточена в бесконечно малом квадрате вокруг конкретной точки.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109192222.png)

**Свойства функции плотности совместного распределения:**
* Совместная плотность распределения является всюду неотрицательной функцией.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109192442.png)
* **Объём** под поверхностью функции плотности совместного распределения равен 1.<br>
Чтобы вычислить **объем** под поверхностью объемной фигуры, используют **двойные интегралы**:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109192714.png)<br>
Двойной интеграл часто означает, что сначала происходит интегрирование по одной переменной в некотором интервале, а потом — по обновлённой функции в некотором интервале.<br>
Пока мы интегрируем по одной переменной, нужно считать другие константами и не обращать на них внимания.<br>
Последовательность интегрирования не влияет на результат: можно интегрировать в том порядке, какой больше нравится.

*Например:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109192848.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109192906.png)

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109193515.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109193520.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109193528.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109193534.png)

* Двойной интеграл в бесконечных пределах плотности совместного распределения двух непрерывных случайных величин равен 1:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109194234.png)

![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109194427.png)

**Плотность распределения каждой компоненты совместного распределения:**<br>
Польза плотности совместного распределения заключается в том, что по её функции $f_{X,Y}(x,y)$ можно найти плотность распределения каждой величины $X$ и $Y$ по отдельности: $f_X(x)$, $f_Y(y)$.

Если $f_{X,Y}(x,y)$ является плотностью совместного распределения случайных величин $X$ и $Y$, то:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109194837.png)

**Независимость непрерывных случайных величин:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109195840.png)<br>
Или:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109195851.png)

**Ковариация двух непрерывных случайных величин:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109201802.png)<br>
Свойства ковариации непрерывных величин не отличаются от тех, что были в дискретном случае:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109201933.png)

**Корреляция двух непрерывных случайных величин:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109205253.png)<br>
Свойства:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250109205319.png)

### Условная вероятность для непрерывных случайных величин

Формула для дискретных случайных величин:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250110140527.png)<br>
Аналог для непрерывных случайных величин:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250110140611.png)<br>
Иными словами, если нам известно совместное распределение $X$ и $Y$ и какое-то конкретное значение $y$ случайной величины $Y$, то по формуле можно найти плотность распределения $X$ при условии, что событие $Y=y$ уже случилось.

*Например:*<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250110141738.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250110141749.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250110141802.png)<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250110141807.png)

**Условное математическое ожидание:**<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250110143008.png)

**Формула полной вероятности:**<br>
Как и в случае с дискретными случайными величинами формула полной вероятности позволяет вычислить вероятность события $A$, когда известны его вероятности при условии выполнения события $B$. То есть, зная все условные вероятности события $A$, можно вычислить безусловную вероятность $A$.<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250110144932.png)

**Формула Байеса для непрерывных случайных величин:**<br>
Как в дискретном, так и в непрерывном случае формулы Байеса помогают пересчитать вероятность события при условии каких-нибудь новых данных.<br>
Байес меняет вероятность с учётом факторов, но число факторов может расти бесконечно, поэтому финальной вероятности мы никогда не получим. Несмотря на это, каждая новая вероятность приближает нас к точному значению:<br>
![](../Вложения/Теория%20вероятностей/Pasted%20image%2020250110173220.png)


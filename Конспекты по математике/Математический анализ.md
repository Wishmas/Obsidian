## Функции и их свойства

**Многозначное отображение** множества _A_ во множество _B_ — это правило, по которому каждому элементу множества _A_ ставится в соответствие элемент (или элементы) множества _B_.

**Однозначное отображение** (или просто **отображение**) — если в соответствие каждому элементу первого множества ставят единственный элемент второго.

**Функция** — это отображение одного множества в другое, где каждому элементу первого множества соответствует только один элемент второго.<br>
![](../Вложения/Математический%20анализ/file-20251104201707070.png)<br>
Функция является однозначным отображением множества _X_ в _Y_, но не из _Y_ в _X_.<br>
![](../Вложения/Математический%20анализ/file-20251104201707069%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707069.png)

**Функция как зависимость переменных:**<br>
![](../Вложения/Математический%20анализ/file-20251104201707068%202.png)<br>
Обозначается как $y=f(x)$ или просто $y(x)$.<br>
![](../Вложения/Математический%20анализ/file-20251104201707068%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707068.png)<br>
**Чтобы построить график функции, нужно:**
1. Выбрать любое значение аргумента $x_1∈X$..
2. Подставить его в формулу $y=f(x)$ и получить значение функции $y_1$​ для этого аргумента.
3. Отметить точку с координатами $(x1, y1)$ на плоскости.
4. Повторить для всех остальных $x∈X$.

**Область определения функции:**<br>
![](../Вложения/Математический%20анализ/file-20251104201707067%201.png)<br>
**Множество значений функции:**<br>
![](../Вложения/Математический%20анализ/file-20251104201707067.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707066%202.png)

![](../Вложения/Математический%20анализ/file-20251104201707066%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707066.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707065%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707065.png)<br>
**Важный момент:** Если функция задана на ограниченных промежутках, то и знаки производной тоже определяют только на них.<br>
Экстремальные точки всегда принадлежат области определения функции. Если точка не входит в область определения, то она не может быть экстремальной.<br>
![](../Вложения/Математический%20анализ/file-20251104201707064%202.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707064%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707064.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707063%201.png)<br>
Экстремумов у функции может быть сколько угодно, а вот наибольшего и наименьшего значений — всегда по одной штуке (если они есть, конечно).

Кандидаты на звание наибольшего или наименьшего значения функции: экстремумы и значения, которые достигаются в крайних точках промежутка, на котором задана функция.

![](../Вложения/Математический%20анализ/file-20251104201707063.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707062.png)<br>
Иногда вместо «выпуклая вверх» говорят просто «**выпуклая**», а вместо «выпуклая вниз» говорят «**вогнутая**».<br>
![](../Вложения/Математический%20анализ/file-20251104201707061%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707061.png)

![](../Вложения/Математический%20анализ/file-20251104201707060%202.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707060%201.png)<br>
Точка, в которой вторая производная равна нулю, окажется точкой перегиба, только если при переходе через неё поменялся знак второй производной и, как следствие, тип выпуклости.

![](../Вложения/Математический%20анализ/file-20251104201707060.png)<br>
Чётность и нечётность видны и на графиках функций — они имеют симметрию.<br>
График **чётной функции** симметричен относительно оси $Oy$. График **нечётной** — симметричен относительно начала координат.

Функция называется **непрерывной** на промежутке, если её график на этом промежутке можно построить, не отрывая руки, одним движением.<br>
![](../Вложения/Математический%20анализ/file-20251104201707059%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707059.png)

**Обратная функция:**<br>
![](../Вложения/Математический%20анализ/file-20251104201707058%201.png)<br>
Во многих математических текстах обратную к _f_ функцию обозначают как $f^{−1}$.<br>
*Например:*<br>
![](../Вложения/Математический%20анализ/file-20251104201707058.png)

![](../Вложения/Математический%20анализ/file-20251104201707057%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707057.png)<br>
Действия, которые можно совершать с правыми частями функций:
- прибавлять и вычитать одинаковые числа,
- умножать и делить на одинаковые ненулевые числа,
- возводить правые части функций в одинаковую степень,
- извлекать корни одинаковой нечётной степени,
- брать одинаковый логарифм от обеих частей,
- превращать функции в показатели.<br>
*Например:*<br>
![](../Вложения/Математический%20анализ/file-20251104201707056%202.png)<br>
Графики двух взаимно обратных функций симметричны относительно прямой $y=x$:<br>
![](../Вложения/Математический%20анализ/file-20251104201707056%201.png)

### Линейная функция
![](../Вложения/Математический%20анализ/file-20251104201707056.png)<br>
При разных значениях _k_ линейная функция ведёт себя по-разному:
- при $k=0$ — функция постоянна, прямая параллельна оси $O_x$
- при $k>0$ — функция возрастает, при $k<0$ — убывает,
- при $k=1$ — переменные $y$ и $x$ растут с одинаковой скоростью, прямая проходит под углом $45°$
- при $k>1$ — прямая круто идёт вверх, то есть $y$ растёт быстрее, чем $x$. И, наоборот, при $0<k<1$ прямая более пологая, так как $x$ растёт быстрее $y$.

![](../Вложения/Математический%20анализ/file-20251104201707055%201.png)<br>
Чтобы объединить одной формулой графики всех прямых (в том числе вертикальных), используют термин «линейное уравнение»:<br>
![](../Вложения/Математический%20анализ/file-20251104201707055.png)<br>
Когда $b≠0$, зависимость будет даже функциональной. В этом случае принято выражать переменную $y$, чтобы получалась привычная запись вида $y=f(x)$. Если же $b=0$, то получается уравнение, графиком которого является вертикальная прямая. Эта зависимость не будет функциональной.

Чтобы задать линейную функцию, достаточно **двух точек**, через которые проходит её график.
### Полиномиальная функция
Все функции, которые в правой части содержат многочлен (полином) степени 2 и выше, называют **полиномиальными**.

![](../Вложения/Математический%20анализ/file-20251104201707054%201.png)
* Коэффициент _a_ отвечает за ширину и направление ветвей .
* Коэффициент _c_ отвечает за вертикальный сдвиг параболы:<br>
График квадратичной функции называют **параболой**.<br>
![](../Вложения/Математический%20анализ/file-20251104201707054.png)<br>
У параболы есть ветви и вершина.<br>
**Ветвь** — это участок графика, где функция либо только возрастает, либо только убывает.<br>
**Вершина** параболы — точка, в которой одна ветвь параболы меняется на другую.<br>
Координаты вершины параболы можно найти по формуле:<br>
![](../Вложения/Математический%20анализ/file-20251104201707053%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707053.png)<br>
Чтобы задать параболу, необходимо знать **три точки**.

**Полиномиальная функция в общем виде:**<br>
![](../Вложения/Математический%20анализ/file-20251104201707052.png)<br>
Если в правой части функции стоит некий многочлен степени _n_, то для однозначного задания этой функции достаточно $n+1$ точки.<br>
**Свойства полиномиальных функций:**<br>
![](../Вложения/Математический%20анализ/file-20251104201707051%201.png)

### Описание данных при помощи функций

**Интерполянт** — функция, график которой проходит через все заданные точки.<br>
**Интерполяционный многочлен** — многочлен минимальной степени, построенный по значениям в данных точках.<br>
![](../Вложения/Математический%20анализ/file-20251104201707051.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707050%201.png)

**Решение в среднем** — приближённое решение, которое передаёт общий характер изменения данных. Не обязательно проходит через все данные точки.<br>
Для одной исходной функции может быть много приближённых решений — как интерполяционных, так и в среднем.<br>
![](../Вложения/Математический%20анализ/file-20251104201707050.png)![](../Вложения/Математический%20анализ/file-20251104201707049%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707049.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707048%201.png)<br>
Чтобы оценить качество приближения, смотрят, как далеко от каждой из точек проходит предсказанная кривая, и считают **среднее значение таких отклонений**. Но одной оценки отклонения недостаточно. Многочлен высокой степени может проходить через все точки и давать нулевое отклонение. При этом он не будет хорошим приближением, потому что на новых точках ошибка будет большой. Иными словами, такой многочлен хорошо **описывает данные**, но плохо **предсказывает изменения**.

Эту проблему обычно решают так: случайными образом разбивают набор точек на две части. По одной находят коэффициенты многочлена, по второй считают его ошибку. То есть строят интерполянт по первому набору и оценивают его ошибку по второму. Так подбирают многочлен, который наиболее точно описывает и предсказывает данные.<br>
![](../Вложения/Математический%20анализ/file-20251104201707048.png)

### Показательная функция

Свойства степеней:<br>
![](../Вложения/Математический%20анализ/file-20251104201707047%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707047.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707046%202.png)

![](../Вложения/Математический%20анализ/file-20251104201707046%201.png)<br>
_X_ здесь может быть любым **действительным** числом.<br>
**Областью определения** являются все действительные числа, а **множество значений** содержит только положительные: слева график будет стремиться к оси $O_x$, но никогда её не достигнет.<br>
![](../Вложения/Математический%20анализ/file-20251104201707046.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707045%201.png)<br>
Все показательные функции с основанием $a>1$ будут иметь примерно такой же вид: медленно разгоняться на отрицательных аргументах, а потом на положительных аргументах стремительно взлетать вверх.<br>
![](../Вложения/Математический%20анализ/file-20251104201707045.png)<br>
Если взять обратное значение $b=1/a$, тогда $0<b<1$ и график будет симметричен предыдущему относительно оси $O_y$.

![](../Вложения/Математический%20анализ/file-20251104201707044%201.png)<br>
**Скорость роста любой экспоненциальной функции больше скорости роста любой линейной или полиномиальной функции.**

### Логарифм и логарифмическая функция
![](../Вложения/Математический%20анализ/file-20251104201707044.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707043%201.png)<br>
**Свойства логарифма:**
* На логарифмы накладывается ограничение $a, b>0$. При неположительных значениях $a$ и $b$, а также при $a=1$ значение логарифма не определено.
* Сумма логарифмов равна логарифму произведения:<br>
![](../Вложения/Математический%20анализ/file-20251104201707043.png)
 * Разность логарифмов равна логарифму частного:<br>
![](../Вложения/Математический%20анализ/file-20251104201707042%201.png)
* Формула перехода к новому основанию:<br>
![](../Вложения/Математический%20анализ/file-20251104201707042.png)
* Вынос степеней из логарифма:<br>
![](../Вложения/Математический%20анализ/file-20251104201707041%201.png)<br>
 ![](../Вложения/Математический%20анализ/file-20251104201707041.png)
 
![](../Вложения/Математический%20анализ/file-20251104201707040.png)

**Логарифмическая функция:**<br>
![](../Вложения/Математический%20анализ/file-20251104201707039%201.png)<br>
Функция является возрастающей при $a>1$ и убывающей при $0<a<1$.<br>
![](../Вложения/Математический%20анализ/file-20251104201707039.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707038%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707038.png)

**Логарифмическая шкала:**<br>
Это шкала, длина отрезка которой пропорциональна логарифму отношения величин, отмеченных на концах этого отрезка, в то время как на шкале в линейном масштабе длина отрезка пропорциональна разности величин на его концах.<br>
![](../Вложения/Математический%20анализ/file-20251104201707037%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707037.png)![](../Вложения/Математический%20анализ/file-20251104201707036%201.png)<br>
Если линейная шкала отражала абсолютную разницу значений (на _x_ больше), то логарифмическая отражает относительную (в _x_ раз больше).<br>
![](../Вложения/Математический%20анализ/file-20251104201707036.png)<br>
Бывают задачи, при решении которых логарифм применяют и к самим данным — скажем, предсказание величин в социологии или биологии.<br>
Модели предсказания часто нелинейны, а с нелинейностью работать трудно, да и качество предсказаний получается невысоким. А вот если применить к данным логарифм, то модели могут стать линейными. Таким образом, получается, что предсказывают логарифм величины, а к самой величине переходят уже с помощью показательной функции.

### Кусочная функция
![](../Вложения/Математический%20анализ/file-20251104201707035.png)<br>
*Пример кусочной функции из трёх фрагментов:*<br>
![](../Вложения/Математический%20анализ/file-20251104201707034%201.png)

![](../Вложения/Математический%20анализ/file-20251104201707034.png)

Кусочная функция может быть непрерывной, а может иметь **точки разрыва**.<br>
**Точки разрыва** бывают:
* **Первого рода**:
	* Точка устранимого разрыва (выколотые точки)![](../Вложения/Математический%20анализ/file-20251104201707033.png)
	* Скачок ![](../Вложения/Математический%20анализ/file-20251104201707032%202.png)
* **Второго рода:**![](../Вложения/Математический%20анализ/file-20251104201707032%201.png)<br>
	Например, здесь будут случаи, когда график функции имеет в данной точке вертикальную асимптоту.<br>
	Чтобы точка разрыва была второго рода, достаточно, чтобы хотя бы один из односторонних пределов был бесконечным или не существовал.
	
**Модуль числа:**<br>
![](../Вложения/Математический%20анализ/file-20251104201707032.png)<br>
**Построение графика функции вида $y=∣f(x)∣$:**
1. Строим график функции без модуля
2. Симметрично отображаем наверх ту часть графика, что оказалась ниже оси $O_x$
3. Стираем то, что было ниже оси $O_x$.<br>
![](../Вложения/Математический%20анализ/file-20251104201707031%201.png)

**Построение графика функции вида $y=f(∣x∣)$:**
1. Строим график функции без модуля, то есть $y=f(x)$.
2. Стираем то, что было левее оси $O_y$.
3. Симметрично отображаем налево ту часть графика, что была правее оси $Oy$.<br>
![](../Вложения/Математический%20анализ/file-20251104201707031.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707030%201.png)

### Композиция функций 
![](../Вложения/Математический%20анализ/file-20251104201707030.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707029.png)<br>
Примеры композиций:<br>
![](../Вложения/Математический%20анализ/file-20251104201707028%201.png)<br>
Любая функция, в которой выполняется больше одного действия, — по сути своей композиция более простых функций. Например, функция $y=2+log_5{x}$ — это композиция функций $f(x)=log_5{x}$ и $g(x)=2+x$<br>
![](../Вложения/Математический%20анализ/file-20251104201707028.png)<br>
Если в композиции три и более функций, то порядок действий идёт изнутри наружу.<br>
![](../Вложения/Математический%20анализ/file-20251104201707027%201.png)<br>
Самых популярных «фильтров», которые применяются к функциям, три, и они простые:
- Умножение всей функции на число,
- Прибавление числа к функции,
- Прибавление числа к аргументу функции.<br>
Порядок выполнения обычно такой:
1. Сдвиг вдоль оси $Ox$.
2. Умножение на коэффициент.
3. Сдвиг вдоль оси $Oy$.<br>
![](../Вложения/Математический%20анализ/file-20251104201707027.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707026%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707026.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707025%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707025.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707024.png)
### Анализ функции

Анализировать функцию мы будем, добывая данные по следующему списку:

1) Область определения функции.

2) Асимптоты: вертикальные и горизонтальные.

3) Промежутки монотонности и экстремумы.

4) Наибольшее и наименьшее значения.

5) Выпуклость и точки перегиба.

Иногда уже на этом этапе можно построить график. Если данных не хватает, то можно исследовать функцию дополнительно:

6) Точки пересечения с осями координат. Если их найти сложно, то этот пункт пропускают.

7) Множество значений функции.

8) Если данных всё ещё недостаточно, составляют таблицу значений функции в дополнительных точках.

## Пределы
![](../Вложения/Математический%20анализ/file-20251104201707023%201.png)<br>
Значение _L_ может быть **конечным** (то есть числом), **бесконечным**, а может **не существовать** вообще.<br>
![](../Вложения/Математический%20анализ/file-20251104201707023.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707022%201.png)

**Рациональная функция:**<br>
![](../Вложения/Математический%20анализ/file-20251104201707022.png)<br>
*Например:*<br>
$\Large y=\frac{4x^2-2x-12}{10x+15}​$<br>
**Область определения** рациональных функций — все числа, за исключением тех, в которых знаменатель обращается в ноль.

Такие точки называют **точками устранимого разрыва**, потому что в них на графике есть разрыв, но его можно устранить.<br>
![](../Вложения/Математический%20анализ/file-20251104201707021.png)

Предел рациональной функции в любой точке из её области определения совпадает с самим значением функции в этой точке.<br>
Предел рациональной функции в точках, в которых она не определена, существует и может быть конечным или бесконечным.

Чтобы вычислить такой предел, нужно **избавиться от всех неопределенностей** в выражении, подставить туда искомые точки и найти предел.<br>
![](../Вложения/Математический%20анализ/file-20251104201707020%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201707020.png)

Предел может быть **бесконечным**. В этом случае, при приближении к точке $x_0$ функция стремится к бесконечности, а в этой точке образуется **вертикальная асимптота**.<br>
![](../Вложения/Математический%20анализ/file-20251104201707019.png)<br>
$\Large\lim_{x \to 0} \frac{1}{x}=\infty$ 

![](../Вложения/Математический%20анализ/file-20251104201707018.png)<br>
Вертикальная асимптота возникает, когда при подстановке числа в функцию возникает неопределенность вида $\frac{m}{0},m\neq0$

Если график функции на вертикальной асимптоте уходит только вверх или только вниз, предел указывают четко как $\infty$ или $-\infty$.<br>
![](../Вложения/Математический%20анализ/file-20251104201707017.png)<br>
Альтернативный вариант преодолеть неопределенность вида $\frac{0}{0}$ - **домножить** и числитель, и знаменатель **на сопряженное выражение** или **вынести числовые множители за знак предела**. 

Если при решении появляется неопределенность вида $\infty/\infty$, нужно выбрать **выбрать из числителя и знаменателя _x_ в самой старшей степени и разделить** на него обе части дроби.<br>
![](../Вложения/Математический%20анализ/file-20251104201706992.png)

![](../Вложения/Математический%20анализ/file-20251104201706989.png)<br>
Если у функции на бесконечности конечный числовой предел _L_, то прямая $y=L$ является его **горизонтальной асимптотой**. График функции будет стремиться к этой прямой, но никогда её не достигнет.

Чтобы посчитать предел дробно-рациональной функции на бесконечности, нужно **в числителе и знаменателе дроби оставить только старшие степени** с их коэффициентами, а остальное отбросить.

**Арифметические действия с бесконечностью при вычислении пределов:**<br>
![](../Вложения/Математический%20анализ/file-20251104201706988%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706988.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706987%201.png)
## Производные
![](../Вложения/Математический%20анализ/file-20251104201706987.png)<br>
Если производная **положительна** $(f′(x0)>0)$ — функция **возрастает** в точке x0​.<br>
Если производная **отрицательна** $(f′(x0)<0)$ — функция **убывает** в точке x0.<br>
Точки, в которых производная **равна нулю** - это **локальные минимумы и максимумы** функции.<br>
Чем быстрее растёт или убывает функция, тем больше модуль её производной.

**Касательная:**<br>
![](../Вложения/Математический%20анализ/file-20251104201706986%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706986.png)<br>
К графику можно провести много касательных: в каждой точке — своя единственная (то есть в одной точке невозможны две разные касательные).

По определению угловой коэффициент касательной равен значению производной в точке. Получается, чем круче наклон касательной в точке, тем быстрее в этой точке растёт или убывает функция, а значит, больше модуль значения производной.

![](../Вложения/Математический%20анализ/file-20251104201706985.png)<br>
$\largeΔx=x−x_0, ​x=x_0+Δx$<br>
![](../Вложения/Математический%20анализ/file-20251104201706984.png)<br>
**Угловой коэффициент** - отношение приращения функции к приращению аргумента.<br>
![](../Вложения/Математический%20анализ/file-20251104201706983%201.png)<br>
Если мы будем уменьшать приращение аргумента, то будет уменьшаться и приращение функции. Чем меньше приращение, тем больше кривая в точке похожа на свою касательную и тем ближе её мгновенная скорость к скорости роста прямой.<br>
Это можно записать с помощью предела:<br>
![](../Вложения/Математический%20анализ/file-20251104201706983.png)<br>
Так как скорость роста касательной прямой равна её угловому коэффициенту $k$ (который, в свою очередь, равен тангенсу угла наклона прямой к горизонтальной оси), то можно сказать, что $f′(x_0)=k=tg⁡α$.

Чтобы найти производную по определению, нужно посчитать этот предел, учитывая, что:<br>
![](../Вложения/Математический%20анализ/file-20251104201706982%201.png)<br>
*Например:*<br>
$\large y=x^2$<br>
![](../Вложения/Математический%20анализ/file-20251104201706982.png)

Вычисление производной функции называется **дифференцированием**.<br>
![](../Вложения/Математический%20анализ/file-20251104201706981.png)![](../Вложения/Математический%20анализ/file-20251104201706980%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706980.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706979.png)

![](../Вложения/Математический%20анализ/file-20251104201706954.png)<br>
Физический смысл второй производной — это скорость изменения скорости, то есть ускорение функции.<br>
Можно считать производные и более высоких порядков: третьего, четвёртого и так далее. Для третьего всё ещё используют обозначения со штрихами: $f^{′′′}(x)$. А вот для четвёртого и далее вместо штрихов пишут число в скобках арабскими или римскими цифрами: $f^{(4)}(x)$. Скобки показывают, что цифра — это не степень, а порядок производной.

## Интеграл

**Первообразная:**<br>
![](../Вложения/Математический%20анализ/file-20251104201706953%201.png)<br>
Следовательно, интегральное исчисление решает задачу нахождения исходной функции по ее производной.<br>
![](../Вложения/Математический%20анализ/file-20251104201706953.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706952.png)<br>
$f(x)$  — **подынтегральная функция**<br>
$dx$ — **дифференциал** аргумента (показывает, по какой переменой будет идти интегрирование)<br>
$f(x)dx$ —  **подынтегральное выражение**<br>
_С_ — **константа**<br>
Воспринимать дифференциал стоит как формальный множитель. Если он идёт после дроби, его можно записать в числитель.

![](../Вложения/Математический%20анализ/file-20251104201706951.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706950.png)<br>
В некотором роде данная таблица интегралов — это таблица производных, у которой поменяли столбцы «до» и «после».<br>
![](../Вложения/Математический%20анализ/file-20251104201706948%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706948.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706947%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706947.png)

**Свойства неопределенного интеграла:**
* Интеграл суммы/разности равен сумме/разности интегралов:<br>
![](../Вложения/Математический%20анализ/file-20251104201706946%201.png)
* Числовой множитель в интеграле можно вынести:<br>
![](../Вложения/Математический%20анализ/file-20251104201706946.png)

**Метод интегрирования по частям:**<br>
Пусть даны две функции, зависящие от одной и той же переменной: $u(x)$ и $v(x)$. Для краткости будем обозначать их просто $u$ и $v$. Тогда:<br>
![](../Вложения/Математический%20анализ/file-20251104201706945%201.png)<br>
Или:<br>
![](../Вложения/Математический%20анализ/file-20251104201706945.png)<br>
Формула позволяет интегрировать произведение такого вида, где вторая функция является чьей-то «хорошей» производной:
* **Логарифм**, умноженный на **многочлен**
* **Экспоненциальная** (показательная) функция, умноженная на **многочлен**
* **Тригонометрическая** (или **обратная тригонометрическая**) функция, умноженная на **многочлен**
* **Экспоненциальная** (показательная) функция, умноженная на **тригонометрическую**

В качестве $u$ выбирается функция, которая упрощается **дифференцированием**, а в качестве $dv$ - оставшаяся часть подынтегрального выражения, из которой можно выразить $v$ путем **интегрирования**.<br>
![](../Вложения/Математический%20анализ/file-20251104201706944.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706943%201.png)<br>
Если под интегралом стоят многочлен и логарифм, то за u принимается логарифм.

*Например:*<br>
![](../Вложения/Математический%20анализ/file-20251104201706943.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706942.png)<br>
**Для определенных интегралов формула сохраняется:**<br>
![](../Вложения/Математический%20анализ/file-20251104201706941.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706941.jpg)<br>
![](../Вложения/Математический%20анализ/file-20251104201706940.jpg)

**Интегрирование методом замены переменной:**<br>
![](../Вложения/Математический%20анализ/file-20251104201706939%201.png)
1. **Занесение переменной под знак дифференциала:**<br>
	Если аргументом табличной функции в подынтегральном выражении является какая-то сложная функция, можно занести ее под знак дифференциала, а затем применять стандартные табличные операции.<br>
	![](../Вложения/Математический%20анализ/file-20251104201706939.png)<br>
	![](../Вложения/Математический%20анализ/file-20251104201706938.png)<br>
	Соответственно, новый дифференциал будет равен производной сложного выражения, умноженной на старый дифференциал.<br>
	2. **Замена переменной:**<br>
		Заменяем сложную функцию одной буквой, выражаем все выражение через эту букву (включая дифференциал), применяем табличные преобразования и делаем обратную замену.<br>
		Применяется, когда в подынтегральном выражении одновременно находится некая функция g(x) и ее производная.<br>
		В таком случае, за t обозначается сама функция g(x), а не ее производная.<br>
		![](../Вложения/Математический%20анализ/file-20251104201706937.jpg)
	
	Замена переменных помогает считать и определённые интегралы. Но здесь есть важный момент:
	* Если замена переменных явная, то есть мы меняем буквы, то меняются и пределы интегрирования.
	* Если же замена переменных неявная, то есть мы остаёмся с той же буквой, то пределы интегрирования остаются прежними.<br>
	![](../Вложения/Математический%20анализ/file-20251104201706937.png)
	
Если в ходе интегрирования вам в правой части снова встретился исходный интеграл (возможно, с коэффициентом), то записывайте оба через I. Получится несложное уравнение, выразите из него I — так вы найдёте исходный интеграл.<br>
*Например:*<br>
![](../Вложения/Математический%20анализ/file-20251104201706936%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706936.png)<br>
Выражаем I:<br>
![](../Вложения/Математический%20анализ/file-20251104201706935.png)
### Определенный интеграл
Допустим, дана функция зависимости скорости y от времени x:<br>
![](../Вложения/Математический%20анализ/file-20251104201706934%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706934.png)<br>
Если мы хотим узнать длину тормозного пути (скорость * время), нам нужно найти площадь фигуры под графиком.<br>
Мы можем приблизить эту площадь, если будем делить фигуру на прямоугольники равного размера:<br>
![](../Вложения/Математический%20анализ/file-20251104201706933.png)<br>
Чем меньше будет $Δx$, тем более точным будет приближение:<br>
![](../Вложения/Математический%20анализ/file-20251104201706932%201.png)

**Формальное определение:**<br>
Возьмем отрезок $[a,b]$, на котором определена функция $y=f(x)$, и разобьем его на n частей точками $a=x_0 < x_1 < ... < x_{n-1} < x_n=b$<br>
![](../Вложения/Математический%20анализ/file-20251104201706932.png)<br>
Длину каждого отрезка обозначим как $Δx_i​=x_i​−x_{i−1​}$<br>
На каждом отрезке выберем произвольную точку $c_i$ и вычислим в ней значение функции $f(c_i)$<br>
![](../Вложения/Математический%20анализ/file-20251104201706931.png)<br>
Тогда произведение $f(c_i)⋅Δx_i$​ — это площадь такого маленького прямоугольника:<br>
![](../Вложения/Математический%20анализ/file-20251104201706930%201.png)<br>
Сумма всех таких значений называется интегральной суммой:<br>
![](../Вложения/Математический%20анализ/file-20251104201706930.png)<br>
Если устремить количество отрезков к бесконечности, а их размер к бесконечно малому числу, интегральная сумма будет равна площади фигуры под графиком:<br>
![](../Вложения/Математический%20анализ/file-20251104201706929%201.png)<br>
**Определённый интеграл — это число.**<br>
Вычислить значение определенного интеграла можно по формуле:<br>
![](../Вложения/Математический%20анализ/file-20251104201706929.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706928.png)

**Интеграл чётных функций:**<br>
График такой функции из-за симметрии образует слева и справа одинаковые фигуры с осью $Ox$. Если промежуток интегрирования симметричен относительно нуля, то получается, что нужно найти площадь фигуры из двух одинаковых половинок:<br>
![](../Вложения/Математический%20анализ/file-20251104201706927.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706926.png)

**Интеграл нечётных функций:**<br>
![](../Вложения/Математический%20анализ/file-20251104201706925%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706925.png)

**Интегрирование кусочно-заданной функции:**

Определенный интеграл обладает свойством **аддитивности**:<br>
$\large \int_{a}^{b} f(x)dx = \int_{a}^{c} f(x)dx + \int_{c}^{b} f(x)dx, a<c<b$

Это позволяет вычислять интегралы от кусочных функций по частям:<br>
![](../Вложения/Математический%20анализ/file-20251104201706924.png)<br>
Алгоритм вычисления:
1. Разбиваем интеграл на два или более кусочка;
2. Подставляем крайние значения, даже если исходная функция этого не разрешала, так как не включала эти точки для данной формулы;
3. Складываем результаты.

**Несобственный интеграл:**<br>
![](../Вложения/Математический%20анализ/file-20251104201706923%201.png)<br>
То есть кто-то из пределов интегрирования равен бесконечности (а может, и оба сразу).<br>
**Важно:** функция $f(x)$ должна быть непрерывна на интегрируемом промежутке или иметь только точки разрыва первого рода.<br>
Чтобы вычислить несобственный интеграл, нужно вычислить предел:<br>
![](../Вложения/Математический%20анализ/file-20251104201706923.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706922.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706921%201.png)

- Если предел **конечный** (то есть равен любому действительному числу), говорят, что несобственный интеграл **сходится**.
- Если предел **бесконечный** — несобственный интеграл **расходится**.
- Если подынтегральная функция не имеет предела на бесконечности, тогда несобственного интеграла не существует.<br>
Для сходимости нужно, чтобы в разности $F(b)−F(a)$ оба слагаемых получились конечными.<br>
![](../Вложения/Математический%20анализ/file-20251104201706921.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706920.png)<br>
Несобственный интеграл от **показательной функции** $a^x$ будет сходящимся в двух случаях:<br>
![](../Вложения/Математический%20анализ/file-20251104201706919%201.png)

## Функции нескольких переменных

На практике величины часто зависят более чем от одной переменной.<br>
Например, индекс массы тела (ИМТ) рассчитывается по формуле $I=\frac{m}{h^2}$​, где m — масса тела в кг, и h — рост в м.<br>
![](../Вложения/Математический%20анализ/file-20251104201706919.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706918.png)

Записывают такую функцию как $z=f(x,y)$ или $z=z(x,y)$. Здесь переменная z будет зависимой, а аргументы x и y — независимыми.<br>
В общем виде говорят о **функции (от) нескольких переменных**, её записывают вот так: **$u=f(x1,x2,... ,xn)$**

У функции нескольких переменных, как и у обычных, есть область определения и множество значений (область изменения).

![](../Вложения/Математический%20анализ/file-20251104201706917%201.png)<br>
*Например:*<br>
$z=5x−17y−5$$<br>
![[Pasted image 20241120211249.png]]<br>
Получается набор точек уже в пространстве, с тремя координатами: первые две подали функции на вход, третью — получили.<br>
Если рассматривать точку в трёхмерном пространстве, то координаты будут описывать её сдвиг относительно $(0, 0, 0)$.

Функция двух переменных всегда «наследует» характер зависимости от каждого своего аргумента. Например, в уравнении плоскости все переменные линейные — и сама плоскость как бы составлена из множества прямых.

Один из самых простых графиков в трёхмерном пространстве — это **плоскость** (аналог прямой в 2D). Уравнение плоскости выглядит так: $Ax+By+Cz+D=0$, где любой из коэффициентов может быть нулевым. Исключением будет лишь ситуация $A=B=C=0$.

Поверхность $z=x2+y2+1$ целиком расположена над плоскостью $xOy$ и выглядит как **объёмная парабола**:<br>
![](../Вложения/Математический%20анализ/file-20251104201706917.png)

Функция $z=x2−2y$ квадратичная по одной переменной и линейная по другой. На её графике парабола как будто ездит по прямой линии:<br>
![](../Вложения/Математический%20анализ/file-20251104201706916.png)

**Линии уровня:**<br>
Альтернативный вариант визуализации трёхмерных поверхностей — построить линии уровня. Они помогают не строить сложные чертежи и при этом дают достаточное понимание характера поверхности.<br>
![](../Вложения/Математический%20анализ/file-20251104201706915.png)<br>
Линии уровня — это такие горизонтальные «срезы» нашей поверхности на различных высотах. На разной высоте «срезы» будут выглядеть по-разному, но неизменно то, что все они будут двумерными. Значит, их все можно изобразить на плоскости.<br>
*Например:*<br>
![](../Вложения/Математический%20анализ/file-20251104201706914.png)

Линия уровня — это кривая, полученная на пересечении графика функции $z=f(x, y)$ и плоскости $z=C$. Поэтому, чтобы получить изображение линии уровня, фактически надо решить систему уравнений:<br>
![](../Вложения/Математический%20анализ/file-20251104201706913%201.png)<br>
Решением этой системы будет не одна точка, а множество точек. Можно выразить y через x и получить уравнение кривой, график которой и будет линией уровня на высоте C.<br>
![](../Вложения/Математический%20анализ/file-20251104201706913.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706912.png)

**Частная производная:**<br>
У функции двух переменных $z=f(x, y)$ аргумента два: _x_ и _y_. И скорость изменения функции по каждому из этих аргументов будет своя. Поэтому для функций двух (или нескольких) переменных говорят о _частных производных._<br>
![](../Вложения/Математический%20анализ/file-20251104201706911%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706911.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706910.png)<br>
Частная производная функции нескольких переменных определяется как производная функции одной из этих переменных при условии постоянства значений остальных независимых переменных. 

Дифференцирование выполняется по тем же правилам, что и в случае с одной переменной, однако есть небольшие особенности:
- При вычислении частной производной по x переменная y считается константой;
- При вычислении частной производной по y переменная x считается константой.

Сравнение частных производных может помочь дать ответ на вопрос, **какой из параметров функции влияет на нее сильнее при данных значениях этих параметров**. Большее влияние имеет тот параметр, значение частной производной по которому в одной и той же точке больше.<br>
Бывает, что значения частных производных в точке имеют разный знак. В этом случае их нужно сравнивать по модулю.

![](../Вложения/Математический%20анализ/file-20251104201706909%201.png)<br>
Обозначения в зависимости от того, в каком порядке шло дифференцирование:<br>
![](../Вложения/Математический%20анализ/file-20251104201706909.png)<br>
Частные производные $z_{xy}^{′′}$​ и $z_{yx}^{′′}$ называются **смешанными производными**.<br>
Если частные производные высшего порядка непрерывны, то смешанные производные одного порядка равны, то есть нет разницы, в каком порядке дифференцировать: сначала по иксу, потом по игреку или наоборот.

**Экстремум функции нескольких переменных:**

Функции нескольких переменных тоже могут иметь экстремумы. Чтобы корректно ввести определение такого экстремума, сначала введём ещё одно понятие.<br>
![](../Вложения/Математический%20анализ/file-20251104201706908%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706908.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706907.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706906.png)<br>
*Точка максимума функции*

Кандидаты на экстремум функции двух переменных — это точки, в которых обе частные производные первого порядка равны нулю или не существуют.<br>
![](../Вложения/Математический%20анализ/file-20251104201706905%201.png)<br>
**Важно:** исходная функция должна быть определена в точке $N(x_0, y_0)$. То есть если невозможно вычислить $z(x_0, y_0)$, то и о производных здесь говорить нельзя. Только точка из области определения функции может быть кандидатом на экстремум.<br>
![](../Вложения/Математический%20анализ/file-20251104201706905.png)

![](../Вложения/Математический%20анализ/file-20251104201706904.png)<br>
Здесь точка с координатами $x_0=0$, $y_0=0$ не является экстремумом: вдоль одной линии она как будто максимум, а вдоль другой как будто минимум. Такая точка не является ни точкой минимума, ни максимума, но имеет особое название — **седловая точка**.

Чтобы проверить, действительно ли точка является точкой экстремума, применяют **дельта-тест** или **second derivative test**.<br>
Пускай:<br>
![](../Вложения/Математический%20анализ/file-20251104201706903%201.png)<br>
$\large Δ=AC−B^2$<br>
Тогда:<br>
![](../Вложения/Математический%20анализ/file-20251104201706903.png)

![](../Вложения/Математический%20анализ/file-20251104201706902.png)

**Градиентный спуск:**

На практике часто встречаются сложные функции, для которых находить экстремумы при помощи дельта-теста очень затратно с вычислительной точки зрения.<br>
Тогда для поиска экстремумов прибегают к численным методам оптимизации. Один из самых известных таких методов - **градиентный спуск**.

**Градиентный спуск** — численный метод нахождения локального минимума или максимума функции с помощью движения вдоль **градиента**.<br>
![](../Вложения/Математический%20анализ/file-20251104201706901.png)<br>
Иными словами, **градиент** - это такой вектор, в направлении которого функция растёт быстрее всего.<br>
*Например*, если взять в качестве функции высоту поверхности земли над уровнем моря, то её градиент в каждой точке поверхности будет показывать «направление самого крутого подъёма», а своей величиной характеризовать крутизну склона.

1. Рассмотрим движение от точки $(x, y)$ по направлению к точке $(x+Δx, y+Δy)$. Направление задаёт вектор $\vec{u}=(Δx, Δy)$.
2. Мы знаем, что частные производные $\frac{∂f}{∂x}$, $\frac{∂f}{∂y}$ показывают скорость изменения функции вдоль положительных направлений $Ox$ и $Oy$ соответственно. Однако эти направления можно совместить.<br>
![](../Вложения/Математический%20анализ/file-20251104201706900%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706900.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706899.png)<br>
Эта формула, по своей сути, является скалярным произведением двух векторов, поэтому ее можно переписать как:<br>
![](../Вложения/Математический%20анализ/file-20251104201706898.png)<br>
Где $(Δx, Δy)$ - $\vec{u}$, а $(\frac{∂f}{∂x},\frac{∂f}{∂y})$ - **градиент функции**.
3. У градиента столько же координат, сколько аргументов у функции. Это вектор, координаты которого сами являются функциями.
4. Чтобы найти градиент функции в конкретной точке $(x0,y0)$, нужно рассчитать значения частных производных в этой точке:<br>
![](../Вложения/Математический%20анализ/file-20251104201706897%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706897.png)
5. У градиента есть важное и полезное свойство: он показывает как раз то направление, в котором функция растёт быстрее всего.<br>
![](../Вложения/Математический%20анализ/file-20251104201706896.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706895.png)<br>
Чтобы найти направление с наибольшей скоростью роста функции, нужно подобрать такой угол α между градиентом и направлением движения, чтобы косинус этого угла был максимальный. Наибольшее возможное значение косинуса равно 1, и оно достигается при угле в 0.<br>
Получается, что угол между направлением движения и градиентом должен быть равен нулю, то есть эти два направления попросту совпадают!

Следовательно:<br>
![](../Вложения/Математический%20анализ/file-20251104201706894.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706893.png)<br>
Направление, противоположное градиенту, называется **антиградиентом**. Специального обозначения для него нет, его записывают просто как «$−∇f$».<br>
Чтобы найти антиградиент, нужно поменять знак перед каждым элементом градиента. Например, если градиент функции в какой-то точке равен (−2, 3), то её антиградиент в этой точке равен (2, −3).<br>
Получается, что в поисках **минимума** надо всегда идти в направлении **антиградиента**.

**Поиск минимума при помощи антиградиента:**<br>
Алгоритм такой:
1) Выбрать начальную точку.
2) Сдвинуться из этой точки против направления градиента в этой точке. Получить новую точку.
3) Повторять второй шаг, пока не подойдём к минимуму достаточно близко.<br>
![](../Вложения/Математический%20анализ/file-20251104201706892.png)<br>
Получается, что из начальной точки мы как бы спускаемся против градиента всё ниже и ниже к минимуму. Поэтому метод и называется **градиентным спуском**. А сдвиг к следующей точке называется **шагом спуска.**

**Выбор начальной точки:**<br>
Самый популярный подход — выбирать точку случайно. Начав из случайной точки, мы подберёмся к какому-то из локальных минимумов функции. Однако в некоторых случаях само условие задачи помогает выбрать начальную точку.

**Движение против градиента:**<br>
Сделать шаг по направлению градиента легче всего так: просто отложить от неё вектор градиента. То есть просто прибавить к координатам точки координаты $(\frac{∂f}{∂x}, \frac{∂f}{∂y})$.<br>
![](../Вложения/Математический%20анализ/file-20251104201706860.png)<br>
*Например:*<br>
![](../Вложения/Математический%20анализ/file-20251104201706859%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706859.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706858.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706857%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706857.png)

В градиентном спуске с каждым шагом мы будем всё ближе подбираться к точке минимума, мы необязательно попадём в неё точно. Тем не менее в реальных задачах точки, близкой к минимуму, вполне достаточно.<br>
Такой алгоритм, который постепенно приближает решение к оптимальному, называется **приближённым**. Он умеет приближаться к локальному минимуму, но не всегда его достигает.<br>
![](../Вложения/Математический%20анализ/file-20251104201706856.png)

**Скорость (темп) обучения:**<br>
Когда мы подходим к минимуму ближе, есть риск перешагнуть через него.<br>
![](../Вложения/Математический%20анализ/file-20251104201706855.png)<br>
Поэтому при подсчёте новой точки размер шага можно и нужно изменять. Это можно сделать, просто домножая градиент на какое-то маленькое число $γ$:<br>
![](../Вложения/Математический%20анализ/file-20251104201706854.png)<br>
Это число называют коэффициентом скорости обучения, а произведение его на градиент функции можно назвать длиной шага.<br>
Наглядно увидеть, как влияет коэффициент скорости спуска на алгоритм, можно на траектории движения по расчётным точкам на графике:<br>
![](../Вложения/Математический%20анализ/file-20251104201706853.png)<br>
На практике коэффициент подбирают отдельно под каждую функцию, учитывая два момента:
- Если шаг слишком большой, то алгоритм может никогда не прийти к минимуму;
- Если шаг слишком маленький, то алгоритм может сходиться к минимуму очень долго.<br>
То есть нужно найти такой коэффициент, при котором значение функции уменьшается, причём довольно быстро. К сожалению, нет универсального правила, которое всегда даёт наилучший результат. Но есть разные рецепты, которые можно использовать. Один из них — перебирать отрицательные степени десятки. Популярные стартовые значения: $10^{−3}, 10^{−2}, 10^{−1}$.

**Критерий остановки:**<br>
В конце спуска шаги становятся очень маленькими и практически не меняют значения функции в точке.<br>
![](../Вложения/Математический%20анализ/file-20251104201706852.png)<br>
Можно заранее задать, какое отличие считать незначительным. Например, считать несущественной разницу в 0.001 или 0.1. Такая величина называется **точностью** и обычно обозначается греческой буквой $ε$.

Отсюда можно вывести популярный критерий остановки: если изменение значения функции на последнем шаге меньше заданной точности, то считается, что мы нашли минимум и нужно остановить вычисления. Формально это условие записывают так:<br>
![](../Вложения/Математический%20анализ/file-20251104201706851%201.png)

Есть и другие критерии остановки — например, алгоритм останавливается, когда
- Функция достигает заранее выбранного маленького значения,
- Или количество итераций достигло максимально заданного,
- Или превышен лимит времени работы программы.

**Стохастический градиентный спуск:**<br>
Считать градиент по всей обучающей выборке на каждом шаге градиентного спуска слишком дорого. Стохастический градиентный спуск (SGD) - это улучшение обычного градиентного спуска, которое позволяет решить эту проблему.

На каждой итерации градиентного спуска будем считать градиент функции потерь не по всей выборке, а лишь по подмножеству выборки фиксированного размера $k$ (такое подмножество называется **батч**). Существует несколько способов реализовать SGD:<br>
![](../Вложения/Математический%20анализ/file-20251104201706851.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706850.png)


## Линейная регрессия

Обычно переопределённая система не имеет решений. Например, в двумерном случае нельзя провести прямую через три и более точки, если они не лежат на одной прямой.<br>
![](../Вложения/Математический%20анализ/file-20251104201706849.png)<br>
**Решение** - построить такую прямую, которая проходит ближе всего к точкам и передаёт общую зависимость.

Чтобы понять, насколько далеко прямая проходит от точек, можно, к примеру, оценить, как сильно отличаются предсказания прямой для существующих точек от их истинных значений.<br>
Оценкой «отличия» в каждой точке будет расстояние по вертикали от точки до нашей прямой. Такое расстояние называют **ошибкой** или **невязкой** модели в заданной точке.<br>
![](../Вложения/Математический%20анализ/file-20251104201706848%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706848.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706847.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706846%201.png)<br>
Сам по себе вектор ошибок не дает полноценного представления о том, хорошо функция описывает данные или плохо. Для того, чтобы делать это универсально, вводят понятие **функции ошибок**:<br>
![](../Вложения/Математический%20анализ/file-20251104201706846.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706845.png)<br>
Сейчас получается, что с увеличением размера выборки растёт и ошибка модели. Поэтому можно усреднить общую ошибку:<br>
![](../Вложения/Математический%20анализ/file-20251104201706844%201.png)<br>
![Pasted image 20241202212951.png](../Вложения/Математический%20анализ/file-20251104201706785.png)<br>
Это равносильно расчету $L_1$ и $L_2$ нормы векторов ошибок соответственно.

В **MSE** возведение в квадрат делает большие значения невязок ещё больше. Из-за этого наибольшее влияние на ошибку оказывают именно крупные отклонения. Если отклонение прогнозируемого значения от истинного будет большим хотя бы на одном объекте, то общая ошибка модели также будет большой. **MAE** же взвешивает все отклонения одинаково, независимо от их величины.<br>
![](../Вложения/Математический%20анализ/file-20251104201706844.png)<br>
Видно, что прямая, полученная минимизацией **MAE**, неплохо подходит к основной группе точек и как бы игнорирует удалённую точку. Прямая же, полученная минимизацией **MSE**, старается описать весь набор точек. Какую функцию выбрать — зависит от целей конкретного исследования, качества исходных данных и других факторов.

**MSE** можно иначе выразить как:<br>
![](../Вложения/Математический%20анализ/file-20251104201706843.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706842%201.png)<br>
Поскольку мы рассматриваем прямую, вектор задаваемых ею значений можно выразить так:<br>
![](../Вложения/Математический%20анализ/file-20251104201706842.png)<br>
Следовательно, можно переписать функцию так:<br>
![](../Вложения/Математический%20анализ/file-20251104201706841.png)<br>
Далее задача сводится к поиску таких коэффициентов $(k,m)$, при которых **функция принимает наименьшее значение**, поскольку именно это означает, что прямая наилучшим образом подходит для предсказания на основе данного набора точек:<br>
![](../Вложения/Математический%20анализ/file-20251104201706840.png)<br>
$MSE(k,m)$ - это функция двух переменных. Ее минимум можно найти двумя способами:<br>
![](../Вложения/Математический%20анализ/file-20251104201706839%201.png)

Найдем частные производные по $k$ и по $m$:
1) По $k$:<br>
![](../Вложения/Математический%20анализ/file-20251104201706839.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706838.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706837%201.png)
2) По $m$:<br>
![](../Вложения/Математический%20анализ/file-20251104201706837.png)
3) Соберём полученные частные производные в один вектор — градиент:<br>
![](../Вложения/Математический%20анализ/file-20251104201706836.png)<br>
То же самое в матричном виде:<br>
![](../Вложения/Математический%20анализ/file-20251104201706835.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706834.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706833%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706833.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706832.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706831.png)<br>
$\large \nabla \text{MSE}(k, m) = -\frac{2}{n} \begin{pmatrix} x^T (y - \hat{y}) \\ 1^T (y - \hat{y}) \end{pmatrix} = -\frac{2}{n} X^T (y - \hat{y}) = \frac{2}{n} X^T (\hat{y} - y)$<br>
Или:<br>
![](../Вложения/Математический%20анализ/file-20251104201706830%201.png)

Мы нашли градиент MSE. Поскольку мы ищем минимум самой функции MSE, нам нужно найти такую точку, в которой градиент равен нулю:<br>
![](../Вложения/Математический%20анализ/file-20251104201706830.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706829.png)<br>
Матрица $X^TX$ - это квадратная матрица 2x2. Она обратима, если её определитель не равен нулю. Если это условие выполняется, домножим слева обе части уравнения на $(X^TX)^{-1}$ и получим формулу-решение для наилучших коэффициентов прямой:<br>
![](../Вложения/Математический%20анализ/file-20251104201706828.png)

*Например:*<br>
![](../Вложения/Математический%20анализ/file-20251104201706827.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706826%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706826.png)

**Случай многомерных данных:**<br>
Эту же формулу можно использовать при работе с данными большей размерности.

*Например:*<br>
![](../Вложения/Математический%20анализ/file-20251104201706825.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706824.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706823%201.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706823.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706822.png)<br>
$\large y=\begin{pmatrix} 10 \\ 7 \\ 7 \\ 6 \end{pmatrix}$<br>
![](../Вложения/Математический%20анализ/file-20251104201706821%201.png)<br>
**-> Коэффициенты прямой: [-0.5  2.   7.5]**

![](../Вложения/Математический%20анализ/file-20251104201706821.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706820.png)<br>
Чтобы получить предсказание сразу для нескольких точек, пользуются матричной формулой предсказания:<br>
![](../Вложения/Математический%20анализ/file-20251104201706819.png)

![](../Вложения/Математический%20анализ/file-20251104201706818.png)<br>
Достоинство линейной регрессии в том, что эта модель хорошо интерпретируемая. 

В уравнении $y=kx+m$ коэффициент $k$ отвечает за наклон прямой и равен производной функции $y(x)$. Он показывает, на сколько изменится $y$, если $x$ увеличится на 1.<br>
В случае с регрессией коэффициент был неизвестен и мы нашли его на основе данных. Точки в данных очень редко лежат на одной прямой, поэтому говорить о строгой зависимости $x$ от $y$ сложно. В таком случае говорят, что $k$ показывает, на сколько **в среднем** меняется $y$, если $x$ увеличивается на 1.<br>
Когда переменных больше, логика рассуждений не меняется: каждый коэффициент отвечает за свою переменную и показывает, на сколько в среднем изменяется $y$ при увеличении этой переменной на 1.

Коэффициент $m$ в уравнении $y=kx+m$ отвечает за сдвиг прямой вдоль вертикальной оси. В уравнении $y$ получится равным $m$, если $x=0$. Поэтому свободный коэффициент можно интерпретировать как «**базовую величину**» $y$ — такое значение, которое принимает $y$, когда на него совсем не влияет $x$.

Коэффициенты линейных моделей бывают обманчивы. Например, так происходит, когда линейной регрессией моделируют нелинейные зависимости. В таких случаях можно найти коэффициент $k$ и интерпретировать его. Но истинная зависимость может быть сложнее и не соответствовать этой интерпретации.<br>
Также на значение коэффициентов влияет количество факторов в модели, поэтому необходимо относиться к их интерпретации с определенным скепсисом.

**Регрессия и градиентный спуск:**<br>
В реальных задачах расчёт оптимальных коэффициентов линейной регрессии по формуле имеет недостатки:
1. Если точек очень много, то матрица $X$ становится очень большой и матричное умножение с ее участием становится слишком затратным.
2. Чтобы обратить большую матрицу $X$ тоже требуется много времени и ресурсов.
3. Формула подходит только для одного случая — для построения линейной регрессии и среднеквадратичной ошибки. Чтобы вывести формулу решения задачи с другой моделью и функцией ошибки, нужно заново решать систему уравнений.
4. Если появляются новые данные, то есть новые точки на плоскости, то нужно всё пересчитывать заново.

Мы решили задачу минимизации с помощью обнуления градиента. Однако точку минимума функции можно найти по-другому — с помощью **градиентного спуска**.<br>
![](../Вложения/Математический%20анализ/file-20251104201706817.png)<br>
Рассмотрим случай с одним признаком. На левом рисунке представлены несколько прямых. На правом рисунке изображены точки, соответствующие этим прямым, на графике линий уровня функции ошибки **MSE** (w). Это возможно визуализировать, так как в случае с одним параметром каждая прямая однозначно задается набором значений $(w_1, w_0)$.

Видно, что параметры модели задают точки, а функция ошибки **MSE** (w) — функция этих параметров. Значит, можно найти её точку минимума градиентным спуском.<br>
Алгоритм поиска точки минимума следующий:<br>
![](../Вложения/Математический%20анализ/file-20251104201706816.png)

Мы знаем градиент функции **MSE**:<br>
![](../Вложения/Математический%20анализ/file-20251104201706815.png)<br>
На каждой итерации мы делаем шаг в направлении минимума функции потерь. Значение этой функции уменьшается, и прямая, построенная по обновлённым весам, ближе подходит к исходным точкам и лучше их описывает.<br>
![](../Вложения/Математический%20анализ/file-20251104201706814.png)<br>
С каждым новым шагом прямые на левой иллюстрации всё лучше описывают исходные точки, а точки на правой иллюстрации всё ближе располагаются к минимуму $MSE(w_0, w_1)$.

**Градиентный спуск и полиномиальная модель:**<br>
Теперь вместо поиска коэффициентов прямой стоит задача найти коэффициенты функции $f(x)=w_2x_2+w_1x_1+w_0$.<br>
![](../Вложения/Математический%20анализ/file-20251104201706813.png)<br>
Решением такой системы является набор коэффициентов, который задаёт параболу.<br>
Найдём градиент функции ошибки. Её формула:<br>
![](../Вложения/Математический%20анализ/file-20251104201706812%201.png)<br>
Градиент вычислим аналогично тому, как вычисляли градиент этой функции для линейной регрессии:<br>
![](../Вложения/Математический%20анализ/file-20251104201706812.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706811.png)<br>
Исполняем алгоритм, аналогичный линейному случаю, и получаем коэффициенты необходимой кривой:<br>
![](../Вложения/Математический%20анализ/file-20251104201706810.png)<br>
Этот подход лежит в основе **numpy polyfit**.

**Дообучение:**<br>
Если строить регрессию с помощью градиентного спуска, то при появлении новых данных не нужно решать всю задачу заново. Можно использовать уже найденное решение и «дообучить» модель.<br>
![](../Вложения/Математический%20анализ/file-20251104201706809.png)

**Сравнение с бейзлайном:**<br>
Чтобы проверить, насколько получившаяся модель подходит для описания данных, можно сравнить ошибку ее предсказаний на тестовых данных с ошибкой константного предикта:<br>
![](../Вложения/Математический%20анализ/file-20251104201706808.png)<br>
Чтобы построить константный предикт, можно, например, создать массив единиц и умножить его на среднее значение $y$. Полученный вектор и будет предсказанием.<br>
Если ошибка модели больше ошибки константного предикта, то ее использование в принципе нецелесообразно.

**Мультиколлинеарность и регуляризация:**<br>
![](../Вложения/Математический%20анализ/file-20251104201706807%201.png)<br>
Если между двумя столбцами признаков существует линейная зависимость, то матрица $X^TX$ получится вырожденной, а значит, у нее не будет обратной матрицы. Аналитическую формулу применить не получится.

Если связь не совсем линейная, но корреляция между признаками близка к 1, то решение будет математически возможно найти, однако коэффициенты такой модели будут очень большими и неинтерпретируемыми, а сама модель будет **переобучена**, то есть будет давать большую ошибку на новых точках.

Чем ближе положение точек к положению «друг над другом», тем:
1) Ближе столбцы X к линейной зависимости.
2) Ближе матрица X к вырожденной.
3) Более вытянуты линии уровня функции потерь.<br>
![](../Вложения/Математический%20анализ/file-20251104201706807.png)

Борьба с переобучением называется **регуляризацией**. Основная идея — добавить в функцию потерь ещё одно слагаемое, отвечающее за размер весов, и минимизировать полученную функцию.<br>
Например, модифицировать функцию потерь так, чтобы модель считала размер весов частью ошибки. В результате получаются такие коэффициенты, которые удовлетворяют и основной функции потерь, и ограничению на небольшую величину.<br>
 ![](../Вложения/Математический%20анализ/file-20251104201706806.png)<br>
 ![](../Вложения/Математический%20анализ/file-20251104201706805.png)<br>
 Есть два популярных способа понять, насколько коэффициенты большие. Первый — это вычислить сумму их квадратов, а второй — сумму их модулей.<br>
![](../Вложения/Математический%20анализ/file-20251104201706804.png)<br>
Также называется **Ridge**-регрессией.<br>
![](../Вложения/Математический%20анализ/file-20251104201706803%201.png)<br>
Если рассчитать градиент, обнулить его и решить полученную систему, получится формула:<br>
![](../Вложения/Математический%20анализ/file-20251104201706803.png)<br>
Где ![](../Вложения/Математический%20анализ/file-20251104201706802.png)<br>
Прибавление $\alpha E$ к $X^TX$ лечит ее от вырожденности:<br>
*Например:*<br>
Вырожденная матрица:<br>
![](../Вложения/Математический%20анализ/file-20251104201706801.png)<br>
Невырожденная матрица:<br>
![](../Вложения/Математический%20анализ/file-20251104201706800.png)

При этом ростом $α$ всегда растёт ошибка на обучающей выборке, так как мы всё сильнее меняем исходную функцию потерь<br>
Наилучшее значение $α$ — то, при котором ошибка на тестовой выборке самая маленькая. Обычно нас интересует работа модели на новых данных, поэтому мы опираемся именно на тестовую выборку — данные, которые модель не видела.<br>
![](../Вложения/Математический%20анализ/file-20251104201706799.png)Благодаря $L_2$ регуляризации веса между скоррелированными признаками распределяются примерно равномерно.

 ![](../Вложения/Математический%20анализ/file-20251104201706798.png)<br>
 Также называется **Lasso**-регрессией.<br>
 Второй способ регуляризации модели — прибавить к функции потерь вместо суммы квадратов коэффициентов — сумму их модулей.<br>
 Тогда функция потерь примет вид:<br>
 ![](../Вложения/Математический%20анализ/file-20251104201706797%201.png)<br>
 ![](../Вложения/Математический%20анализ/file-20251104201706797.png)<br>
 L1-регуляризация зануляет веса при всех сильно скоррелированных признаках, кроме одного. Таким образом, в алгоритм встроен механизм отбора признаков (feature selection) — его применяют, когда нужно снизить размерность и избавиться от дублирующих признаков. Постепенно повышая α, можно обнулять всё больше коэффициентов, а столбцы при ненулевых коэффициентах использовать как значимые.
 
В реальных задачах встречаются ситуации, когда влияющих параметров очень много. С помощью Lasso-регрессии убирают незначимые параметры и строят предсказания на меньшем наборе данных. В итоге анализ полученного решения становится проще, а точность предсказания меняется незначительно.

### Линейная регрессия с вероятностной точки зрения

Запишем ещё раз общий вид линейной регрессии:<br>
![](../Вложения/Математический%20анализ/file-20251104201706796.png)<br>
Учтём, что каждое значение $X_i$​ и $Y$ — это случайная величина:<br>
![](../Вложения/Математический%20анализ/file-20251104201706795.png)<br>
где $E$ - ошибка.

Каждая величина $X_i$​ может описывать совершенно разные характеристики, поэтому они совершенно необязательно будут иметь одинаковое распределение. Однако мы все равно можем применить ЦПТ и сказать, что общая ошибка каждой величины складывается из множества факторов, а значит, сумма такого набора ошибок имеет распределение, близкое к нормальному.<br>
![](../Вложения/Математический%20анализ/file-20251104201706794%201.png)

Теперь осталось определить параметры случайной величины $γ$, которая описывает случайную ошибку. Так как ошибка может быть как положительной, так и отрицательной в равной мере, то параметр $μ$ математического ожидания считают равным 0. Параметр $σ$ оценить сложно, так как случайная величина $γ$ и величины![](../Вложения/Математический%20анализ/file-20251104201706794.png)​ независимы.<br>
Получается, что точные значения элементов величины $Y$ выражаются как линейная зависимость величин $X_i$​ и нормально распределённого шума.

![](../Вложения/Математический%20анализ/file-20251104201706793.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706792.png)<br>
Чтобы упростить вычисления, используем логарифм функции правдоподобия и найдем производную получившегося выражения:<br>
![](../Вложения/Математический%20анализ/file-20251104201706791.png)<br>
Аналогично можно перейти к задаче поиска минимума функции $−ln⁡L(β)$:<br>
![](../Вложения/Математический%20анализ/file-20251104201706790%201.png)<br>
Дифференцируем полученное выражение по каждому параметру, приравняем к нулю производные и составим систему уравнений. Запишем производную по параметру $β_m$​:<br>
![](../Вложения/Математический%20анализ/file-20251104201706790.png)<br>
Получается та же самая формула, с помощью которой мы находили параметры линейной регрессии с помощью метода наименьших квадратов

С помощью метода максимального правдоподобия мы получили формулу для коэффициентов из предположения, что ошибки распределены нормально. Если предположить, что ошибки распределены по другому закону, то можно повторить рассуждения и получить формулу для коэффициентов в такой ситуации.

**Коэффициент детерминации $R^2$:**

Рассмотрим пример. У нас есть данные о массе группы людей и их росте. Мы хотим прогнозировать по этим данным вес нового человека. Пойдем двумя путями. В одном случае, будет прогнозировать вес нового человека как вес среднего человека из выборки, а в другом - построим линейную регрессию, используя данные о росте:<br>
![](../Вложения/Математический%20анализ/file-20251104201706789.png)<br>
Теперь нам нужно сравнить эти модели и понять, насколько линейная регрессия лучше модели со средними значениями.<br>
Чтобы описать, насколько более точной стала модель, используем дисперсию. Поймём, насколько уменьшилась дисперсия, когда мы перешли от среднего к линейной регрессии:<br>
![](../Вложения/Математический%20анализ/file-20251104201706788.png)<br>
![](../Вложения/Математический%20анализ/file-20251104201706787.png)<br>
Видно, что общая дисперсия одной точки — это сумма объяснённой и необъяснённой дисперсий. Объяснённая дисперсия — это та часть, которую «объяснила» регрессионная модель. Оставшаяся часть общей дисперсии — необъяснённая.

Очевидно, что чем больше объяснённая дисперсия и чем меньше необъяснённая, тем лучше модель описывает исходные данные. Когда необъяснённая дисперсия равна нулю, прогнозируемое и исходное значение совпадают. Это соображение подводит нас к важному показателю:<br>
![](../Вложения/Математический%20анализ/file-20251104201706786.png)

Если выборочный коэффициент детерминации детерминации равен, например, 0.83, результат интерпретируется так:
- Дисперсия точек относительно построенной линии на 83% меньше, чем исходная дисперсия набора данных. Это означает, что точки стоят ближе к этой прямой, чем к своему среднему, то есть линейная регрессия лучше описывает разброс точек, чем их среднее.
- 83%83% всей дисперсии исходного набора данных описывается построенной линейной регрессией. Всего 17% всей дисперсии осталось не описано. Это достаточно хороший результат.

R2 — это также квадрат корреляции, то есть он показывает линейную зависимость между двумя величинами.
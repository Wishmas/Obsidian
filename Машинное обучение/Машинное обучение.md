# Машинное обучение

## Введение

- Моделью машинного обучения можно назвать некую функцию, которая отображает объекты или примеры (samples) в предсказания разного вида (targets).
- В одних случаях, мы основываемся на примерах, чтобы выдавать правильные предсказания для будущих объектов. В других случаях, мы сразу работаем с неразмеченными объектами и ищем закономерности в них.
- В качестве набора примеров можно взять датасет.
- Он состоит из объектов с определенными атрибутами и ответов (targets), то есть целевых параметров, которые мы в дальнейшем хотим предсказывать.
- Атрибуты могут быть разных типов:
    - Дискретные (категориальные и целочисленные)
    - Непрерывные (вещественные)
    - Бинарные (булевые)
    - Ординальные (ранговые)
    - Изображения, тексты, видео, звук, графы и т.д.
- Для решения конкретной задачи нужно правильно подобрать модель обучения и алгоритм обучения.
- Здесь модель выступает в качестве непосредственного метода решения задачи, а алгоритм - в качестве процедуры, которая реализует обучение модели и зависит от внутренних параметров, которые необходимо подобрать.

## Три типа машинного обучения

1. **Обучение с учителем:**
Задача заключается в получении прогнозов о будущих данных на основании заранее маркированных тренировочных данных.

- Задачи классификации - определение дискретных неупорядоченных меток принадлежности объекта к определенному классу, когда эти классы известны.
- Задачи регрессии - определение значения непрерывной величины на основании имеющихся признаков.
- Отношение порядка - определение рангов исследуемых объектов по отношению друг к другу для создания конечного упорядоченного множества.

2. **Обучение без учителя :**
Задача заключается в том, чтобы найти закономерности в немаркированных данных или данных с неизвестной структурой и провести более качественный разведывательный анализ.
- Кластеризация  - разделение объектов на заранее неизвестные классы по принципу подобия и отличия по определенному набору признаков.
- Снижение размерности - уменьшение количества признаков для снижения уровня шума и улучшения предсказательной способности других моделей.

![Untitled](../Вложения/Машинное%20обучение/Untitled.png)

3. **Обучение с подкреплением:**
Задача заключается в том, чтобы подобрать оптимальный подход к “взаимодействию со средой” при помощи функции вознаграждения, которая поощряет модель за совершение правильных действий. 

![Untitled](../Вложения/Машинное%20обучение/Untitled%201.png)

Цель - создание автономных самообучающихся агентов.

## Классический алгоритм прогнозного моделирования

![Untitled](../Вложения/Машинное%20обучение/Untitled%202.png)

Очень важной частью машинного обучения является предобработка данных.

- Признаки должны быть тщательно отобраны и не должны коррелировать между собой, поскольку, в противном случае, может возникнуть проблема мультиколлинеарности.
- Для многих моделей важно, чтобы отобранные признаки находились в одной и той же шкале, что достигается, к примеру, через приведение данных к диапазону [0,1] или к стандартизированному нормальному распределению.
- Необходимо внимательно обработать пропуски, дубликаты, выбросы (только из обучающего датасета) и ошибки в данных.
- Отбор фичей можно осуществлять по-разному. Например, можно поочередно выкидывать фичи из датасета и замерять изменение ошибки, фиксируя, становятся показатели лучше или хуже. Также можно дедуктивно выявлять зависимости между факторами и либо объединять их, либо оставлять только один.
- Весь датасет необходимо случайным образом разделить на тренировочный и тестовый наборы, чтобы проверить качество получившейся модели (кросс-валидация).

Разных алгоритмов машинного обучения существует много и никогда нельзя с уверенностью сказать, какой из них выполнит задачу лучше. Поэтому, в любой задаче необходимо проверить несколько разных моделей, а затем сравнить получившиеся на них метрики.

Выбор наиболее релевантных метрик зависит от выбранной модели, особенностей исследования и данных, бизнес-требований и прочего, поэтому к нему нужно подходить внимательно.

![Untitled](../Вложения/Машинное%20обучение/Untitled%203.png)

![Untitled](../Вложения/Машинное%20обучение/Untitled%204.png)

После того, как мы оказываемся удовлетворены качеством модели, мы можем использовать ее для прогнозирования новых будущих данных.

### Переобучение и недообучение

При обучении модели возможны следующие негативные сценарии:

- **Недообучение:** модель допускает слишком много ошибок как на обучении, так и на тестовой выборке. Это значит, что она не уловила существующие взаимосвязи в данных. Причинами этого могут быть:
    - Слишком малое число примеров или признаков;
    - Слишком простая функция;
    - Неверный подход к подбору разных вариантов искомой зависимости;
    
    Недообучение приводит нас к ошибке смещения (high bias).
    
    $$\mathbb{V}_X[a(x, X)] = \mathbb{E}_X \left[ a(x, X) - \mathbb{E}_X[a(x, X)] \right]^2$$
    
- **Переобучение:** модель показывает хорошие результаты на обучающей выборке, но допускает очень много ошибок на тестовой. Это происходит из-за того, что модель избыточно подстроилась под данные на обучающей выборке (возможно, из-за их зашумленности) и не может на основании их делать какие-то выводы об объектах, которые не видела.
    
Переобучение приводит нас к ошибке разброса (hugh variance).

    $$
    \sigma^2 = \mathbb{E}_x \mathbb{E}_\epsilon[y(x, \epsilon) - f(x)]^2
    $$
    

Понятия Overfit / Underfit и Bias / Variance во многом пересекаются, однако называть их эквивалентными нельзя, потому что в ряде случаев они не пересекаются.

Способность модели не просто подстраиваться к обучающим данным, но и улавливать в них существенные для предсказаний тенденции, называется генерализацией.

![Untitled](../Вложения/Машинное%20обучение/Untitled%205.png)

![Untitled](../Вложения/Машинное%20обучение/Untitled%206.png)

![Untitled](../Вложения/Машинное%20обучение/Untitled%207.png)

![Untitled](../Вложения/Машинное%20обучение/Untitled%208.png)

Стратегии борьбы с высоким Bias:

- Использовать более сложную модель
- Добавить больше параметров
- Увеличить количество данных

Стратегии борьбы с высокой Variance:

- Использовать более простую модель
- Уменьшить количество параметров
- Увеличить количество данных (тоже)

## Оценка качества

### Подходы к кросс-валидации
Прежде чем оценивать качество модели, необходимо подготовить данные, на которых ее можно будет обучить и протестировать.

**Кросс-валидация** - метод подтверждения работоспособности модели, позволяющий понять, насколько модель полезна на практике. Основывается на разделении имеющегося набора данных на тренировочный и тестовый разными способами. На тренировочном датасете модель учится, а на тестовом считаются метрики ее успешности. Это позволяет объективно оценить степень генерализации модели и избежать таких проблем, как переобучение.

1. **Hold-out**

Это простое разделение датафрейма на тренировочную и тестовую группы в заданной пропорции. По умолчанию имеет выставленный параметр *shuffle*=True, то есть перед тем, как разделить данные, перемешивает их.

*Датафрейм:*

![Untitled](../Вложения/Машинное%20обучение/Untitled%209.png)

*Код:*

```python
from sklearn.model_selection import train_test_split

targets = df['target']
atributes = df.drop('target',axis=1)

x_train, x_test, y_train, y_test = train_test_split(
    atributes, targets,
		test_size=0.2,
		random_state=42
)
```

Если данных много, то можно также дополнительно создать валидационное множество:

```python
x_train, x_val, y_train, y_val = train_test_split(
    x_train, y_train, 
    test_size=0.1, 
    random_state=42
)
```

Это множество может пригодиться при переборе моделей. Оптимизировать их качества стоит на валидационном множестве, а окончательное сравнение моделей проводить на тестовом множестве. Оптимизация качеств модели может включать в себя подбор гиперпараметров, подбор архитектуры (в случае нейросеток), подбор оптимального трешолда для максимизации значений целевой метрики и т.д.

1. **Стратификация**

Это разбиение на трейн и тест, сохраняющее соотношение классов, представленное в исходном датасете. Стратификация может оказаться полезной, если данные очень несбалансированные и один класс встречается сильно чаще другого. 

```python
x_train, x_test, y_train, y_test = train_test_split(
    atributes, targets, 
    test_size=0.2, 
    random_state=42,
    stratify=y
)
```

1. **K-folds**

Это алгоритм, представляющий из себя обобщение hold-out и состоящий из следующих шагов:

- Фиксируется некоторое целое число k (обычно от 5 до 10), меньшее числа семплов в датасете.
- Датасет разбивается на k одинаковых частей (в последней части может быть меньше семплов, чем в остальных). Эти части называются *фолдами*.
- Далее происходит k итераций, во время каждой из которых один фолд выступает в роли тестового множества, а объединение остальных — в роли тренировочного. Модель учится на k-1 фолде и тестируется на оставшемся.
- Финальный скор модели получается либо усреднением k получившихся тестовых результатов, либо измеряется на отложенном тестовом множестве, не участвовавшем в кросс-валидации.

![Untitled](../Вложения/Машинное%20обучение/Untitled%2010.png)

```python
# функция для получения score на одной итерации;
# можно модифицировать под разные метрики
def get_score(model,x_train,x_test,y_train,y_test):
    model.fit(x_train,y_train)
    return model.score(x_test,y_test)

from sklearn.model_selection import KFold

kf = KFold(n_splits=3) # задаем количество фолдов (k)
scores = []

# на каждой итерации получаем индексы трейна и теста,
# разбиваем датафреймы нужным образом и смотрим score
# тестируемой модели; применяем к разным моделям и выбираем лучшую
for train_index, test_index in kf.split(atributes):
    x_train, x_test = atributes.iloc[train_index], atributes.iloc[test_index]
    y_train, y_test = targets.iloc[train_index], targets.iloc[test_index]
    res = get_score(model,x_train,x_test,y_train,y_test)
    scores.append(res)

print(scores.mean())
```

*Чтобы проводить разделение со стратификацией, можно использовать StratifiedKFold вместо обычного KFold.*

Этот же процесс можно реализовать при помощи метода cross_val_score.

Он принимает модель, данные, таргеты и нужное число фолдов и возвращает массив scores.

```python
from sklearn.model_selection import cross_val_score

# для примера взята логистическая регрессия
lr = LogisticRegression(random_state=42)
scores = cross_val_score(lr,atributes,targets,cv=5)
print(scores)
```

Предобрабатывать и стандартизировать данные нужно до кросс-валидации! 

1. **Кросс-валидация для временных рядов**

Если задача заключается в анализе временных рядов (н-р: что будет с показателями продукта через месяц / год?), то обычные методы кросс-валидации не подходят, поскольку нельзя допустить, чтобы данные пересекались по времени: тренировочные данные должны идти до валидационных, а валидационные — до тестовых. 

Из-за этих особенностей, фолды должны располагаться так:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2011.png)

```python
from sklearn.model_selection import TimeSeriesSplit

tss = TimeSeriesSplit()
 
for train_index, test_index in tss.split(X):
    x_train, x_test = time_atributes.iloc[train_index], time_atributes.iloc[test_index]
    y_train, y_test = targets.iloc[train_index], targets.iloc[test_index]
    res = get_score(model,x_train,x_test,y_train,y_test)
    scores.append(res)

print(scores)
```

### Метрики классификации и регрессии
Метрики, применяемые для оценки качества модели машинного обучения, можно разделить на два вида:

- **Online-метрики:** вычисляются по данным, собираемым с рабочей системы. Связаны с бизнес-требованиями и могут быть оценены только после введения модели в эксплуатацию.
- **Offline-метрики:** вычисляются на тестовых данных или с привлечением экспертов, которые выносят свою оценку качества работы модели. Могут быть посчитаны до введения модели в эксплуатацию.

Метрика качества - это объективный критерий успеха, зависящий не от параметров модели, а только от предсказанных меток. В отличие от функции потерь, которая возникает в задаче оптимизации во время построения модели, метрика качества не смотрит на то, что происходит внутри, а оценивает лишь конечный результат.

#### Метрики классификации
**Confusion matrix**
Это матрица ошибок, которая работает для бинарной классификации и показывает, какую долю ответов модели можно отнести к какой из четырех категорий:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2012.png)

Мы предсказали положительную метку и угадали. Будет относить такие объекты к **true positive** (**TP**) группе (true – потому что предсказали мы правильно, а positive – потому что предсказали положительную метку);

Мы предсказали положительную метку, но ошиблись в своём предсказании – **false positive** (**FP**) (false, потому что предсказание было неправильным);

Мы предсказали отрицательную метку и угадали – **true negative** (**TN**);

Мы предсказали отрицательную метку, но ошиблись – **false negative** (**FN**).

```python
cm = sklearn.metrics.confusion_matrix(y_true,y_pred)
tn, fp, fn, tp = cm.ravel()
```

В некоторых задачах предпочтительнее модели, показывающие меньший FP, в некоторых - меньший FN. Это необходимо решать экспертно.

**Accuracy**
Это доля объектов, которым мы правильно предсказали класс:

$$
{\text{Accuracy}= \frac{TP + TN}{TP + TN + FP + FN}}
$$

```python
accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)
```

**Error rate**
Сопряженная с Accuracy метрика, показывающая долю объектов с неправильно предсказанными классами:

$$
{\text{Error Rate}= 1 - Accuracy}
$$

$$
{\text{Error Rate}= \frac{FP + FN}{TP + TN + FP + FN}}
$$

**Precision (точность)**
Показывает долю правильно предсказанных положительных объектов среди всех объектов, для которых был предсказан положительный класс:

$$
{\text{Precision Rate}= \frac{TP}{TP + FP}}
$$

```python
precision = sklearn.metrics.precision_score(y_true, y_pred)
```

![Untitled](../Вложения/Машинное%20обучение/Untitled%2013.png)

Применяется, когда нам требуется минимальное количество ложноположительных (FP) срабатываний.  

**Recall (полнота)**
Показывает долю правильно предсказанных положительных объектов среди всех объектов действительно положительного класса:

$$
{\text{Recall Rate}= \frac{TP}{TP + FN}}
$$

```python
recall = sklearn.metrics.recall_score(y_true, y_pred)
```

![Untitled](../Вложения/Машинное%20обучение/Untitled%2014.png)

Применяется, когда нам нужно найти как можно больше объектов положительного класса и по возможности не упускать их.

! Precision и Recall особенно полезны при дисбалансе классов, когда один представлен значительно меньше, чем другой

 **F1-мера**
Это среднее гармоническое Precision и Recall, позволяющее совместить их в одну метрику. Эта метрика позволяет найти баланс между Precision и Recall при условии, что они для нам примерно одинаково важны.

$$
F1 = 2 \frac{Recall \cdot Precision }{Recall + Precision} = \frac
{TP} {TP + \frac{FP + FN}{2}}
$$

```python
f1 = sklearn.metrics.f1_score(y_true, y_pred)
```

Есть также функция, возвращающая сразу Recall, Precision и F-меру для каждого из классов, а также количество экземпляров каждого класса.

```python
report = sklearn.metrics.classification_report(y_true, y_pred)
```

**ROC-AUC**
Многие модели бинарной классификации построены на том, что до определенного порога они относят объект к одному классу, а после него - к другому. Соответственно, в зависимости от установленного порога, модель может выдавать разные по качеству результаты.

Чтобы оценить качество модели безотносительно выбранного порога, применяют кривую **ROC-AUC**. В ее основе лежат две другие метрики:

**TPR** (**true positive rate**) – это полнота, доля положительных объектов, правильно предсказанных положительными.

$$
{\text{TPR = Recall Rate}= \frac{TP}{TP + FN}}
$$

**FPR** (**false positive rate**) – это доля отрицательных объектов, неправильно предсказанных положительными.

$$FPR = \frac{FP}{FP + TN}$$

Сама метрика **ROC-AUC** представляет из себя площадь под кривой в осях **TPR[0,1]** и **FPR[0,1]**. Каждая точка на графике соответствует выбору некоторого порога. Чем больше площадь под кривой, тем выше качество алгоритма. Кроме этого, важной является крутизна самой кривой — мы хотим максимизировать TPR, минимизируя FPR, а значит, наша кривая в идеале должна стремиться к точке (0,1).

![Untitled](../Вложения/Машинное%20обучение/Untitled%2015.png)

*Код построения на примере логистической регрессии:*

```python
fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, lr.predict_proba(x_test))
auc_roc = sklearn.metrics.auc(fpr,tpr)

plt.figure(figsize=(10, 8))
plt.plot(fpr, tpr, lw=2, label='ROC curve ')
plt.plot([0, 1], [0, 1])
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve')
plt.show()
```

Лучшее пороговое значение находится в точке касания графика **ROC** и прямой под углом в 45 градусов. 

**PR-AUC**
Аналогичным образом можно оценить площадь под кривой в осях Precision и Recall, постепенно сдвигая порог от 0 до 1. Количество объектов, которым мы приписываем положительный класс, будет увеличиваться, а количество объектов, на самом деле относящихся к положительному классу, очевидно, меняться не будет.

![Untitled](../Вложения/Машинное%20обучение/Untitled%2016.png)

**Average Precision** будет равен площади под получившейся кривой.

```python
precision, recall, thresholds = sklearn.metrics.\
precision_recall_curve(y_test, y_score)

auc_precision_recall = sklearn.metrics.auc(recall, precision)

sklearn.metrics.plot_precision_recall_curve(model, x_test, y_test)
```

**Особенности многоклассовой классификации**
Задачу классификации на K классов можно представить как K задач об отделении класса i от всех остальных. Тогда для каждой из таких подзадач можно посчитать свою матрицу ошибок. 

Посчитать метрики, в таком случае, можно двумя способами:

- **Микроусреднение:** усреднить значение соответствующих элементов всех получившихся матриц, а по средним значениям посчитать Precision, Recall и F-меру.
- **Макроусреднение:** посчитать Precision, Recall и F-меру для каждой матрицы отдельно, а затем усреднить их.

Иногда порядок усреднения может привести к различным результатам, например, в случае дисбаланса классов.

#### Метрики регрессии
В задачах регрессии наша задача сводится к минимизации регрессионных остатков:

$$
e_i = f(x_i) - y_i
$$

то есть ошибок на каждом из предсказанных объектов.

**MSE (mean square error)**

$$
MSE(y^{true}, y^{pred}) = \frac1N\sum_{i=1}^{N} (y_i - f(x_i))^2
$$

```python
mse = sklearn.metrics.mean_squared_error(y_true, y_pred)
```

Квадратично штрафует за большие ошибки на объектах и потому чувствителен к выбросам.

Представляет из себя среднее арифметическое суммы квадратов отклонений прогнозов от реальных значений целевой переменной.

**MAE (mean absolute error)**

$$
MAE(y^{true}, y^{pred}) = \frac{1}{N}\sum_{i=1}^{N} \left|y_i - f(x_i)\right|
$$

```python
mae = sklearn.metrics.mean_absolute_error(y_true, y_pred)
```

Выполняет аналогичную функцию, но меньше штрафует за выбросы в данных.

Представляет из себя среднее арифметическое суммы модулей отклонений прогнозов от реальных значений целевой переменной.

**R2 (Коэффициент детерминации)**

$$
R^2 = 1 - \frac{\sum_{i=1}^{N} (y_i - f(x_i))^2}{\sum_{i=1}^{N} (y_i - \bar{y})^2}.
$$

```python
r2 = sklearn.metrics.r2_score(y_true, y_pred)
```

Показывает, какая доля дисперсии таргетов (знаменатель) объяснена моделью.

Принимает значения от 0 до 1. Чем он ближе к единице, тем лучше прогноз соотносится с реальными значениями целевой переменной.

**MAPE** (**mean absolute percentage error**)

$$
MAPE(y^{true}, y^{pred}) = \frac{1}{N} \sum_{i=1}^{N} \frac{ \left|y_i - f(x_i)\right|}{\left|y_i\right|}
$$

Принимает значения от 0 до 1, чем больше - тем хуже.

```python
mape = sklearn.metrics.mean_absolute_percentage_error(y_true, y_pred)
```

Предоставляет среднюю относительную ошибку прогнозов.

**WAPE** (**weighted average percentage error**)

$$
WAPE(y^{true}, y^{pred}) = \frac{\sum_{i=1}^{N} \left|y_i - f(x_i)\right|}{\sum_{i=1}^{N} \left|y_i\right|}
$$

Это нормализованная сумма абсолютной погрешности между фактическим и прогнозируемым значением.

Подходит для случаев, когда используемый набор данных имеет низкие или прерывистые значения. Например, в сценариях, когда данные состоят из нулевых/низких значений чаще, чем ожидается.

! Все вышеописанные метрики легко допускают введение весов для объектов. Если мы из каких-то соображений можем определить стоимость ошибки на объекте, можно брать эту величину в качестве веса. Например, в задаче предсказания спроса в качестве веса можно использовать стоимость объекта.

## Feature engineering и предобработка

### Заполнение пропусков:
https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer
```python
from sklearn.impute import SimpleImputer

simple_imputer = SimpleImputer(missing_values=np.nan, strategy='median')
train_data['credit_count'] = simple_imputer.fit_transform(train_data[['credit_count']])
```
Заменяет пропуски вида missing_values в таблице по одной из стратегий:<br>
mean, median, most_frequent, constant.<br>
https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html
```python
from sklearn.impute import KNNImputer

knn_imputer = KNNImputer(missing_values=np.nan, 
                         n_neighbors=5)
numeric_columns = [column for column in knn_fillna.columns if knn_fillna[column].dtype != 'O']
knn_fillna_num = knn_fillna[numeric_columns].copy()
knn_fillna_num = knn_imputer.fit_transform(knn_fillna_num)

knn_fillna['credit_count'] = knn_fillna_num[:, numeric_columns.index('credit_count')]
```
Применяет метод ближайших соседей, чтобы заполнить пропуски на основании средних среди похожих строк в датасете.

* Категориальные признаки чаще всего логично заменять новым значением, например "ДРУГОЕ". 
* Если по какому-то признаку пропусков слишком много (большая часть), этот признак логично исключить.
* Если какой-то из объектов в Train-выборке имеет слишком много пропусков, его также можно исключить, однако к Test-выборке это не применимо.
* Аналогично, нельзя использовать признаки Test-выборки, чтобы заполнять в ней пропуски. Например, **мы можем обучить KNNImputer на тренировочной выборке и использовать его для заполнения пропусков в тестовой, но обучать его сразу на тестовой нельзя. То же самое касается заполнения пропусков средним, медианой и т.д.**

```python
class my_imputer():
    
    def __init__(self):
        
        self.imp_libr = {}
    
    def fit_(self, df, column, missing_values=np.nan, strategy='median'):
        
        if column not in self.imp_libr:
            simple_imputer = SimpleImputer(missing_values=missing_values, strategy=strategy)
            simple_imputer.fit(df[[column]])
            self.imp_libr[column] = simple_imputer
            print(f'Добавлен Imputer для {column}')
        else:
            pass
    
    def transform_(self, df, column):
        
        if column not in self.imp_libr:
	        print(f'Сначала необходимо завести Imputer для столбца {column}')
            return df['column']
            
        else:
            print(f'Заполнен столбец {column}')
            return self.imp_libr[column].transform(df[[column]])
```
### Кодирование категориальных признаков:
Чтобы отобразить в такой системе категориальные признаки, принимающие M признаков, применяют one-hot кодирование, то есть заменяют столбец с признаком на M-1 столбец со значениями 0 и 1.

```python
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(drop='if_binary', sparse_output=False)
ohe.fit(train_data[categorical_columns])

new_category_columns = ohe.transform(train_data[categorical_columns])
new_train_columns = pd.DataFrame(new_category_columns, columns=ohe.get_feature_names_out())

train_data = train_data.drop(columns=categorical_columns)
train_data = pd.concat([train_data, new_train_columns], axis=1)
train_data.head()
```

Если в категориальной колонке много разных признаков, их можно предварительно обработать. К примеру, можно избавиться от признаков, которые встречаются слишком редко, заменив их на 'ДРУГОЕ', или вывести на их основе новые признаки, а после этого уже проводить one-hot кодирование.

В некоторых случаях можно также превращать числовые признаки в дискретные, деля их на группы по квантилям.<br>
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html
```python
a = pd.DataFrame({'val':[i for i in range(100)]})
a['q_val'] = pd.qcut(a['val'], q=5, labels=False)
```
![](../Вложения/Машинное%20обучение/Pasted%20image%2020251012165727.png)<br>
К таким признакам тоже можно далее применить one-hot кодирование.

## Метод ближайших соседей

Это парадигма, идея которой заключается в том, чтобы рассматривать объекты как точки, находящиеся, например, в пространстве R^p, где p - количество признаков этих объектов. Тогда мы можем   как-то расположить все имеющиеся точки в этом пространстве, а затем для каждой точки определить ее соседей, то есть те точки, которые находятся ближе всего друг к другу. 

После того, как найден способ расположить точки в пространстве, а также способ определить расстояние между точками, можно достаточно легко работать с новыми точками, для которых мы хотим что-то найти.

**В задаче классификации:** 

- Вычислить расстояние от нового объекта до каждого из объектов обучающей выборки
- Отобрать k объектов обучающей выборки, расстояние до которых минимально
- Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди k ближайших соседей

**В задаче регрессии:**

- Вычислить расстояние от нового объекта до каждого из объектов обучающей выборки
- Отобрать k объектов обучающей выборки, расстояние до которых минимально
- Взять в качестве значения таргета среднее или медианное значение таргетов k ближайших соседей

Качество классификации/регрессии методом ближайших соседей зависит от нескольких параметров:

- Числа соседей
- Метрики расстояния между объектами (часто используются метрика Хэмминга, евклидово расстояние, косинусное расстояние и расстояние Минковского). При использовании большинства метрик значения признаков надо масштабировать.
- Весов соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его "голос")

Предсказания по методу k общих соседей не требуют обучения модели как такового. Все вычисления начинаются в тот момент, когда мы пытаемся определить класс или значение нашего объекта. С одной стороны это плюс, а с другой - минус, поскольку при эксплуатации модель kNN затрачивает довольно большие мощности.

Вместо исходных примеров можно брать аггрегаты объектов одного класса, чтобы уменьшить количество точек и облегчить вычисления.

Также известно, что с увеличением размерности расстояния начинают значить все меньше и меньше и эффективность модели становится сомнительной (проклятие размерности).

```python
knn_class = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)
knn_reg = sklearn.neighbors.KNeighborsRegressor(n_neighbors=5)
```

*algorithm: {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’*

*metric: {"minkowski", "manhattan", "euclidean", "chebyshev”}, default=’minkowski’*

*weights: {‘uniform’, ‘distance’}, default=’uniform’*

## Линейные модели

Задачу классификации и регрессии можно представить как задачу поиска наилучшего отображения из множества объектов в множество таргетов. Выбор модели задает определенное параметризированное семейство функций, в котором в последствие ищется решение.

Одно из таких семейств функций называется линейными и имеет вид:

$$
y = w_1 x_1 + \ldots + w_D x_D + w_0,
$$

$$
y - целевая \ переменная \ (таргет)\\
(x_1, \ldots, x_D) - вектор \  признаков \ (фичи)\\ (w_1, \ldots, w_D, w_0) - параметры \ модели \ (веса) \\ w_0 - свободный \ коэффициент \ (bias)
$$

![Untitled](../Вложения/Машинное%20обучение/Untitled%2017.png)

Следовательно, задача сводится к подбору такого вектора весов, который наилучшим образом будет выполнять предсказательную функцию.

Вектор признаков обязательно должен представлять из себя набор численных признаков, к которому необходимо заранее привести все фичи.

Важная особенность линейных моделей - их интерпретируемость. Глядя на получившиеся коэффициенты, мы можем понять, как тот или иной признак влияет на модель, является он положительным или отрицательным и т.д. Это может помочь объяснить получившиеся результаты заказчику. Однако веса сильно зависят от подобранных признаков, и доверять им полностью не стоит.

### Приложение к регрессии

Наилучших вектор весов - это такой набор параметров, с которым ошибка модели минимальна.

Функция, оценивающая, как часто модель ошибается, называется функцией потерь или лоссом. Ее оптимизация и лежит в основе обучения.

Лосс можно измерять разными способами. Самый простой вариант - это брать евклидово расстояние межу вектором таргетов и вектором предсказаний модели:

$$L(f, X, y) = |y - f(X)|_2^2 = \sum_{i=1}^N(y_i - \langle x_i, w \rangle)^2$$

Либо же можно брать СКО этого расстояния или же MSE:

$$
{\text{MSE}(f, X, y) =  \frac{1}{N}|y - X w|_2^2}
$$

Таким образом, задача оптимизации сводится к решению следующей оптимизационной задачи:

$$
{|y - Xw|_2^2 \longrightarrow \min_w}
$$

Главный враг линейных моделей - мультиколлинеарность , то есть приближенная линейная зависимость между несколькими признаками. Из-за нее вычисления могут значительно усложниться, а модель может потерять интерпретируемость. 

В частности, для решения проблемы мультиколлинеарности применяют **регуляризацию**.

L1-регуляризация способствует разреженности функции, когда лишь немногие факторы не равны нулю. L2-регуляризация способствует появлению малых весовых коэффициентов модели, но не способствует их точному равенству нулю.

- L1-регуляризация зануляет веса при всех сильно скоррелированных признаках, кроме одного. Таким образом, в алгоритм встроен механизм отбора признаков (feature selection) — его применяют, когда нужно снизить размерность и избавиться от дублирующих признаков.
- L2-регуляризация предотвращает переобучение модели путём запрета на непропорционально большие весовые коэффициенты. В этом случае веса между скоррелированными признаками будут распределены примерно равномерно.

```python
# перед тем как применять линейную модель нужно стандартизировать данные:

# приводит к матожиданию 0 и СКО 1
scaler = sklearn.preprocessing.StandardScaler() 
df = scaler.fit_transform(df)
```

```python
lr = sklearn.linear_model.LinearRegression() # простая линейная регрессия

lr_l1 = sklearn.linear_model.Lasso() #L-1 регуляризация

lr_l2 = sklearn.linear_model.Ridge() #L-2 регуляризация
```

```python
# веса при признаках выводят атрибутом .coef_ модели:
print(model.coef_) 
# а значение нулевого коэффициента (англ. intercept) — атрибутом .intercept_. 
print(model.intercept_)
```

### Приложение к классификации

Задача обучения линейной модели классификации сводится к тому, чтобы задать плоскость, которая будет наилучшим образом отделять объекты одного класса от другого. К сожалению, полноценные линейно разделимые плоскости встречаются редко.

Рассмотрим задачу на примере бинарной классификации:

Допустим, объекты в выборке делятся на два класса: (-1, 1).

Тогда предсказания модели будет иметь вид:

$$
y = \text{sign} \langle w, x_i\rangle
$$

А задача оптимизации вид:

$$
\sum_i \mathbb{I}[y_i \neq sign \langle w, x_i\rangle]\longrightarrow \min_w
$$

Или:

$$
\sum_i \mathbb{I}[y_i \langle w, x_i\rangle < 0]\longrightarrow \min_w
$$

Величина $M = y_i \langle w, x_i\rangle$ называется **отступом** (**margin**) классификатора. Такая функция потерь называется **misclassification loss**. Эта величина положительна, когда класс угадан верно, и отрицательная, когда модель ошибается.

От каждого из отступов можно вычислить функцию:

$$
F(M) = \mathbb{I}[M < 0] = \begin{cases}1,\ M < 0,\\ 0,\ M\geqslant 0\end{cases}
$$

Эта функция кусочно-постоянная, поэтому ее нельзя оптимизировать из-за недифференцируемости. Однако вместо нее можно рассматривать другую гладкую функцию и оптимизировать ее. Тогда требуемый результат будет достигнут.

**SVM (метод опорных векторов)**

Используем вместо M функцию: $F(M) = \max(0, 1-M)$

![Untitled](../Вложения/Машинное%20обучение/Untitled%2021.png)

Задача - не только найти разделяющую прямую, но и постараться провести её на одинаковом удалении от обоих классов, то есть максимизировать минимальный отступ.

Максимизируя минимальный отступ, мы максимизируем $\frac{2}{|w|_2}$ , то есть ширину полосы:

$$
\lambda|w|^2_2 + \sum_i \max(0, 1-y_i \langle w, x_i\rangle) \longrightarrow\min\limits_{w}
$$

Второе слагаемое – это штраф за то, что некоторые объекты неправильно расположены относительно разделительной полосы.

Итоговое положение плоскости задаётся всего несколькими обучающими примерами. Это ближайшие к плоскости правильно классифицированные объекты, которые называют **опорными векторами**.

```python
# необходима предварительная стандартизация
svc = sklearn.svm.SVC()
```

**Логистическая регрессия**

Идея логистической регрессии заключается в том, чтобы представить классификацию как задачу предсказание вероятностей принадлежности объекта к тому или иному классу.

Если быть точным, объектом предсказания логистической регрессии являются логиты (logits), логарифмы отношения вероятности положительного события к отрицательному:

$$
\langle w, x_i\rangle = \log\left(\frac{p}{1-p}\right)
$$

Искомая же вероятность вычисляется как:

$$p=\frac{1}{1 + e^{-\langle w, x_i\rangle}}\\{\sigma(z) = \frac1{1 + e^{-z}}}\\p = \sigma(\langle w, x_i\rangle)$$

где  $\sigma(\langle w, x_i\rangle)$ - функция под названием **сигмоид**.

$p = \sigma(\langle w, x_i\rangle)$ - это вероятность положительного класса. Переход от нее к предсказанию класса производится через установление порога вероятности, который будет определять, к какому классу отнести очередной объект.

Подбор этого порога правильно осуществлять на отложенной выборке. Например, сделать так, чтобы доля положительных и отрицательных классов примерно совпадала с реальной.

В качестве функции потерь для логистической регрессии может использоваться **LogLoss** (выводится из метода максимального правдоподобия):<br>
![](../Вложения/Машинное%20обучение/Pasted%20image%2020251019142035.png)

```python
lr = sklearn.linear_model.LogisticRegression()
```

**Многоклассовая классификация**

Задачу классификации объектов на K классов при помощи линейных моделей рассматривают как набор бинарных классификаций, которые реализуются один из двух основных способов:

- **Один против всех (one-versus-all)**

Обучаются K классификаторов, каждый из которых отличает i-ый класс от всех остальных:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2022.png)

Затем сравниваются значения линейных функций:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2023.png)

и для каждой точки выбирается тот класс, которому соответствует большее значение, то есть самый «уверенный» классификатор:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2024.png)

Основная проблема данного подхода заключается в том, что каждый классификатор обучается на своей выборке, из-за чего их выходы могут иметь разные масштабы.

- **Все против всех (all-versus-all)**

Обучаются $C_K^2$ классификаторов, по одному для каждой пары классов:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2025.png)

Каждый новый объект подается на вход каждого их классификаторов, они голосуют за свой класс и в ответ идет тот, за которого было отдано больше всего голосов:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2026.png)

![](../Вложения/Машинное%20обучение/Pasted%20image%2020251019142138.png)<br>
Для реализации предсказываем логиты для каждого класса и применяем к ним **Softmax**, чтобы выбрать наиболее вероятный вариант.<br>
![](../Вложения/Машинное%20обучение/Pasted%20image%2020251019142311.png)<br>
![](../Вложения/Машинное%20обучение/Pasted%20image%2020251019142348.png)
## Решающие деревья

Это семейство моделей классификации и регрессии, которые сами по себе имеют не слишком высокую обобщающую способность, но обладают очень важными свойствами:

- Являются интерпретируемыми
- Быстро работают после обучения
- Выступают в качестве блоков при построении ансамблей

Идея работы решающего дерева заключается в следующем:

- Сперва на основе признаков имеющихся данных (диаграммы рассеяния) строятся так называемые решающие поверхности. Это участки пространства, разделенные линиями или плоскостями, на которых доминирует тот или иной класс таргетов или на котором можно выделить определенное значение регрессии.
- Алгоритм отнесения объекта к тому или иному классу представляется в виде дерева: в зависимости от своего положения (признаков) он постепенно спускается от корня дерева к одному из листов, который и содержит ответ.
- Логические операторы в каждом узле дерева называются предикатами.
    
    ![Untitled](../Вложения/Машинное%20обучение/Untitled%2027.png)
    
- Таким образом, дерево осуществляет кусочно-постоянную аппроксимацию целевой зависимости, а его точность зависит от его глубины:
    
    ![Untitled](../Вложения/Машинное%20обучение/Untitled%2028.png)
    

При этом деревья очень склонны к переобучению. Если не ограничивать их высоту, они могут просто запомнить всю обучающую выборку, идеально подстроившись под нее:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2029.png)

![Untitled](../Вложения/Машинное%20обучение/Untitled%2030.png)

Такие модели бесполезны для предсказания значений, которых не было в тестовой выборке, поэтому необходимо, во-первых, выставлять ограничения на высоту или производить “обрезку дерева” (pruning), а во-вторых, иметь достаточно большое количество данных, чтобы  модель могла найти в них какие-то закономерности.

### Жадный алгоритм построения решающего дерева
Алгоритм построения дерева строится на трех вспомогательных функциях:

$\color{#ff5050} Stop(X_m):$ решает, нужно ли продолжать ветвление или пора остановиться. Например, остановиться только в тот момент, когда объекты в листе получились достаточно однородными и/или их не слишком много.

$\color{#a6ff4d} Ans(X_m):$  вычисляет ответ для листа по попавшим в него объектам из обучающей выборки. Может быть, к примеру, меткой самого частого класса или оценкой дискретного распределения вероятностей классов для объектов в этом листе (классификация) или средним, медианой или другой статистикой (регрессия).

$\color{#6699ff} Branch(X_m, feature, value):$ измеряет, насколько хорош предлагаемый сплит. Чаще всего эта функция оценивает, насколько улучшится некоторая финальная метрика качества дерева в случае, если получившиеся два листа будут терминальными, по сравнению с ситуацией, когда сама исходная вершина является листом.

Пускай $X$ - исходное множество объектов обучающей выборки, а $X_m$ — множество объектов, попавших в текущий лист (в самом начале они равны). Тогда:

1. Создаём вершину $v$.
2. Если выполнен критерий $\color{#ff5050} Stop(X_m)$, то останавливаемся, объявляем эту вершину листом и ставим ей в соответствие ответ $\color{#a6ff4d} Ans(X_m)$, после чего возвращаем её.
3. Иначе: находим предикат (иногда ещё говорят *сплит*), который определит наилучшее разбиение текущего множества объектов $X_m$ на две подвыборки $X_l$ и $X_r$, максимизируя *критерий ветвления* $\color{#6699ff} Branch(X_m, feature, value)$.

Подбор оптимального сплита базируется на понятии загрязненности (impurity). Это вероятность того, что случайно выбранный экземпляр будет классифицирован ошибочно. Это значение мы хотим минимизировать.

### Критерии ветвления
**Для регрессии:**
- **MSE** $= {H(X_m) = \sum\limits_{(x_i, y_i) \in X_m}\frac{\left(y_i - \overline{y} \right)^2}{|X_m|}, ~ \text{где} ~ \overline{y} = \frac{1}{\vert X_m \vert} \sum_i y_i}$

Для минимизации загрязненности, минимизируем среднеквадратичную ошибку.<br>
Для этого оцениваем дисперсии таргетов для объектов, попавших в лист. Оценка значения в каждом листе — это среднее, а выбирать сплиты надо так, чтобы сумма дисперсий в листьях была как можно меньше.

- **MAE $= H(X_m) = \sum\limits_{(x_i, y_i) \in X_m}\frac{|y_i - MEDIAN(Y)|}{|X_m|}$**

Для минимизации загрязненности, минимизируем среднюю абсолютную ошибку.<br>
Для этого минимизируем абсолютное отклонение от медианы.

**Для классификации:**<br>
Подбираем такую функцию **H**, чтобы выполнялось правило (при классификации на две группы - L и R):

$$\frac{L}{Q}*H(Pl)+\frac{R}{Q}*H(Pr)\xrightarrow{}min$$

- **Misclassification Error** $= H(X_m) = 1 - p_{k_{\ast}}$
- **Энтропия** $= {H(X_m) = -\sum_{k = 1}^K p_k \log p_k}$
- **Индекс Джини** $= {H(X_m) = \sum_{k = 1}^K p_k (1 - p_k)}$<br>
где $p_k$ - доля объектов класса k в текущей вершине,<br>
Q - общее количество объектов в вершине.<br>
![600](../Вложения/Машинное%20обучение/file-20251109122530452.png)

```python
# Классификация:

dtc = sklearn.tree.DecisionTreeClassifier(
# критерий: {“gini”, “entropy”, “log_loss”}
criterion = 'gini', 
# максимальная глубина дерева
max_depth = 5,
# минимальное число элементов в узле
min_samples_split = 5,
# минимальное число элементов в листе
min_samples_leaf = 5,
# веса для классов
class_weight = None
)
```

```python
# Регрессия:

dtr = sklearn.tree.DecisionTreeRegressor(
# критерий {“squared_error”, “friedman_mse”, “absolute_error”, “poisson”}
criterion = 'squared_error',
# максимальная глубина дерева
max_depth = 5,
# минимальное число элементов в узле
min_samples_split = 5,
# Минимальная взвешенная доля от общей суммы весов, 
# которая должна находиться в конечном узле
min_weight_fraction = 0
)
```

```python
# отрисовка дерева в виде изображения

dtc = dtc.fit(x_train, y_train)
plt.figure(figsize = (20,15)) 
sklearn.tree.plot_tree(dtc)
plt.show()
```

```python
# важность признаков для модели

print(dtc.feature_importances_)
```

## Ансамбли

Идея этого подхода базируется на стремлении получить более точные предсказания, используя не одну слабую модель, а сразу много. Тогда их усредненный результат *(для регрессии)* или большинство голосов за принадлежность к какому-то классу *(для классификации)* будет значительно более приближен к реальности, чем результат каждой модели по-отдельности.  

Существует несколько способов реализации этого подхода:
- **Стекинг**
- **Бэггинг**
- **Бустинг**
### Бэггинг (bootstrap aggregation)
Это стандартный ансамблевый метод, который работает с группе базовых алгоритмах **одного семейства**.<br>
Стандартный алгоритм бэггинга таков:
- Имеем выборку из N объектов.
- Возьмем из нее новую выборку размера N при помощи бутстрепирования, то есть с возвращением. Какие-то объекты из изначальной выборки не попадут в новую, а какие-то попадут в нее несколько раз.
- Обучим на получившейся выборке какую-то модель и повторим процедуру.
- После k итераций у нас будет k базовых моделей, обученных на k разных выборок.
- Итоговое предсказание же будет делать ансамбль этих моделей, то есть модель, которая будет выносить решение основываясь на усредненном показателе базовых моделей *(для регрессии)* или на методе простого голосования *(для классификации)*.

$$
 \color{pink}a(x)  \color{white}=\frac{1}{k}\color {brown}(b_1(x) + \dots + b_k(x)).
$$

Такой подход позволяет очень сильно уменьшить дисперсию предсказания моделей, то есть Variance, при условии, что базовые модели не скоррелированы. 

**Случайный лес - бэггинг над решающими деревьями**<br>
Немного отличающаяся версия бэггинга для решающих деревьев называется случайный лес.<br>
Алгоритм построения такой модели таков:
- Имеем выборку из N объектов.
- Возьмем из нее новую выборку размера n при помощи бутстрепирования, то есть с возвращением. Какие-то объекты из изначальной выборки не попадут в новую, а какие-то попадут в нее несколько раз.
- Выберем случайное число признаков и обучим очередное дерево только на них. Такой подход позволяет управлять скоррелированностью базовых алгоритмов.
- Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев *(для регрессии)* или берём самый популярный класс *(для классификации)*.

```python
rfc = sklearn.ensemble.RandomForestClassifier(
# число деревьев в лесу (можно сделать больше, а потом уменьшать)
n_estimators=100, 
# критерий {“gini”, “entropy”, “log_loss”}
criterion='gini', 
# максимальная глубина дерева
max_depth=5, 
# минимальное число элементов в узле
min_samples_split = 5,
# минимальное число элементов в листе
min_samples_leaf = 5,
# вычисление out-of-bag ошибки,
# альтернатива кросс-валидации для мелких выборок
oob_score=False, 
# позволяет наращивать выборку новыми деревьями
warm_start=False, 
# веса для классов
class_weight=None,
# ограничение на количество признаков, доступных каждому дереву
# {“sqrt”, “log2”, None, int}
max_features = 'sqrt')
```

```python
rfr = sklearn.ensemble.RandomForestRegressor(
# число деревьев в лесу (можно сделать больше, а потом уменьшать)
n_estimators=100, 
# критерий {“squared_error”, “friedman_mse”, “absolute_error”, “poisson”}
criterion='squared_error', 
# максимальная глубина дерева
max_depth=None, 
# минимальное число элементов в узле
min_samples_split = 5,
# минимальное число элементов в листе
min_samples_leaf = 5,
# альтернатива кросс-валидации для мелких выборок
oob_score=False, 
# позволяет наращивать выборку новыми деревьями
warm_start=False,
# Минимальная взвешенная доля от общей суммы весов, 
# которая должна находиться в конечном узле
min_weight_fraction_leaf=0.0,
# ограничение на количество признаков, доступных каждому дереву
# {“sqrt”, “log2”, None, int}
max_features = 'sqrt'
```

При помощи случайного леса можно также проверять важность признаков. Для этого можно брать признаки, по очереди перемешивать их внутри своего столбца и смотреть, улучшилось качество модели или нет. Признаки, показывающие наиболее серьезное ухудшение метрик, наиболее релевантны. 

$\sum_{ij} w_{ij}^2$

$\sum_{ij} |w_{ij}|$

### Стекинг
**Идея стекинга** заключается в следующем:
* Обучить несколько **разноплановых алгоритмов** на имеющихся данных.
* Добавить предсказания базовых моделей в набор признаков.
* Обучить мета-модель на этом наборе признаков и использовать ее для принятия окончательного решения.

**Обучение стекинга** проходит в несколько этапов:
* Общая выборка разделяется на тренировочную и тестовую.
* Тренировочная выборка делится на n фолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации. Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались.
* На полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. Выбор зависит от решаемой задачи.<br>
![600](../Вложения/Машинное%20обучение/file-20251109131931728.png)<br>
![600](../Вложения/Машинное%20обучение/file-20251109131936582.png)<br>
Если данных достаточно много, то можно просто разделить обучающие данные на две непересекающиеся части: ту, на которой учатся базовые алгоритмы, и ту, на которой они делают свои предсказания и обучается мета-модель. Использование такого простого разбиения вместо кросс-валидации на тренировочных данных иногда называют **блендингом (blending)**.

*Пример реализации для задачи классификации:*
```python
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Создаем синтетические данные
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Определяем базовые модели
base_models = [
    ('dt', DecisionTreeClassifier(max_depth=5)),
    ('svm', SVC(probability=True, random_state=42))
]

# Мета-модель
meta_model = LogisticRegression()

# Создаем стекинг-классификатор
stacking_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=5  # используем кросс-валидацию для создания мета-признаков
)

# Обучаем модель
stacking_model.fit(X_train, y_train)

# Делаем предсказания
y_pred = stacking_model.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
```
### Бустинг
Это еще один ансамблевый метод для алгоритмов **одного типа**.<br>
Его идея похожа на **бэггинг**, но основное отличие заключается в том, что каждый следующий базовый алгоритм в бустинге обучается так, чтобы уменьшить общую ошибку всех своих предшественников. То есть обучение происходит не независимо, а **последовательно**.

Решение, в таком случае, принимается взвешенным голосованием всех алгоритмов:

$$a(x)=c_{1}a_{1}(x)+c_{2}a_{2}(x)+\dots+c_{n}a_{n}(x)$$

Поскольку основная цель бустинга — **уменьшение смещения**, в качестве базовых алгоритмов часто выбирают алгоритмы с высоким смещением и небольшим разбросом. Например, если в качестве базовых классификаторов выступают деревья, то их глубина должна быть небольшой — обычно не больше 2-3 уровней. Это важно также потому, что эти алгоритмы учатся быстрее.

### Градиентный бустинг
Наиболее эффективный на сегодняшний день вид бустинга - это  **градиентный бустинг над решающими деревьями**. Это основное продакшн-решение при работе с табличными данными. 

**Схема его работы** выглядит так: мы берем выборку, строим на ней решающее дерево, потом получаем остатки (ошибки), далее уже берем эти ошибки как целевые переменные, снова строим дерево и т. д. Так шаг за шагом мы движемся в сторону наилучшего решения, напоминая процесс градиентного спуска, но не по отдельным параметрам, а по целым функциям, описывающим прогноз.<br>
![](../Вложения/Машинное%20обучение/file-20251109143729910.png)

#### Формально алгоритм для регрессии выглядит так:
Возьмем в качестве функции потерь **MSE**:

$$
 L(y,x)=\frac{1}{2}\sum_{i=1}^{N}(y_{i}-a(x_{i}))^2\xrightarrow{}min
$$

Будем строить композицию из $K$ **базовых алгоритмов** семейства $B$ - **решающих деревьев фиксированной** глубины:

$$
 a(x)=b_{1}​(x)+b_{2}​(x)+\dots+b_{K}​(x)
$$

**Обучим первый алгоритм** $b_{1}$. Скорее всего он будет работать не идеально, но он даст нам какую-то точку старта.

$$
 b_{1}​(x)=argmin\ ​L(y,b(x))
$$

**Вычислим его ошибки** - насколько сильно отличаются предсказания этого дерева от истинных значений:

$$
 s^i_{1}​=y_{i}​−b_{1}​(x_{i}​)
$$

Обучим **второй алгоритм** так, чтобы он **предсказывал ошибки первого**, поскольку тогда их сумма даст нам правильный ответ:

$$
 b_{2}​(x)=argmin\ ​L(s^1,b(x))
$$

Далее рассуждения **повторяются** до построения всей композиции. На $k$-ом шаге **вычисляется разность** между правильным ответом и текущим предсказанием композиции $(k-1)$ алгоритмов. Затем $k$-й алгоритм учится **предсказывать эту разность**:

$$
 b_{k}​(x)=argmin\ ​L(s^{k-1},b(x))
$$

#### Выражение через градиент:
На практике, мы можем заменить обучение на разность $s^{k}_{i}$​ обучением на **антиградиент функции потерь** $(−g^{k}_{i})$ :


$$
 g_i^k =L^{'}_{z}(y_{i},z)\bigg|_{z=a_k(x_i)}
$$
В случае с **MSE** это объясняется тем, что:

![](../Вложения/Машинное%20обучение/file-20251109161332428.png)

![](../Вложения/Машинное%20обучение/file-20251109161345316.png)

Таким образом, для каждого объекта $x_{i}$ очередной алгоритм в бустинге обучается предсказывать антиградиент функции потерь по предсказанию модели $-L^{'}_{z}(y_{i},z)$ в точке $a_{k}(x_{i})$ предсказания текущей части композиции на объекте $x_{i}$​.

Этот же подход можно доказанно распространить на другие функции потерь. Соответственно, наша **оптимизационная задача** будет выглядеть так:

$$
 b_k \approx \underset{b\in \mathcal{B}}{\mathrm{argmin}} \sum_{i = 1}^N b(x_i) g_i^{k - 1}
$$

*Пример для решения задачи регрессии:*
```python
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.datasets import make_regression
from sklearn.metrics import mean_squared_error, r2_score

# Создаем данные для регрессии
X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Модель градиентного бустинга для регрессии
gb_regressor = GradientBoostingRegressor(
    n_estimators=200,
    learning_rate=0.05,
    max_depth=4,
    subsample=0.8,      
    random_state=42
)

gb_regressor.fit(X_train, y_train)

# Предсказания
y_pred = gb_regressor.predict(X_test)

print(f"MSE: {mean_squared_error(y_test, y_pred):.4f}")
print(f"R² Score: {r2_score(y_test, y_pred):.4f}")
```

Другие реализации:
* **XGBoost**: https://xgboost.readthedocs.io/en/stable/
* **CatBoost**: https://catboost.ai/

## Подбор гиперпараметров

Практически у всех видов моделей есть какие-то параметры, которые **фиксируются до начала обучения** (глубина решающего дерева, значение силы регуляризации в линейной модели, learning rate для градиентного спуска) и от выбора которых зависит ее эффективность.<br>
**Цель подбора гиперпараметров** — найти такие значения, при которых модель даёт лучшую метрику на валидации, не переобучаясь. 

### Подходы к подбору
К подбору гиперпараметров можно пойти двумя путями:

1. **Разделение выборки на тренировочную, валидационную и тестовую части**<br>
В таком случае, для каждой модели подбираются гиперпараметры, максимизирующие её метрики на валидации, а окончательное сравнение моделей проводить по тестовым метрикам. Разделения только на тренировочную и тестовую выборки недостаточно, так как в модель через подобранные гиперпараметры просачивается информация о тестовой выборке.

2. **Кросс-валидация**<br>
В этом случае мы фиксируем некоторое тестовое множество и откладываем его. Затем делим оставшееся множество данных на k фолдов, проходим по ним циклом, на каждой итерации фиксируя один фолд в качестве валидационного и обучаясь на остальных. В качестве оценки качества модели можем взять среднее значение валидационной метрики по фолдам. Финальное сравнение моделей с уже подобранными гиперпараметрами проводится на отложенном тестовом множестве.

![700](../Вложения/Машинное%20обучение/file-20251115170906366.png)

Кроме **ручного перебора** возможных значений гиперпараметров существуют различные подходы, которые позволяют решать эту задачу. 
### Grid Search
Идея заключается в том, чтобы задать дискретную сетку значений для каждого гиперпараметра и **перебрать все возможные комбинации**.

```python
from sklearn.model_selection import GridSearchCV

model = DecisionTreeClassifier()

param_grid = {
    "min_samples_split": np.arange(1, 5, 1),
    "max_depth": np.arange(1, 8, 1)
}

grid_search = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    scoring="roc_auc",
    cv=5,
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train_fin, y_train)

print(grid_search.best_params_)
print(grid_search.best_score_)
best_model = grid_search.best_estimator_
---
Fitting 5 folds for each of 28 candidates, totalling 140 fits
{'max_depth': 7, 'min_samples_split': 4}
0.9093314787845861
```

Подробно посмотреть, как проходил отбор, можно через атрибут `cv_results_`:
```python
means = grid_search.cv_results_['mean_test_score']
error = grid_search.cv_results_['std_test_score']
params = grid_search.cv_results_['params']
```

Сразу же видно **естественное ограничение** данного метода: если комбинаций параметров слишком много либо каждое обучение / тест длится долго, алгоритм не завершится за разумное время.
### Random Search
Похожий вариант - **RandomizedSearchCV**. Позволяет вместо полного перебора по сетке случайно выбирать комбинации гиперпараметров из заданных распределений. 

```python
from sklearn.model_selection import RandomizedSearchCV

param_distributions = {    
	"min_samples_split": randint(2, 10),
    "max_depth": randint(3, 20),
}

random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions=param_distributions,
    n_iter=50,
    scoring="roc_auc",
    cv=5,
    random_state=42,
    n_jobs=-1,
    verbose=1
)
```

Для каждого гиперпараметра задается распределение, из которого выбирается его значение. Благодаря такому подходу, найти оптимальный набор гиперпараметров можно быстрее.

### Итерационные методы
В описанных далее методах подбора гиперпараметров будет так или иначе происходить поиск баланса между *exploration* и *exploitation*. Допустим, у нас появилась возможность подбирать гиперпараметры, учитывая результаты предыдущих вычислений. Тогда у нас есть два варианта:

*Exploration*: исследование тех областей, в которых у нас **мало семплов на текущей итерации**, что даёт нам возможность **с меньшей вероятностью пропустить оптимальное значение**.

*Exploitation*: выбирать больше семплов в областях, которые мы достаточно **неплохо изучили** и где, как мы считаем, **с большой вероятностью находится оптимум**.

**Постановка задачи:** пусть наша функция — значение валидационных метрик в зависимости от текущего сочетания гиперпараметров. Её вычисление **затратно по времени** (нужно натренировать и провалидировать модель), и мы **не можем вычислить градиенты** этой функции по её переменным (нашим гиперпараметрам).
#### Байесовская оптимизация
**Байесовская оптимизация** — это итерационный метод, позволяющий оценить оптимум функции, не дифференцируя её. Кроме того, на каждой итерации метод указывает, в какой следующей точке мы с наибольшей вероятностью улучшим нашу текущую оценку оптимума. Это позволяет значительно сократить количество вычислений функции, каждое из которых может быть довольно затратным по времени.

Она хорошо работает, когда нужно оптимизировать **небольшое число гиперпараметров**, так как в наивной реализации алгоритм не поддаётся распараллеливанию. 

В изначальной постановке предполагалась для работы с **непрерывными гиперпараметрами**, а для работы с категориальными гиперпараметрами ей нужны некоторые трюки.
#### Tree-structured Parzen Estimator (TPE)
 В случае с **TPE** также на каждой итерации принимается решение о том, какие следующие значения гиперпараметров нужно выбрать, исходя из результатов предыдущих итераций. Но идейно этот подход имеет довольно сильные отличия.<br>
<br>
 Сначала мы запускаем несколько разных наборов гиперпараметров и собираем историю:<br>
 
$$ 
(x1,y1),(x2,y2),…,(xn,yn)
$$
Затем выбираем порог по качеству $y^∗$, например, такое значение, что 20% лучших запусков имеют $y<y^{*}$.<br>
Делим все наблюдения на две группы:
* «хорошие»: $y_{i}<y^{*}$     
- «плохие» : $y_{i}>=y^{*}$     

Строим две вероятностные модели:<br>
$l(x) = p(x \mid y < y^*)$ - как обычно выглядят **хорошие** гиперпараметры<br>
$g(x) = p(x \mid y \geq y^*)$ - как обычно выглядят **плохие** гиперпараметры

Дальше логика такая - хочется выбирать такие x, которые **часто встречались среди удачных** - большое $l(x)$ и **редко среди неудачных** - маленькое $g(x)$ 

Формально TPE показывает, что максимизация некоторой меры улучшения (Expected Improvement) сводится к выбору тех x, у которых минимально отношение:

$$EL(x)=\frac{g(x)}{l(x)}$$

Алгоритм работает с гиперпараметрами, представляя их в форме дерева:

![700](../Вложения/Машинное%20обучение/file-20251115175116759.png)

Преимущества **TPE**:
* TPE естественно поддерживает **категориальные** параметры, **условные** параметры и **вложенные** структуры;
- Проще **масштабируется** на большее число параметров;
- Проще работает с **дискретными** параметрами;

#### Реализация в Optuna
**Optuna** — это фреймворк для для автоматизированного поиска оптимальных гиперпараметров для моделей машинного обучения. 

**Документация**: https://optuna.org/

Основные сущности в **Optuna** - *Samplers* и *Pruners*.
* *Samplers* - набор алгоритмов для поиска гиперпараметров (по умолчанию используется **TPE**).
* *Pruners* - набор алгоритмов для прореживания экспериментов. *Pruning* - это механизм который позволяет обрывать эксперименты , которые с большой долей вероятности приведут к не оптимальным результатам.

Наилучшие результаты среди *Pruners* показывают:
- Для **RandomSampler** - *MedianPruner* (https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html#optuna.pruners.MedianPruner).
- Для **TPESampler** - *Hyperband* (https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.HyperbandPruner.html#optuna.pruners.HyperbandPruner).

Главные термины:
- *Study* - оптимизация, основанная на функции **objective**.
- *Trial* - разовое исполнение функции **objective**.

Задача *Study* - подобрать оптимальный набор значений гиперпараметров через проведение множественных *Trials* (н-р: `n_trials=100`). 

```python
import optuna

def objective(trial, X_train, y_train):

    max_depth = trial.suggest_int("max_depth", 3, 20)
    min_samples_split = trial.suggest_int("min_samples_split", 2, 10)

    model = DecisionTreeClassifier(
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        random_state=42
    )

    scores = cross_val_score(
        model, X_train, y_train,
        cv=5, scoring="roc_auc", n_jobs=-1
    )

    return scores.mean()


study = optuna.create_study(direction="maximize")
study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=50)

print("Best value:", study.best_value)
print("Best params:", study.best_params)

# Обучаем финальную модель
best_params = study.best_params
best_model = DecisionTreeClassifier(
    **best_params,
    random_state=42
)
best_model.fit(X_train, y_train)
```

Задать характеристики оптимизируемых параметров можно при помощи методов:
1. `suggest_categorical(name, choice)` задает категориальные параметры. 
2. `suggest_float(name, low, high, *, step=None, log=False)` задает параметр типа `float` - число с плавающей точкой.
3. `suggest_int(name, low, high, step=1, log=False)` задает параметр типа `int` - целое число.

Показатели по каждой итерации можно выгрузить в Датафрейм:
```python
study.trials_dataframe()
```

![](../Вложения/Машинное%20обучение/file-20251115190432749.png)






















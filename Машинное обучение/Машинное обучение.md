# Машинное обучение

## Введение

- Моделью машинного обучения можно назвать некую функцию, которая отображает объекты или примеры (samples) в предсказания разного вида (targets).
- В одних случаях, мы основываемся на примерах, чтобы выдавать правильные предсказания для будущих объектов. В других случаях, мы сразу работаем с неразмеченными объектами и ищем закономерности в них.
- В качестве набора примеров можно взять датасет.
- Он состоит из объектов с определенными атрибутами и ответов (targets), то есть целевых параметров, которые мы в дальнейшем хотим предсказывать.
- Атрибуты могут быть разных типов:
    1. Дискретные (категориальные и целочисленные)
    2. Непрерывные (вещественные)
    3. Бинарные (булевые)
    4. Ординальные (ранговые)
    5. изображения, тексты, видео, звук, графы и т.д.
    
- Для решения конкретной задачи нужно правильно подобрать модель обучения и алгоритм обучения.
- Здесь модель выступает в качестве непосредственного метода решения задачи, а алгоритм - в качестве процедуры, которая реализует обучение модели и зависит от внутренних параметров, которые необходимо подобрать.

## Три типа машинного обучения

1. **Обучение с учителем:**

Задача заключается в получении прогнозов о будущих данных на основании заранее маркированных тренировочных данных.

- Задачи классификации - определение дискретных неупорядоченных меток принадлежности объекта к определенному классу, когда эти классы известны.
- Задачи регрессии - определение значения непрерывной величины на основании имеющихся признаков.
- Отношение порядка - определение рангов исследуемых объектов по отношению друг к другу для создания конечного упорядоченного множества.
1. **Обучение без учителя :** 

Задача заключается в том, чтобы найти закономерности в немаркированных данных или данных с неизвестной структурой и провести более качественный разведывательный анализ.

- Кластеризация  - разделение объектов на заранее неизвестные классы по принципу подобия и отличия по определенному набору признаков.
- Снижение размерности - уменьшение количества признаков для снижения уровня шума и улучшения предсказательной способности других моделей.

![Untitled](../Вложения/Машинное%20обучение/Untitled.png)

1. **Обучение с подкреплением:**

Задача заключается в том, чтобы подобрать оптимальный подход к “взаимодействию со средой” при помощи функции вознаграждения, которая поощряет модель за совершение правильных действий. 

![Untitled](../Вложения/Машинное%20обучение/Untitled%201.png)

Цель - создание автономных самообучающихся агентов.

## Классический алгоритм прогнозного моделирования

![Untitled](../Вложения/Машинное%20обучение/Untitled%202.png)

Очень важной частью машинного обучения является предобработка данных.

- Признаки должны быть тщательно отобраны и не должны коррелировать между собой, поскольку, в противном случае, может возникнуть проблема мультиколлинеарности.
- Для многих моделей важно, чтобы отобранные признаки находились в одной и той же шкале, что достигается, к примеру, через приведение данных к диапазону [0,1] или к стандартизированному нормальному распределению.
- Необходимо внимательно обработать пропуски, дубликаты, выбросы (только из обучающего датасета) и ошибки в данных.
- Отбор фичей можно осуществлять по-разному. Например, можно поочередно выкидывать фичи из датасета и замерять изменение ошибки, фиксируя, становятся показатели лучше или хуже. Также можно дедуктивно выявлять зависимости между факторами и либо объединять их, либо оставлять только один.
- Весь датасет необходимо случайным образом разделить на тренировочный и тестовый наборы, чтобы проверить качество получившейся модели (кросс-валидация).

Разных алгоритмов машинного обучения существует много и никогда нельзя с уверенностью сказать, какой из них выполнит задачу лучше. Поэтому, в любой задаче необходимо проверить несколько разных моделей, а затем сравнить получившиеся на них метрики.

Выбор наиболее релевантных метрик зависит от выбранной модели, особенностей исследования и данных, бизнес-требований и прочего, поэтому к нему нужно подходить внимательно.

![Untitled](../Вложения/Машинное%20обучение/Untitled%203.png)

![Untitled](../Вложения/Машинное%20обучение/Untitled%204.png)

После того, как мы оказываемся удовлетворены качеством модели, мы можем использовать ее для прогнозирования новых будущих данных.

### Переобучение и недообучение

При обучении модели возможны следующие негативные сценарии:

- **Недообучение:** модель допускает слишком много ошибок как на обучении, так и на тестовой выборке. Это значит, что она не уловила существующие взаимосвязи в данных. Причинами этого могут быть:
    - Слишком малое число примеров или признаков;
    - Слишком простая функция;
    - Неверный подход к подбору разных вариантов искомой зависимости;
    
    Недообучение приводит нас к ошибке смещения (high bias).
    
    $$
    \mathbb{V}_X[a(x, X)] = \mathbb{E}_X \left[ a(x, X) - \mathbb{E}_X[a(x, X)] \right]^2
    $$
    
- **Переобучение:** модель показывает хорошие результаты на обучающей выборке, но допускает очень много ошибок на тестовой. Это происходит из-за того, что модель избыточно подстроилась под данные на обучающей выборке (возможно, из-за их зашумленности) и не может на основании их делать какие-то выводы об объектах, которые не видела.
    
    Переобучение приводит нас к ошибке разброса (hugh variance).
    
    $$
    \sigma^2 = \mathbb{E}_x \mathbb{E}_\epsilon[y(x, \epsilon) - f(x)]^2
    $$
    

Понятия Overfit / Underfit и Bias / Variance во многом пересекаются, однако называть их эквивалентными нельзя, потому что в ряде случаев они не пересекаются.

Способность модели не просто подстраиваться к обучающим данным, но и улавливать в них существенные для предсказаний тенденции, называется генерализацией.

![Untitled](../Вложения/Машинное%20обучение/Untitled%205.png)

![Untitled](../Вложения/Машинное%20обучение/Untitled%206.png)

![Untitled](../Вложения/Машинное%20обучение/Untitled%207.png)

![Untitled](../Вложения/Машинное%20обучение/Untitled%208.png)

Стратегии борьбы с высоким Bias:

- Использовать более сложную модель
- Добавить больше параметров
- Увеличить количество данных

Стратегии борьбы с высокой Variance:

- Использовать более простую модель
- Уменьшить количество параметров
- Увеличить количество данных (тоже)

## Оценка качества

### **Подходы к кросс-валидации**

Прежде чем оценивать качество модели, необходимо подготовить данные, на которых ее можно будет обучить и протестировать.

**Кросс-валидация** - метод подтверждения работоспособности модели, позволяющий понять, насколько модель полезна на практике. Основывается на разделении имеющегося набора данных на тренировочный и тестовый разными способами. На тренировочном датасете модель учится, а на тестовом считаются метрики ее успешности. Это позволяет объективно оценить степень генерализации модели и избежать таких проблем, как переобучение.

1. **Hold-out**

Это простое разделение датафрейма на тренировочную и тестовую группы в заданной пропорции. По умолчанию имеет выставленный параметр *shuffle*=True, то есть перед тем, как разделить данные, перемешивает их.

*Датафрейм:*

![Untitled](../Вложения/Машинное%20обучение/Untitled%209.png)

*Код:*

```python
from sklearn.model_selection import train_test_split

targets = df['target']
atributes = df.drop('target',axis=1)

x_train, x_test, y_train, y_test = train_test_split(
    atributes, targets,
		test_size=0.2,
		random_state=42
)
```

Если данных много, то можно также дополнительно создать валидационное множество:

```python
x_train, x_val, y_train, y_val = train_test_split(
    x_train, y_train, 
    test_size=0.1, 
    random_state=42
)
```

Это множество может пригодиться при переборе моделей. Оптимизировать их качества стоит на валидационном множестве, а окончательное сравнение моделей проводить на тестовом множестве. Оптимизация качеств модели может включать в себя подбор гиперпараметров, подбор архитектуры (в случае нейросеток), подбор оптимального трешолда для максимизации значений целевой метрики и т.д.

1. **Стратификация**

Это разбиение на трейн и тест, сохраняющее соотношение классов, представленное в исходном датасете. Стратификация может оказаться полезной, если данные очень несбалансированные и один класс встречается сильно чаще другого. 

```python
x_train, x_test, y_train, y_test = train_test_split(
    atributes, targets, 
    test_size=0.2, 
    random_state=42,
    stratify=y
)
```

1. **K-folds**

Это алгоритм, представляющий из себя обобщение hold-out и состоящий из следующих шагов:

- Фиксируется некоторое целое число k (обычно от 5 до 10), меньшее числа семплов в датасете.
- Датасет разбивается на k одинаковых частей (в последней части может быть меньше семплов, чем в остальных). Эти части называются *фолдами*.
- Далее происходит k итераций, во время каждой из которых один фолд выступает в роли тестового множества, а объединение остальных — в роли тренировочного. Модель учится на k-1 фолде и тестируется на оставшемся.
- Финальный скор модели получается либо усреднением k получившихся тестовых результатов, либо измеряется на отложенном тестовом множестве, не участвовавшем в кросс-валидации.

![Untitled](../Вложения/Машинное%20обучение/Untitled%2010.png)

```python
# функция для получения score на одной итерации;
# можно модифицировать под разные метрики
def get_score(model,x_train,x_test,y_train,y_test):
    model.fit(x_train,y_train)
    return model.score(x_test,y_test)

from sklearn.model_selection import KFold

kf = KFold(n_splits=3) # задаем количество фолдов (k)
scores = []

# на каждой итерации получаем индексы трейна и теста,
# разбиваем датафреймы нужным образом и смотрим score
# тестируемой модели; применяем к разным моделям и выбираем лучшую
for train_index, test_index in kf.split(atributes):
    x_train, x_test = atributes.iloc[train_index], atributes.iloc[test_index]
    y_train, y_test = targets.iloc[train_index], targets.iloc[test_index]
    res = get_score(model,x_train,x_test,y_train,y_test)
    scores.append(res)

print(scores.mean())
```

*Чтобы проводить разделение со стратификацией, можно использовать StratifiedKFold вместо обычного KFold.*

Этот же процесс можно реализовать при помощи метода cross_val_score.

Он принимает модель, данные, таргеты и нужное число фолдов и возвращает массив scores.

```python
from sklearn.model_selection import cross_val_score

# для примера взята логистическая регрессия
lr = LogisticRegression(random_state=42)
scores = cross_val_score(lr,atributes,targets,cv=5)
print(scores)
```

Предобрабатывать и стандартизировать данные нужно до кросс-валидации! 

1. **Кросс-валидация для временных рядов**

Если задача заключается в анализе временных рядов (н-р: что будет с показателями продукта через месяц / год?), то обычные методы кросс-валидации не подходят, поскольку нельзя допустить, чтобы данные пересекались по времени: тренировочные данные должны идти до валидационных, а валидационные — до тестовых. 

Из-за этих особенностей, фолды должны располагаться так:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2011.png)

```python
from sklearn.model_selection import TimeSeriesSplit

tss = TimeSeriesSplit()
 
for train_index, test_index in tss.split(X):
    x_train, x_test = time_atributes.iloc[train_index], time_atributes.iloc[test_index]
    y_train, y_test = targets.iloc[train_index], targets.iloc[test_index]
    res = get_score(model,x_train,x_test,y_train,y_test)
    scores.append(res)

print(scores)
```

### Метрики классификации и регрессии

Метрики, применяемые для оценки качества модели машинного обучения, можно разделить на два вида:

- Online-метрики: вычисляются по данным, собираемым с рабочей системы. Связаны с бизнес-требованиями и могут быть оценены только после введения модели в эксплуатацию.
- Offline-метрики: вычисляются на тестовых данных или с привлечением экспертов, которые выносят свою оценку качества работы модели. Могут быть посчитаны до введения модели в эксплуатацию.

Метрика качества - это объективный критерий успеха, зависящий не от параметров модели, а только от предсказанных меток. В отличие от функции потерь, которая возникает в задаче оптимизации во время построения модели, метрика качества не смотрит на то, что происходит внутри, а оценивает лишь конечный результат.

1. **Метрики бинарной классификации**
- **Confusion matrix**

Это матрица ошибок, которая работает для бинарной классификации и показывает, какую долю ответов модели можно отнести к какой из четырех категорий:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2012.png)

Мы предсказали положительную метку и угадали. Будет относить такие объекты к **true positive** (**TP**) группе (true – потому что предсказали мы правильно, а positive – потому что предсказали положительную метку);

Мы предсказали положительную метку, но ошиблись в своём предсказании – **false positive** (**FP**) (false, потому что предсказание было неправильным);

Мы предсказали отрицательную метку и угадали – **true negative** (**TN**);

Мы предсказали отрицательную метку, но ошиблись – **false negative** (**FN**).

```python
cm = sklearn.metrics.confusion_matrix(y_true,y_pred)
tn, fp, fn, tp = cm.ravel()
```

В некоторых задачах предпочтительнее модели, показывающие меньший FP, в некоторых - меньший FN. Это необходимо решать экспертно.

- **Accuracy**

Это доля объектов, которым мы правильно предсказали класс:

$$
{\text{Accuracy}= \frac{TP + TN}{TP + TN + FP + FN}}
$$

```python
accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)
```

- **Error rate**

Сопряженная с Accuracy метрика, показывающая долю объектов с неправильно предсказанными классами:

$$
{\text{Error Rate}= 1 - Accuracy}
$$

$$
{\text{Error Rate}= \frac{FP + FN}{TP + TN + FP + FN}}
$$

- **Precision (точность)**

Показывает долю правильно предсказанных положительных объектов среди всех объектов, для которых был предсказан положительный класс:

$$
{\text{Precision Rate}= \frac{TP}{TP + FP}}
$$

```python
precision = sklearn.metrics.precision_score(y_true, y_pred)
```

![Untitled](../Вложения/Машинное%20обучение/Untitled%2013.png)

Применяется, когда нам требуется минимальное количество ложноположительных (FP) срабатываний.  

- **Recall (полнота)**

Показывает долю правильно предсказанных положительных объектов среди всех объектов действительно положительного класса:

$$
{\text{Recall Rate}= \frac{TP}{TP + FN}}
$$

```python
recall = sklearn.metrics.recall_score(y_true, y_pred)
```

![Untitled](../Вложения/Машинное%20обучение/Untitled%2014.png)

Применяется, когда нам нужно найти как можно больше объектов положительного класса и по возможности не упускать их.

! Precision и Recall особенно полезны при дисбалансе классов, когда один представлен значительно меньше, чем другой

- **F1-мера**

Это среднее гармоническое Precision и Recall, позволяющее совместить их в одну метрику. Эта метрика позволяет найти баланс между Precision и Recall при условии, что они для нам примерно одинаково важны.

$$
F1 = 2 \frac{Recall \cdot Precision }{Recall + Precision} = \frac
{TP} {TP + \frac{FP + FN}{2}}
$$

```python
f1 = sklearn.metrics.f1_score(y_true, y_pred)
```

Есть также функция, возвращающая сразу Recall, Precision и F-меру для каждого из классов, а также количество экземпляров каждого класса.

```python
report = sklearn.metrics.classification_report(y_true, y_pred)
```

- **ROC-AUC**

Многие модели бинарной классификации построены на том, что до определенного порога они относят объект к одному классу, а после него - к другому. Соответственно, в зависимости от установленного порога, модель может выдавать разные по качеству результаты.

Чтобы оценить качество модели безотносительно выбранного порога, применяют кривую **ROC-AUC**. В ее основе лежат две другие метрики:

- **TPR** (**true positive rate**) – это полнота, доля положительных объектов, правильно предсказанных положительными.

$$
{\text{TPR = Recall Rate}= \frac{TP}{TP + FN}}
$$

- **FPR** (**false positive rate**) – это доля отрицательных объектов, неправильно предсказанных положительными.
    
    $$
    FPR = \frac{FP}{FP + TN}
    $$
    

Сама метрика **ROC-AUC** представляет из себя площадь под кривой в осях **TPR[0,1]** и **FPR[0,1]**. Каждая точка на графике соответствует выбору некоторого порога. Чем больше площадь под кривой, тем выше качество алгоритма. Кроме этого, важной является крутизна самой кривой — мы хотим максимизировать TPR, минимизируя FPR, а значит, наша кривая в идеале должна стремиться к точке (0,1).

![Untitled](../Вложения/Машинное%20обучение/Untitled%2015.png)

*Код построения на примере логистической регрессии:*

```python
fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, lr.predict_proba(x_test))
auc_roc = sklearn.metrics.auc(fpr,tpr)

plt.figure(figsize=(10, 8))
plt.plot(fpr, tpr, lw=2, label='ROC curve ')
plt.plot([0, 1], [0, 1])
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve')
plt.show()
```

Лучшее пороговое значение находится в точке касания графика **ROC** и прямой под углом в 45 градусов. 

- **PR-AUC**

Аналогичным образом можно оценить площадь под кривой в осях Precision и Recall, постепенно сдвигая порог от 0 до 1. Количество объектов, которым мы приписываем положительный класс, будет увеличиваться, а количество объектов, на самом деле относящихся к положительному классу, очевидно, меняться не будет.

![Untitled](../Вложения/Машинное%20обучение/Untitled%2016.png)

**Average Precision** будет равен площади под получившейся кривой.

```python
precision, recall, thresholds = sklearn.metrics.\
precision_recall_curve(y_test, y_score)

auc_precision_recall = sklearn.metrics.auc(recall, precision)

sklearn.metrics.plot_precision_recall_curve(model, x_test, y_test)
```

1. **Особенности многоклассовой классификации**

Задачу классификации на K классов можно представить как K задач об отделении класса i от всех остальных. Тогда для каждой из таких подзадач можно посчитать свою матрицу ошибок. 

Посчитать метрики, в таком случае, можно двумя способами:

- **Микроусреднение:** усреднить значение соответствующих элементов всех получившихся матриц, а по средним значениям посчитать Precision, Recall и F-меру.
- **Макроусреднение:** посчитать Precision, Recall и F-меру для каждой матрицы отдельно, а затем усреднить их.

Иногда порядок усреднения может привести к различным результатам, например, в случае дисбаланса классов.

1. **Метрики регрессии**

В задачах регрессии наша задача сводится к минимизации регрессионных остатков:

$$
e_i = f(x_i) - y_i
$$

то есть ошибок на каждом из предсказанных объектов.

- **MSE (mean square error)**

$$
MSE(y^{true}, y^{pred}) = \frac1N\sum_{i=1}^{N} (y_i - f(x_i))^2
$$

```python
mse = sklearn.metrics.mean_squared_error(y_true, y_pred)
```

Квадратично штрафует за большие ошибки на объектах и потому чувствителен к выбросам.

Представляет из себя среднее арифметическое суммы квадратов отклонений прогнозов от реальных значений целевой переменной.

- **MAE (mean absolute error)**

$$
MAE(y^{true}, y^{pred}) = \frac{1}{N}\sum_{i=1}^{N} \left|y_i - f(x_i)\right|
$$

```python
mae = sklearn.metrics.mean_absolute_error(y_true, y_pred)
```

Выполняет аналогичную функцию, но меньше штрафует за выбросы в данных.

Представляет из себя среднее арифметическое суммы модулей отклонений прогнозов от реальных значений целевой переменной.

- **R2 (Коэффициент детерминации)**

$$
R^2 = 1 - \frac{\sum_{i=1}^{N} (y_i - f(x_i))^2}{\sum_{i=1}^{N} (y_i - \bar{y})^2}.
$$

```python
r2 = sklearn.metrics.r2_score(y_true, y_pred)
```

Показывает, какая доля дисперсии таргетов (знаменатель) объяснена моделью.

Принимает значения от 0 до 1. Чем он ближе к единице, тем лучше прогноз соотносится с реальными значениями целевой переменной.

- **MAPE** (**mean absolute percentage error**)

$$
MAPE(y^{true}, y^{pred}) = \frac{1}{N} \sum_{i=1}^{N} \frac{ \left|y_i - f(x_i)\right|}{\left|y_i\right|}
$$

Принимает значения от 0 до 1, чем больше - тем хуже.

```python
mape = sklearn.metrics.mean_absolute_percentage_error(y_true, y_pred)
```

Предоставляет среднюю относительную ошибку прогнозов.

**WAPE** (**weighted average percentage error**)

$$
WAPE(y^{true}, y^{pred}) = \frac{\sum_{i=1}^{N} \left|y_i - f(x_i)\right|}{\sum_{i=1}^{N} \left|y_i\right|}
$$

Это нормализованная сумма абсолютной погрешности между фактическим и прогнозируемым значением.

Подходит для случаев, когда используемый набор данных имеет низкие или прерывистые значения. Например, в сценариях, когда данные состоят из нулевых/низких значений чаще, чем ожидается.

! Все вышеописанные метрики легко допускают введение весов для объектов. Если мы из каких-то соображений можем определить стоимость ошибки на объекте, можно брать эту величину в качестве веса. Например, в задаче предсказания спроса в качестве веса можно использовать стоимость объекта.

## Feature engineering и предобработка

### Заполнение пропусков:
https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer
```python
from sklearn.impute import SimpleImputer

simple_imputer = SimpleImputer(missing_values=np.nan, strategy='median')
train_data['credit_count'] = simple_imputer.fit_transform(train_data[['credit_count']])
```
Заменяет пропуски вида missing_values в таблице по одной из стратегий: 
mean, median, most_frequent, constant.
https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html
```python
from sklearn.impute import KNNImputer

knn_imputer = KNNImputer(missing_values=np.nan, 
                         n_neighbors=5)
numeric_columns = [column for column in knn_fillna.columns if knn_fillna[column].dtype != 'O']
knn_fillna_num = knn_fillna[numeric_columns].copy()
knn_fillna_num = knn_imputer.fit_transform(knn_fillna_num)

knn_fillna['credit_count'] = knn_fillna_num[:, numeric_columns.index('credit_count')]
```
Применяет метод ближайших соседей, чтобы заполнить пропуски на основании средних среди похожих строк в датасете.

* Категориальные признаки чаще всего логично заменять новым значением, например "ДРУГОЕ". 
* Если по какому-то признаку пропусков слишком много (большая часть), этот признак логично исключить.
* Если какой-то из объектов в Train-выборке имеет слишком много пропусков, его также можно исключить, однако к Test-выборке это не применимо.
* Аналогично, нельзя использовать признаки Test-выборки, чтобы заполнять в ней пропуски. Например, **мы можем обучить KNNImputer на тренировочной выборке и использовать его для заполнения пропусков в тестовой, но обучать его сразу на тестовой нельзя. То же самое касается заполнения пропусков средним, медианой и т.д.**

```python
class my_imputer():
    
    def __init__(self):
        
        self.imp_libr = {}
    
    def fit_(self, df, column, missing_values=np.nan, strategy='median'):
        
        if column not in self.imp_libr:
            simple_imputer = SimpleImputer(missing_values=missing_values, strategy=strategy)
            simple_imputer.fit(df[[column]])
            self.imp_libr[column] = simple_imputer
            print(f'Добавлен Imputer для {column}')
        else:
            pass
    
    def transform_(self, df, column):
        
        if column not in self.imp_libr:
	        print(f'Сначала необходимо завести Imputer для столбца {column}')
            return df['column']
            
        else:
            print(f'Заполнен столбец {column}')
            return self.imp_libr[column].transform(df[[column]])
```
### Кодирование категориальных признаков:
Чтобы отобразить в такой системе категориальные признаки, принимающие M признаков, применяют one-hot кодирование, то есть заменяют столбец с признаком на M-1 столбец со значениями 0 и 1.

![[Машинное обучение/Вложения/Untitled 18.png]]
![[Машинное обучение/Вложения/Untitled 19.png]]
![[Машинное обучение/Вложения/Untitled 20.png]]

```python
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(drop='if_binary', sparse_output=False)
ohe.fit(train_data[categorical_columns])

new_category_columns = ohe.transform(train_data[categorical_columns])
new_train_columns = pd.DataFrame(new_category_columns, columns=ohe.get_feature_names_out())

train_data = train_data.drop(columns=categorical_columns)
train_data = pd.concat([train_data, new_train_columns], axis=1)
train_data.head()
```

Если в категориальной колонке много разных признаков, их можно предварительно обработать. К примеру, можно избавиться от признаков, которые встречаются слишком редко, заменив их на 'ДРУГОЕ', или вывести на их основе новые признаки, а после этого уже проводить one-hot кодирование.

В некоторых случаях можно также превращать числовые признаки в дискретные, деля их на группы по квантилям. 
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html
```python
a = pd.DataFrame({'val':[i for i in range(100)]})
a['q_val'] = pd.qcut(a['val'], q=5, labels=False)
```
![](../Вложения/Машинное%20обучение/Pasted%20image%2020251012165727.png)
К таким признакам тоже можно далее применить one-hot кодирование.
## Метод ближайших соседей

Это парадигма, идея которой заключается в том, чтобы рассматривать объекты как точки, находящиеся, например, в пространстве R^p, где p - количество признаков этих объектов. Тогда мы можем   как-то расположить все имеющиеся точки в этом пространстве, а затем для каждой точки определить ее соседей, то есть те точки, которые находятся ближе всего друг к другу. 

После того, как найден способ расположить точки в пространстве, а также способ определить расстояние между точками, можно достаточно легко работать с новыми точками, для которых мы хотим что-то найти.

**В задаче классификации:** 

- Вычислить расстояние от нового объекта до каждого из объектов обучающей выборки
- Отобрать k объектов обучающей выборки, расстояние до которых минимально
- Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди k ближайших соседей

**В задаче регрессии:**

- Вычислить расстояние от нового объекта до каждого из объектов обучающей выборки
- Отобрать k объектов обучающей выборки, расстояние до которых минимально
- Взять в качестве значения таргета среднее или медианное значение таргетов k ближайших соседей

Качество классификации/регрессии методом ближайших соседей зависит от нескольких параметров:

- Числа соседей
- Метрики расстояния между объектами (часто используются метрика Хэмминга, евклидово расстояние, косинусное расстояние и расстояние Минковского). При использовании большинства метрик значения признаков надо масштабировать.
- Весов соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его "голос")

Предсказания по методу k общих соседей не требуют обучения модели как такового. Все вычисления начинаются в тот момент, когда мы пытаемся определить класс или значение нашего объекта. С одной стороны это плюс, а с другой - минус, поскольку при эксплуатации модель kNN затрачивает довольно большие мощности.

Вместо исходных примеров можно брать аггрегаты объектов одного класса, чтобы уменьшить количество точек и облегчить вычисления.

Также известно, что с увеличением размерности расстояния начинают значить все меньше и меньше и эффективность модели становится сомнительной (проклятие размерности).

```python
knn_class = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)
knn_reg = sklearn.neighbors.KNeighborsRegressor(n_neighbors=5)
```

*algorithm: {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’*

*metric: {"minkowski", "manhattan", "euclidean", "chebyshev”}, default=’minkowski’*

*weights: {‘uniform’, ‘distance’}, default=’uniform’*

## Линейные модели

Задачу классификации и регрессии можно представить как задачу поиска наилучшего отображения из множества объектов в множество таргетов. Выбор модели задает определенное параметризированное семейство функций, в котором в последствие ищется решение.

Одно из таких семейств функций называется линейными и имеет вид:

$$
y = w_1 x_1 + \ldots + w_D x_D + w_0,
$$

$$
y - целевая \ переменная \ (таргет)\\
(x_1, \ldots, x_D) - вектор \  признаков \ (фичи)\\ (w_1, \ldots, w_D, w_0) - параметры \ модели \ (веса) \\ w_0 - свободный \ коэффициент \ (bias)
$$

![Untitled](../Вложения/Машинное%20обучение/Untitled%2017.png)

Следовательно, задача сводится к подбору такого вектора весов, который наилучшим образом будет выполнять предсказательную функцию.

Вектор признаков обязательно должен представлять из себя набор численных признаков, к которому необходимо заранее привести все фичи.

Важная особенность линейных моделей - их интерпретируемость. Глядя на получившиеся коэффициенты, мы можем понять, как тот или иной признак влияет на модель, является он положительным или отрицательным и т.д. Это может помочь объяснить получившиеся результаты заказчику. Однако веса сильно зависят от подобранных признаков, и доверять им полностью не стоит.

### Приложение к регрессии

Наилучших вектор весов - это такой набор параметров, с которым ошибка модели минимальна.

Функция, оценивающая, как часто модель ошибается, называется функцией потерь или лоссом. Ее оптимизация и лежит в основе обучения.

Лосс можно измерять разными способами. Самый простой вариант - это брать евклидово расстояние межу вектором таргетов и вектором предсказаний модели:

$$
L(f, X, y) = |y - f(X)|_2^2 = \sum_{i=1}^N(y_i - \langle x_i, w \rangle)^2

$$

Либо же можно брать СКО этого расстояния или же MSE:

$$
{\text{MSE}(f, X, y) =  \frac{1}{N}|y - X w|_2^2}
$$

Таким образом, задача оптимизации сводится к решению следующей оптимизационной задачи:

$$
{|y - Xw|_2^2 \longrightarrow \min_w}
$$

Главный враг линейных моделей - мультиколлинеарность , то есть приближенная линейная зависимость между несколькими признаками. Из-за нее вычисления могут значительно усложниться, а модель может потерять интерпретируемость. 

В частности, для решения проблемы мультиколлинеарности применяют **регуляризацию**.

L1-регуляризация способствует разреженности функции, когда лишь немногие факторы не равны нулю. L2-регуляризация способствует появлению малых весовых коэффициентов модели, но не способствует их точному равенству нулю.

- L1-регуляризация зануляет веса при всех сильно скоррелированных признаках, кроме одного. Таким образом, в алгоритм встроен механизм отбора признаков (feature selection) — его применяют, когда нужно снизить размерность и избавиться от дублирующих признаков.
- L2-регуляризация предотвращает переобучение модели путём запрета на непропорционально большие весовые коэффициенты. В этом случае веса между скоррелированными признаками будут распределены примерно равномерно.

```python
# перед тем как применять линейную модель нужно стандартизировать данные:

# приводит к матожиданию 0 и СКО 1
scaler = sklearn.preprocessing.StandardScaler() 
df = scaler.fit_transform(df)
```

```python
lr = sklearn.linear_model.LinearRegression() # простая линейная регрессия

lr_l1 = sklearn.linear_model.Lasso() #L-1 регуляризация

lr_l2 = sklearn.linear_model.Ridge() #L-2 регуляризация
```

```python
# веса при признаках выводят атрибутом .coef_ модели:
print(model.coef_) 
# а значение нулевого коэффициента (англ. intercept) — атрибутом .intercept_. 
print(model.intercept_)
```

### Приложение к классификации

Задача обучения линейной модели классификации сводится к тому, чтобы задать плоскость, которая будет наилучшим образом отделять объекты одного класса от другого. К сожалению, полноценные линейно разделимые плоскости встречаются редко.

Рассмотрим задачу на примере бинарной классификации:

Допустим, объекты в выборке делятся на два класса: (-1, 1).

Тогда предсказания модели будет иметь вид:

$$
y = \text{sign} \langle w, x_i\rangle
$$

А задача оптимизации вид:

$$
\sum_i \mathbb{I}[y_i \neq sign \langle w, x_i\rangle]\longrightarrow \min_w
$$

Или:

$$
\sum_i \mathbb{I}[y_i \langle w, x_i\rangle < 0]\longrightarrow \min_w
$$

Величина $M = y_i \langle w, x_i\rangle$ называется **отступом** (**margin**) классификатора. Такая функция потерь называется **misclassification loss**. Эта величина положительна, когда класс угадан верно, и отрицательная, когда модель ошибается.

От каждого из отступов можно вычислить функцию:

$$
F(M) = \mathbb{I}[M < 0] = \begin{cases}1,\ M < 0,\\ 0,\ M\geqslant 0\end{cases}
$$

Эта функция кусочно-постоянная, поэтому ее нельзя оптимизировать из-за недифференцируемости. Однако вместо нее можно рассматривать другую гладкую функцию и оптимизировать ее. Тогда требуемый результат будет достигнут.

**SVM (метод опорных векторов)**

Используем вместо M функцию: $F(M) = \max(0, 1-M)$

![Untitled](../Вложения/Машинное%20обучение/Untitled%2021.png)

Задача - не только найти разделяющую прямую, но и постараться провести её на одинаковом удалении от обоих классов, то есть максимизировать минимальный отступ.

Максимизируя минимальный отступ, мы максимизируем $\frac{2}{|w|_2}$ , то есть ширину полосы:

$$
\lambda|w|^2_2 + \sum_i \max(0, 1-y_i \langle w, x_i\rangle) \longrightarrow\min\limits_{w}
$$

Второе слагаемое – это штраф за то, что некоторые объекты неправильно расположены относительно разделительной полосы.

Итоговое положение плоскости задаётся всего несколькими обучающими примерами. Это ближайшие к плоскости правильно классифицированные объекты, которые называют **опорными векторами**.

```python
# необходима предварительная стандартизация
svc = sklearn.svm.SVC()
```

**Логистическая регрессия**

Идея логистической регрессии заключается в том, чтобы представить классификацию как задачу предсказание вероятностей принадлежности объекта к тому или иному классу.

Если быть точным, объектом предсказания логистической регрессии являются логиты (logits), логарифмы отношения вероятности положительного события к отрицательному:

$$
\langle w, x_i\rangle = \log\left(\frac{p}{1-p}\right)
$$

Искомая же вероятность вычисляется как:

$$
p=\frac{1}{1 + e^{-\langle w, x_i\rangle}}\\{\sigma(z) = \frac1{1 + e^{-z}}}\\p = \sigma(\langle w, x_i\rangle)
$$

где  $\sigma(\langle w, x_i\rangle)$ - функция под названием **сигмоид**.

$p = \sigma(\langle w, x_i\rangle)$ - это вероятность положительного класса. Переход от нее к предсказанию класса производится через установление порога вероятности, который будет определять, к какому классу отнести очередной объект.

Подбор этого порога правильно осуществлять на отложенной выборке. Например, сделать так, чтобы доля положительных и отрицательных классов примерно совпадала с реальной.

В качестве функции потерь для логистической регрессии может использоваться **LogLoss** (выводится из метода максимального правдоподобия):
![](../Вложения/Машинное%20обучение/Pasted%20image%2020251019142035.png)

```python
lr = sklearn.linear_model.LogisticRegression()
```

**Многоклассовая классификация**

Задачу классификации объектов на K классов при помощи линейных моделей рассматривают как набор бинарных классификаций, которые реализуются один из двух основных способов:

- **Один против всех (one-versus-all)**

Обучаются K классификаторов, каждый из которых отличает i-ый класс от всех остальных:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2022.png)

Затем сравниваются значения линейных функций:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2023.png)

и для каждой точки выбирается тот класс, которому соответствует большее значение, то есть самый «уверенный» классификатор:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2024.png)

Основная проблема данного подхода заключается в том, что каждый классификатор обучается на своей выборке, из-за чего их выходы могут иметь разные масштабы.

- **Все против всех (all-versus-all)**

Обучаются $C_K^2$ классификаторов, по одному для каждой пары классов:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2025.png)

Каждый новый объект подается на вход каждого их классификаторов, они голосуют за свой класс и в ответ идет тот, за которого было отдано больше всего голосов:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2026.png)

![](../Вложения/Машинное%20обучение/Pasted%20image%2020251019142138.png)
Для реализации предсказываем логиты для каждого класса и применяем к ним **Softmax**, чтобы выбрать наиболее вероятный вариант.
![](../Вложения/Машинное%20обучение/Pasted%20image%2020251019142311.png)
![](../Вложения/Машинное%20обучение/Pasted%20image%2020251019142348.png)
## Решающие деревья

Это семейство моделей классификации и регрессии, которые сами по себе имеют не слишком высокую обобщающую способность, но обладают очень важными свойствами:

- Являются интерпретируемыми
- Быстро работают после обучения
- Выступают в качестве блоков при построении ансамблей

Идея работы решающего дерева заключается в следующем:

- Сперва на основе признаков имеющихся данных (диаграммы рассеяния) строятся так называемые решающие поверхности. Это участки пространства, разделенные линиями или плоскостями, на которых доминирует тот или иной класс таргетов или на котором можно выделить определенное значение регрессии.
- Алгоритм отнесения объекта к тому или иному классу представляется в виде дерева: в зависимости от своего положения (признаков) он постепенно спускается от корня дерева к одному из листов, который и содержит ответ.
- Логические операторы в каждом узле дерева называются предикатами.
    
    ![Untitled](../Вложения/Машинное%20обучение/Untitled%2027.png)
    
- Таким образом, дерево осуществляет кусочно-постоянную аппроксимацию целевой зависимости, а его точность зависит от его глубины:
    
    ![Untitled](../Вложения/Машинное%20обучение/Untitled%2028.png)
    

При этом деревья очень склонны к переобучению. Если не ограничивать их высоту, они могут просто запомнить всю обучающую выборку, идеально подстроившись под нее:

![Untitled](../Вложения/Машинное%20обучение/Untitled%2029.png)

![Untitled](../Вложения/Машинное%20обучение/Untitled%2030.png)

Такие модели бесполезны для предсказания значений, которых не было в тестовой выборке, поэтому необходимо, во-первых, выставлять ограничения на высоту или производить “обрезку дерева” (pruning), а во-вторых, иметь достаточно большое количество данных, чтобы  модель могла найти в них какие-то закономерности.

**Жадный алгоритм построения решающего дерева:**

Алгоритм построения дерева строится на трех вспомогательных функциях:

$\color{#ff5050} Stop(X_m):$ решает, нужно ли продолжать ветвление или пора остановиться. Например, остановиться только в тот момент, когда объекты в листе получились достаточно однородными и/или их не слишком много.

$\color{#a6ff4d} Ans(X_m):$  вычисляет ответ для листа по попавшим в него объектам из обучающей выборки. Может быть, к примеру, меткой самого частого класса или оценкой дискретного распределения вероятностей классов для объектов в этом листе (классификация) или средним, медианой или другой статистикой (регрессия).

$\color{#6699ff} Branch(X_m, feature, value):$ измеряет, насколько хорош предлагаемый сплит. Чаще всего эта функция оценивает, насколько улучшится некоторая финальная метрика качества дерева в случае, если получившиеся два листа будут терминальными, по сравнению с ситуацией, когда сама исходная вершина является листом.

Пускай $X$ - исходное множество объектов обучающей выборки, а $X_m$ — множество объектов, попавших в текущий лист (в самом начале они равны). Тогда:

1. Создаём вершину $v$.
2. Если выполнен критерий $*\color{#ff5050} Stop(X_m)*$, то останавливаемся, объявляем эту вершину листом и ставим ей в соответствие ответ $\color{#a6ff4d} Ans(X_m)$, после чего возвращаем её.
3. Иначе: находим предикат (иногда ещё говорят *сплит*), который определит наилучшее разбиение текущего множества объектов $X_m$ на две подвыборки $X_l$ и $X_r$, максимизируя *критерий ветвления* $\color{#6699ff} Branch(X_m, feature, value)$.

Подбор оптимального сплита базируется на понятии загрязненности (impurity). Это вероятность того, что случайно выбранный экземпляр будет классифицирован ошибочно. Это значение мы хотим минимизировать.

В качестве $\color{#6699ff} критериев \ ветвления$ (метрик загрязненности) могут выступать следующие метрики:

**Для регрессии:**

- **MSE** $= {H(X_m) = \sum\limits_{(x_i, y_i) \in X_m}\frac{\left(y_i - \overline{y} \right)^2}{|X_m|}, ~ \text{где} ~ \overline{y} = \frac{1}{\vert X_m \vert} \sum_i y_i}$

Для минимизации загрязненности, минимизируем среднеквадратичную ошибку.

Для этого оцениваем дисперсии таргетов для объектов, попавших в лист. Оценка значения в каждом листе — это среднее, а выбирать сплиты надо так, чтобы сумма дисперсий в листьях была как можно меньше.

- **MAE $= H(X_m) = \sum\limits_{(x_i, y_i) \in X_m}\frac{|y_i - MEDIAN(Y)|}{|X_m|}$**

Для минимизации загрязненности, минимизируем среднюю абсолютную ошибку.

Для этого минимизируем абсолютное отклонение от медианы.

**Для классификации:**

- **Misclassification Error** $= H(X_m) = 1 - p_{k_{\ast}}$
- **Энтропия** $= {H(X_m) = -\sum_{k = 1}^K p_k \log p_k}$
- **Индекс Джини** $= {H(X_m) = \sum_{k = 1}^K p_k (1 - p_k)}$

где $p_k$ - доля объектов класса k в текущей вершине.

```python
# Классификация:

dtc = sklearn.tree.DecisionTreeClassifier(
# критерий: {“gini”, “entropy”, “log_loss”}
criterion = 'gini', 
# максимальная глубина дерева
max_depth = 5,
# минимальное число элементов в узле
min_samples_split = 5,
# минимальное число элементов в листе
min_samples_leaf = 5,
# веса для классов
class_weight = None
)
```

```python
# Регрессия:

dtr = sklearn.tree.DecisionTreeRegressor(
# критерий {“squared_error”, “friedman_mse”, “absolute_error”, “poisson”}
criterion = 'squared_error',
# максимальная глубина дерева
max_depth = 5,
# минимальное число элементов в узле
min_samples_split = 5,
# Минимальная взвешенная доля от общей суммы весов, 
# которая должна находиться в конечном узле
min_weight_fraction = 0
)
```

```python
# отрисовка дерева в виде изображения

dtc = dtc.fit(x_train, y_train)
plt.figure(figsize = (20,15)) 
sklearn.tree.plot_tree(dtc)
plt.show()
```

```python
# важность признаков для модели

print(dtc.feature_importances_)
```

## Ансамбли

Идея этого подхода базируется на стремлении получить более точные предсказания, используя не одну слабую модель, а сразу много. Тогда их усредненный результат будет значительно более приближен к реальности, чем результат каждой модели по-отдельности.  

Существует несколько способов реализации этого подхода:

- Стекинг
- Бэггинг
- Бустинг

### Бэггинг (bootstrap aggregation)

Стандартный алгоритм бэггинга таков:

- Имеем выборку из N объектов.
- Возьмем из нее новую выборку размера N при помощи бутстрепирования, то есть с возвращением. Какие-то объекты из изначальной выборки не попадут в новую, а какие-то попадут в нее несколько раз.
- Обучим на получившейся выборке какую-то модель и повторим процедуру.
- После k итераций у нас будет k базовых моделей, обученных на k разных выборок.
- Итоговое предсказание же будет делать ансамбль этих моделей, то есть модель, которая будет выносить решение основываясь на усредненном показателей базовых моделей.

$$
 \color{pink}a(x)  \color{white}=\frac{1}{k}\color {brown}(b_1(x) + \dots + b_k(x)).
$$

Такой подход позволяет очень сильно уменьшить дисперсию предсказания моделей, то есть Variance, при условии, что базовые модели не скоррелированы. 

### Случайный лес

Немного отличающаяся версия бэггинга для решающих деревьев называется случайный лес.

Алгоритм построения такой модели таков:

- Имеем выборку из N объектов.
- Возьмем из нее новую выборку размера n при помощи бутстрепирования, то есть с возвращением. Какие-то объекты из изначальной выборки не попадут в новую, а какие-то попадут в нее несколько раз.
- Выберем случайное число признаков и обучим очередное дерево только на них. Такой подход позволяет управлять скоррелированностью базовых алгоритмов.
- Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев (для регрессии) или берём самый популярный класс (для классификации).

```python
rfc = sklearn.ensemble.RandomForestClassifier(
# число деревьев в лесу (можно сделать больше, а потом уменьшать)
n_estimators=100, 
# критерий {“gini”, “entropy”, “log_loss”}
criterion='gini', 
# максимальная глубина дерева
max_depth=5, 
# минимальное число элементов в узле
min_samples_split = 5,
# минимальное число элементов в листе
min_samples_leaf = 5,
# вычисление out-of-bag ошибки,
# альтернатива кросс-валидации для мелких выборок
oob_score=False, 
# позволяет наращивать выборку новыми деревьями
warm_start=False, 
# веса для классов
class_weight=None,
# ограничение на количество признаков, доступных каждому дереву
# {“sqrt”, “log2”, None, int}
max_features = 'sqrt')
```

```python
rfr = sklearn.ensemble.RandomForestRegressor(
# число деревьев в лесу (можно сделать больше, а потом уменьшать)
n_estimators=100, 
# критерий {“squared_error”, “friedman_mse”, “absolute_error”, “poisson”}
criterion='squared_error', 
# максимальная глубина дерева
max_depth=None, 
# минимальное число элементов в узле
min_samples_split = 5,
# минимальное число элементов в листе
min_samples_leaf = 5,
# альтернатива кросс-валидации для мелких выборок
oob_score=False, 
# позволяет наращивать выборку новыми деревьями
warm_start=False,
# Минимальная взвешенная доля от общей суммы весов, 
# которая должна находиться в конечном узле
min_weight_fraction_leaf=0.0,
# ограничение на количество признаков, доступных каждому дереву
# {“sqrt”, “log2”, None, int}
max_features = 'sqrt'
```

При помощи случайного леса можно также проверять важность признаков. Для этого можно брать признаки, по очереди перемешивать их внутри своего столбца и смотреть, улучшилось качество модели или нет. Признаки, показывающие наиболее серьезное ухудшение метрик, наиболее релевантны. 

$\sum_{ij} w_{ij}^2$

$\sum_{ij} |w_{ij}|$
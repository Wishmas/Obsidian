# Docker

# Введение

Docker — это платформа, которая предназначена для разработки, развёртывания и запуска приложений в контейнерах.

Это ПО, которое позволяет обернуть программу вместе со всеми имеющимися в ней зависимостями в некий самодостаточный контейнер, который изолирован от других программ.

Его основные сильные стороны - это:

- Разрешение зависимостей
- Изолированность
- Стандартизация
- Воспроизводимость
- Откат
- Масштабирование

## Установка Докера на windows

https://lab.karpov.courses/learning/102/module/1276/lesson/12125/35054/170856/
## Основные сущности

Демон (daemon) - фоновая программа, которая управляет всеми объектами докера.

Образ (image) - инструкция, определяющая, каким должен быть контейнер.

Репозиторий (registry) - сервер, где хранятся готовые образы.

Контейнер (container) - изолированная среда запуска приложений

Клиент (client) - пользовательский интерфейс взаимодействия с докером

Хост (host) - компьютер, на котором установлен докер

![Untitled](Разработка/Docker/Вложения/Docker/Untitled.png)

### Образы и контейнеры

Чтобы получить образ, на основе которого будут создаваться контейнеры, можно воспользоваться одним из следующих способов:

1. Скачать образ из репозитория (н-р: Docker Hub):

```bash
$ docker pull <образ>
```

![Untitled](752bc7c7-aa3b-4671-bfce-c2ebae6c40c0.png)

В репозиториях образы одних и тех же вещей могут иметь разные теги в зависимости от наполнения. По умолчанию скачивается тег latest, однако руками можно указать и какой-то другой.

1. Создать свой образ через Dockerfile;
2. Создать образ на основе существующего контейнера:

```bash
$ docker commit <контейнер>
```

Чтобы посмотреть список имеющихся образов, можно использовать команду:

```bash
$ docker images
```

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%201.png)

Чтобы удалить образ, можно использовать команду:

```bash
$ docker rmi <образ>
```

!Важно: образы имеют вес, то есть физически занимают место на компьютере. За этим нужно следить и удалять лишнее.

Чтобы создать контейнер из образа и запустить его, нужно использовать команду:

```bash
$ docker run <образ>

$ docker run --name <имя> <образ> # присваиивает имя контейнеру при создании
$ docker run --rm <образ> # удаляет контейнер после завершения его работы
$ docker run -d <образ> # запускает контейнер в фоновом режиме
```

Можно также вызвать эту команду с флагом -it, чтобы оказаться внутри контейнера:

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%202.png)

В таком случае, контейнер будет поддерживаться в работающем состоянии, пока мы не выйдем из него командой Ctrl-D.

При этом, жизненный цикл контейнера может выглядеть по-разному:

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%203.png)

Контейнер работает до тех пор, пока работает программа внутри него. 

Чтобы посмотреть список имеющихся контейнеров, можно использовать команду:

```bash
$ docker ps --all # все имеющиеся контейнеры
$ docker ps # все запущенные контейнеры
$ docker ps -q # только айдишники контейнеров
```

Чтобы остановить работающий контейнер, можно использовать команду:

```bash
$ docker stop <контейнер>
```

Чтобы поднять остановленный контейнер, можно использовать команду:

```bash
$ docker start <контейнер>
```

Чтобы удалить созданный контейнер, можно использовать команду:

```bash
$ docker rm <контейнер>
```

В качестве аргумента для таких команд можно передавать или имя, или айдишник. Причем можно передавать сразу несколько параметром через пробел.

Можно также использовать удобный инструмент bash:

```bash
$ <команда_1> $(<команда_2>) 
```

Она выполняет команду в скобках (команда_2), а затем передает ее результат в команду перед ней (команда_1). При помощи этого можно, например, получать айдишники контейнеров, а затем удалять или останавливать их все одновременно.

Чтобы зайти внутрь работающего контейнера, можно использовать команду:

```bash
$ docker exec -it <контейнер> bash
```

Находясь внутри контейнера, можно производить любые обычные манипуляции с командной строкой, менять файлы, добавлять их и т.д.

### Dockerfile

В большинстве случаев, готовых образов из репозитория недостаточно. Мы хотим, чтобы в контейнерах реализовывалась какая-то дополнительная логика: запускались скрипты, поднимались приложения и т.д.

Чтобы добиться этого, нужно взять за основу готовый образ и на его основе, взаимодействуя с файлом Dockerfile и вручную создавать нужный нам образ.

Все образы состоят из слоев. Каждая инструкция в Dockerfile создает новый слой. 

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%204.png)

При помощи команд внутри Dockerfile, мы можем копировать скрипты и файлы, устанавливать и обновлять библиотеки и зависимости и делать много чего еще.

Докер умеет кешировать слои и забирать их оттуда, если новый образ использует те же слои, что и какой-то из предыдущих.

Чтобы не потерять какую-то логику из-за этой особенности, нужно грамотно формировать инструкции.

Начинается Dockerfile с оператора FROM, которая определяет, какой образ берется за основу.

```docker
FROM <образ>
```

Чтобы указать, в какую рабочую директорию следует переместиться при выполнении инструкций, используется оператор:

```docker
WORKDIR <путь>
```

Чтобы скопировать в Dockerfile содержимое какого-то другого файла, например, скрипта, можно использовать оператор:

```docker
COPY <путь на компьютере> <путь в контейнере>
# или
ADD <путь на компьютере> <путь в контейнере>
```

При использовании ADD можно распаковывать архивы и скачивать файлы по ссылке. В остальном, их функционал схож.

Чтобы запустить произвольный скрипт или применить операции командной строки, можно использовать оператор:

```docker
RUN <команда>
```

Чтобы задать команду, которая должна запуститься при поднятии контейнера, можно использовать команду:

```docker
CMD ["<команда>"]
# или
ENTRYPOINT ["<команда>"]
```

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%205.png)

Чтобы собрать новый образ из готового Dockerfile используют команду:

```bash
$ docker build -t <имя нового образа> <путь к папке с Dockerfile>
```

Если у вас есть аккаунт на DockerHub, готовый образ можно запушить туда. Для этого, нужно создать там репозиторий:

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%206.png)

После этого, нужно залогиниться локально командой:

```bash
$ docker login
```

Затем нужно использовать команду tag, чтобы переименовать образ на устройстве так же, как называется репозиторий:

```bash
$ docker tag <имя образа> <имя репозитория>
```

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%207.png)

Затем можно запушить образ командой:

```bash
$ docker push <имя репозитория>
```

### Связь контейнера и хоста

По умолчанию, файлы, которые были скопированы в контейнер при его создании, становятся независимы от изначальных файлов на хосте. Кроме того, если контейнер падает, файлы и данные из него оказываются утеряны, что не позволяет, к примеру, полноценно работать с базами данных.

Чтобы решить эту проблему, используются функционал BIND MOUNT и VOLUME, который позволяет связать файловую систему контейнера с файловой системой компьютера.

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%208.png)

Отличие между ними заключается в том, что BIND MOUNT позволяет выбирать для связи любую папку, полностью указывая путь до нее, а VOLUME связывается с конкретной папкой volumes. 

### Вольюмы

Чтобы посмотреть, какие вольюмы созданы на устройстве, можно использовать команду:

```bash
$ docker volume ls
```

Чтобы удалить вольюм, можно использовать команду:

```bash
$ docker volume rm <имя вольюма>
```

Чтобы удалить все неиспользуемые контейнерами вольюмы, можно использовать команду:

```bash
$ docker volume prune
```

Чтобы посмотреть подробную информацию про конкретный вольюм, можно использовать команду:

```bash
$ docker volume inspect <имя вольюма>
```

Чтобы создать новый вольюм, можно использовать команду:

```bash
$ docker volume create <имя вольюма>
```

Чтобы создать контейнер с привязкой к какому-то вольюму, нужно использовать команду:

```bash
$ docker run -v <имя вольюма>:<путь в контейнере> <образ>
```

Также можно в любой момент скопировать файл с хоста в запущенный контейнер. Для этого можно использовать команду:

```bash
$ docker cp <путь на хосте> <имя контейнера>:<путь в контейнере>
```

Аналогично, можно скопировать файл из контейнера на хост:

```bash
$ docker cp <имя контейнера>:<путь в контейнере> <путь на хосте>
```

### Bind Mount

Байнд-маунт связывает файлы или папки на компьютере и в контейнере и синхронизирует изменения в них.

Чтобы создать контейнер с такой привязкой, нужно использовать команду:

```bash
$ docker run -v <полный_путь_на_хосте>:<полный_путь_в_контейнере> <образ>
```

Чтобы случайно не потерять какие-то важные папки или файлы, можно добавить в конце приписку :ro (read only).

Через Байнд-маунт можно также прокинуть сокет докера, в результате чего мы получим доступ к демону внутри контейнера. 

Для этого нужно создать образ самого докера и правильно настроить параметр -v:

```bash
$ docker run -it --rm -v /var/run/docker.sock:/var/run/docker.sock docker
```

### Переменные окружения

Это значения, которые используются в различных командах и программных сценариях, выполняемых в операционной системе. 

Принципиально они работают точно так же, как переменные в языках программирования. Они представляют знакомые нам пары «ключ-значение» и используются для хранения параметров, настроек приложений, хранения ключей и других информационных данных.

Чтобы напрямую задать какую-то переменную окружения в Dockerfile, можно использовать оператор ENV:

```docker
ENV a = "value"
```

Однако такой способ не подходит для того, чтобы передавать секретные ключи, токены и пароли.

Чтобы использовать переменные окружения для этой цели, можно пробрасывать переменные окружения при поднятии контейнера, используя флаг -e:

```docker
$ docker run -e <имя_переменной>=<значение переменной> <образ>
```

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%209.png)

Чтобы передать сразу несколько скрытых переменных, можно записать их в файл .env, а затем указать при запуске параметр:

```docker
$ docker run --env-file <путь к файлу .env> <образ>
```

При помощи python можно доставать такие переменные окружения, используя библиотеку os:

```python
os.environ.get("TOKEN")
```

### Логи

Писать логи программы, которая работает в контейнере можно двумя основными способами:

1. Писать логи напрямую в файл или использовать библиотеку, которая пишет логи в какой-то файл, а потом использовать Байнд-маунт или вольюм, чтобы дублировать этот файл на хосте.
2. Писать логи в консоль (print), а потом использовать команды:

```python
$ docker logs <контейнер>
```

Команда выводит логи контейнера в терминал и позволяет там же их отсматривать.

Можно запустить эту команду с флагом -f, чтобы продолжать смотреть логи в прямом эфире, а также с флагом -t, чтобы иметь временные метки логов.

Такие логи тоже хранятся на хосте. Чтобы посмотреть их напрямую, можно найти нужный файл командой:

```bash
$ docker inspect --format "{{.LogPath}}" <контейнер>
```

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2010.png)

используя операторы >,>>,2>,2>> мы можем сохранить все наши логи в файлики, а затем смотреть на них (например обработать их при помощи кода):

- `>` — запись stdout в файл
- `>>` — дозапись stdout в файл
- `2>` — запись stderr в файл
- `2>>` — дозапись stderr в файл

### Порты

Порт – это виртуальное "окно" на устройстве, через которое проходят данные для определённого приложения или службы. Каждый порт имеет свой уникальный номер, функционируя как адрес для различных сетевых процессов. Благодаря портам одновременные сетевые соединения на устройстве упорядочены и целенаправлены.

Иными словами:

Порт - это условный номер программы, которой на этом конкретном компьютере шлется запрос, т.е. которая его обработает.

В частности, порт нужен, чтобы подключиться к веб-серверу или к базе данных и осуществлять с ней какие-либо манипуляции. Однако, если мы поднимаем базу данных в контейнере, подключиться к ней по порту нельзя из-за особенностей изоляции.

Чтобы связать порт на хосте с портом в контейнере, его нужно пробросить напрямую:

```bash
$ docker run -p <порт на хосте>:<порт в контейнере> <образ>
```

В опции -p можно указать не только порт:

```bash
$ docker run -p <IP_адрес_на_компьютере>:<порт_на_компьютере>:<порт_в_контейнере> <образ>
```

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2011.png)

У тех контейнеров, которые используют порты, нужный порт указан в колонке PORTS:

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2012.png)

Можно также связать несколько портов на хосте с одним портом в контейнере:

```bash
$ docker run -p <порт на хосте>:<порт в контейнере> \\
-p <порт на хосте>:<порт в контейнере> \\
-p <порт на хосте>:<порт в контейнере> <образ>
```

Явным образом порт задается в Dockerfile оператором EXPOSE <порт>. Такая запись не связывает контейнеры, а служит подсказкой тому, кто запускает контейнер.

Если инструкция EXPOSE прописана не была, а узнать, какой порт слушает приложение в контейнере нужно, можно зайти внутрь контейнера и использовать команду:

```bash
$ ss -tuln
```

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2013.png)

Если при создании контейнера с БД был успешно проброшен порт, к ней можно подключиться при помощи python или DBeaver и успешно работать через графический интерфейс. 

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2014.png)

### Сети

Порты позволяют взаимодействовать с контейнером из внешнего мира, однако не дают контейнерам возможности взаимодействовать между собой. 

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2015.png)

Чтобы решить эту проблему, нужно сделать так, чтобы контейнеры находились в одной подсети. В таком случае, достучаться до контейнеров можно будет при помощи их IP-адреса.

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2016.png)

В Docker существуют три основных типа сетей: bridge, host и none. У каждой из них свои особенности и сценарии использования.

1. Bridge:
    - Это тип сети по умолчанию для новых контейнеров. Bridge-сеть создает виртуальный мост, который позволяет контейнерам на одном хосте общаться друг с другом.
    - Особенности:
        - Каждый контейнер получает собственный IP-адрес.
        - Контейнеры могут обмениваться данными друг с другом, используя эти IP-адреса.
        - Контейнеры на разных хостах не могут напрямую общаться через bridge-сеть.
        - Можно настраивать правила доступа и маршрутизации.
2. Host:
    - Контейнер использует сетевой стек хоста. В этом случае контейнер не получает отдельный сетевой интерфейс.
    - Особенности:
        - Контейнеры разделяют IP-адрес и порты хоста.
        - Более высокая производительность за счет устранения слоя виртуализации.
        - Подходит для случаев, когда нужно минимизировать накладные расходы на сетевое взаимодействие и когда контейнер должен иметь доступ к сетевым интерфейсам хоста.
3. None:
    - Контейнер не подключается ни к какой сети. У него есть только интерфейс loopback.
    - Особенности:
        - Полное отсутствие сетевого взаимодействия.
        - Подходит для изолированных задач, не требующих сетевого доступа.

По умолчанию, все контейнеры попадают в сеть Bridge, однако мы можем менять сети по своему усмотрению, чтобы корректно выстраивать изоляцию контейнеров друг от друга.

Чтобы посмотреть список существующих сетей, можно использовать команду:

```bash
$ docker network ls
```

Чтобы создать новую кастомную сеть, можно использовать команду:

```bash
$ docker network create <имя сети>
```

Чтобы удалить созданную сеть, можно использовать команду:

```bash
$ docker network rm <имя сети>
```

Чтобы посмотреть подробную информацию о сети, включая subnet и gateway, можно использовать команду:

```bash
$ docker inspect <имя сети>
```

 Чтобы подключить контейнер к конкретной сети, нужно запустить его с флагом:

```bash
$ docker run --net=<имя сети> <образ>
```

Чтобы подключить к сети контейнер, который уже поднят в другой сети, нужно использовать команду:

```bash
$ docker network connect <имя сети> <имя контейнера>
```

Можно поднять два контейнера на одинаковом порту, если указать разные IP адреса.

Чтобы посмотреть имеющиеся сетевые интерфейсы, можно воспользоваться командой ifconfig:

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2017.png)

!Важно: если контейнеру было задано имя, это имя можно использовать вместо IP-адреса в запросах между контейнерами, что позволяет настраивать взаимосвязь между ними. 

К примеру, чтобы контейнер с ботом увидел контейнер с базой и начал с ней взаимодействовать, ему в качестве хоста нужно передать имя контейнера с базой или его IP.

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2018.png)

Пример:

1. Поднимаем контейнер с базой:

```bash
$ docker run --name test_postgre \
-e POSTGRES_PASSWORD=password \
-e POSTGRES_USER=user \
-e POSTGRES_DB=db_name \
--net=net_name -d postgres
```

1. Поднимаем контейнер с приложением:

```bash
$ docker run --name app \
-e PG_HOST=test_postgre \
-e PG_PASSWORD=password \
-e PG_USER=user \
-e PG_DATABASE=db_name \
--net=net_name -d kcoursedocker/task-6.4
```

1. В самом приложении читаем переменные окружения через:

```python
connection = Client(
    host=os.environ.get("PG_HOST"),
    user=os.environ.get("PG_USER"),
    password=os.environ.get("PG_PASSWORD"),
    port=5432,
    database=os.environ.get("PG_DATABASE"),
)
```

### Multi-stage build

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2019.png)

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2020.png)

Dockerfile может содержать несколько операторов FROM, то есть собираться в несколько этапов. На каждом из этих этапов могут оставаться некоторые артефакты, то есть файлы, генерируемые в процессе исполнения команд. 

Эти файлы можно выборочно копировать на последующих этапах, оставляя в финальной сборке только нужное. Такой поход позволяет экономить место и делать образы более легковесными.

[Multi-stage builds](https://docs.docker.com/build/building/multi-stage/)

Если нужно остановить сборку на каком-то этапе для целей отладки, можно использовать опцию `--target` при выполнении команды `docker build`:

```bash

$ docker build --target <Имя этапа (н-р build)> -t \
<имя нового образа> <путь к папке с Dockerfile>

```

## Docker-compose

Это инструмент для запуска и управления многоконтейнерными приложениями в Docker.

В специальном файле формата .yaml описываются инструкции того, какие контейнеры должно включать приложение, и какими характеристиками они должны обладать.

Затем все приложение запускается одной командой.

### YAML-файлы

Это формат сериализации данных, который удобен для чтения и записи человеком. Его идея заключатся в том, чтобы на основании отступов строить сложные вложенные структуры, основанные на парах ключ - значение.

Пример YAML-файла:

```yaml
server:
  host: localhost
  port: 8080

database:
  type: postgres
  host: localhost
  port: 5432
  username: user
  password: pass

features:
  - auth
  - payments
  - notifications
```

Это соответствует такой структуре данных в python:

```python
{
    'server': {
        'host': 'localhost',
        'port': 8080
    },
    'database': {
        'type': 'postgres',
        'host': 'localhost',
        'port': 5432,
        'username': 'user',
        'password': 'pass'
    },
    'features': [
        'auth',
        'payments',
        'notifications'
    ]
}
```

YAML поддерживает массивы, списки, словари, строки, числа, булевы значения и другие типы данных. В него также можно добавлять комментарии с помощью символа `#`.
Можно также создавать якоря и ссылки на них для повторяющихся значений:

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2021.png)

Пример yaml-файла для конфигурации Airflow:

[docker-compose.yaml](docker-compose.yaml)

## Команды Docker-compose

Чтобы работать с командами docker-compose, нужно находиться в папке, где лежит файл docker-compose.yaml

Чтобы исполнить инструкции в этом файле и поднять все нужные контейнеры, используется команда:

```bash
$ docker-compose up -d
```

Чтобы остановить и удалить все задействованные в инструкции контейнеры, используется команда:

```bash
$ docker-compose down
```

Другие команды docker-compose:

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2022.png)

Основные блоки Yaml-файла:

- version - версия
- services - контейнеры
- volumes - вольюмы
- networks - сети

Внутри блока services можно задавать те же параметры, которые задаются при ручном поднятии контейнера:

build ( = docker build <файл>)

image ( = docker run <образ>)

container_name ( = docker run - - name <имя>)

volumes ( = docker run -v <путь на хосте> : <путь в контейнере>)

environment ( = docker run -e <переменная> = <значение>)

networks ( = docker run - - net = <сеть>)

ports ( = docker run -p <порт на хосте> : <порт в контейнере> )

![Untitled](Разработка/Docker/Вложения/Docker/Untitled%2023.png)

Также для конкретного контейнера можно задать дополнительные инструкции, например:

- restart и restart_policy - инструкции по перезапуску упавшего контейнера
- replicates - количество экземпляров контейнера, которые нужно поднять
- depends_on - зависимость одного контейнера от других
- healthcheck - проверка, выполняемая после запуска контейнера
- И т.д.

## Доставка на сервер

Наиболее простым вариантом разворачивания docker-приложения на сервере может быть локальная сборка всех нужных образов, отправка их на docker-hub через docker push, а затем получение их на сервере через docker pull и разворачивание контейнеров.

Для более сложных задач можно использовать дополнительные инструменты, например Ansible. Это система управления конфигурациями, которая применяется для автоматизации настройки и развёртывания программного обеспечения

Ansible позволыет локально прописать инструкции того, что необходимо сделать на сервере в YAML-файле, а затем исполнить ти инструкции.

## Коротко о Kubernetes (k8s)

Это платформа для оркетсрации контейнеризированных приложений.

![Untitled](Разработка/Docker/Untitled%2024.png)

Kubernetes имеет доступ к разным серверам (нодам). Существует два типа нод:

- Master-node
- Worker-node

Мастер-ноды управляют воркер-нодам. На воркер-нодах находятся Поды (pod) - наименьшие единицы развертывания. Именно на них работат контейнеры.

Точкой входа для пользователя является Сервис (service).  Он определяет, на какой под нужно отправить пользователя, и выступает в качестве балансировщика нагрузок. 

Мастер-нода нужна для управления кластером: с помощью нее можно задать инструкции о том, сколько нужно подов, контейнеров и т.д.

![Untitled](Разработка/Docker/Untitled%2025.png)

### Основные сущности Kubernetes:

- Namespaces
- Pod - минимальная единица
- ReplicaSet - абстракция над подами
- Deployment - абстракция над ReplicaSet
- Services
- ConfigMaps
- Ingress
- Secrets
- Job
- CronJob
- PersistentVolumes

Deployment позволяет более гибко настраиваиь поведение подов. Например, можно куказать, как именно должно происходить обновление. 

![Untitled](Разработка/Docker/Untitled%2026.png)
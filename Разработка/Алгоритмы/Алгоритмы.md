# Алгоритмы

## Идея сложности алгоритма

**Алгоритм** — это набор четко сформулированных правил для решения некоторой вычислительной задачи.

**Сложность алгоритма** — порядок количества действий, которые выполняет алгоритм.

**Асимптотический анализ** представляет из себя смещение в сторону больших входных данных.

**«Быстрый алгоритм»** — это алгоритм, время работы которого в худшем случае растет медленно, в зависимости от роста размера входных данных.

![Untitled](Разработка/Алгоритмы/Untitled.png)

![Untitled](Разработка/Алгоритмы/Untitled%201.png)

**Основные правила:**

- Постоянные множители можно опускать
- Медленнее растущие слагаемые можно опускать
- Многочлен более высокой степени растет быстрее, чем многочлен более низкой
- Экспонента растет быстрее многочлена
- Многочлен растет быстрее логарифма

### **Пример с числами Фибоначчи**

```python
def fib(n):
	a,b = 0,1
	for i in range(n-1):
		a,b = b,a+b
	return 0 if n==0 else b
```

*Этот алгоритм средне эффективен и работает за ~О(n^2).*

```python
def fib(n):
    if n <= 1:
        return n
    else:
        return fib(n-1) + fib(n-2)
```

*Этот алгоритм не эффективен и растет экспоненциально.*

! Факт: последняя цифра n-го числа Фибоначчи равна (fib(n-1)[-1] + fib(n-2)[-1]) mod 10

### **Пример с НОД**

```python
def gcd(a, b):
    if a == 0:
        return b
    elif b == 0:
        return a
    elif a >= b:
        return gcd(a%b,b)
    elif b >= a:
        return gcd(a,b%a)
```

Это алгоритм Евклида, который основан на Лемме:

![Untitled](Разработка/Алгоритмы/Untitled%202.png)

Он работает за ~ log(a) + log(b), что гораздо эффективнее прямого перебора.

Его можно переписать следующим образом:

```python
def gcd(a,b):
	if a==0 or b==0:
		return max(a,b)
	else:
		return gcd(b%a,a)
```

## Жадные алгоритмы

**Идея:** итеративно конструировать решение посредством последовательности близоруких решений и надеяться, что в конце концов все получится.

**Особенности и недостатки:**

1. Легко придумать один или несколько жадных алгоритмов.
2. Легко проанализировать время выполнения алгоритма.
3. Трудно установить правильность алгоритма.

**Ход решения:**

1. Находим надежный шаг: действие, для которого мы уверены, что существует оптимальное решение, согласованное с ним.
2. Делаем надежный шаг и переходим от изначальной задачи к тому, что осталось после надежного шага.
3. Эта задача имеет тот же тип, поэтому надежные шаги можно повторять, пока решение не будет найдено.

### **Пример отрезками и точками**

“Дано множество из n точек на прямой. Нужно найти минимальное количество отрезков единичной длины, которыми можно покрыть все эти точки.

**Идея:** 

- Существует оптимальное решение, в котором самая левая точка покрыта самым левым концом отрезка.
- Будем добавлять в решение такой отрезок, убирать все точки, которые он покрыл, а потом повторять.

![Untitled](Разработка/Алгоритмы/Untitled%203.png)

```python
def point_cover(line):
    line.sort()
    i = 0
    cnt = 0
    while i <= len(line)-1:
        r = line[i] + 1 
        i += 1
        cnt += 1
        while i <= len(line)-1 and line[i] <= r:
            i += 1
    return cnt
```

*Этот алгоритм эффективен и его сложность равна сложности используемой в нем сортировки, то есть ~n log(n).*

### **Пример бронированием переговорки**

“Дается несколько временных отрезков. Нужно выбрать как можно больше отрезков таким образом, чтобы ни один из них не пересекался с другим (отрезки пересекаются, если у них есть общая точка).”

**Идея:**

- Существует оптимальное решение, содержащее отрезок, правый конец которого минимален.
- Отсортируем отрезки по правому концу. Добавим самый первый и уберем те отрезки, которые он пересекает.
- Возьмем следующий подходящий и будем повторять, пока отрезки не закончатся.

![Untitled](Разработка/Алгоритмы/Untitled%204.png)

![Untitled](Разработка/Алгоритмы/Untitled%205.png)

```python
def booking(box):
    box.sort(key = lambda x: x[1])
    ans = [box[0]]
    for i in range(1,len(box)):
        if box[i][0] > ans[-1][1]:
            ans.append(box[i])
    return ans
```

*Этот алгоритм эффективен и его сложность равна сложности используемой в нем сортировки, то есть ~n log(n).*

### **Пример с непрерывным рюкзаком**

“Вор забрался в магазин с рюкзаком вместительности total. На полках в магазине стоят предметы, у каждого из которых есть вес w(i) и стоимость c(i). Вор хочет забрать предметов на максимальную суммарную стоимость, которые могут поместиться в его рюкзак. При этом он может отрезать от любого предмета часть, так что его вес и стоимость изменятся пропорционально.”

**Идея:**

- Существует оптимальное решение, содержащее максимально возможную часть предмета, стоимость которого за килограмм максимальна.
- Рассчитаем для каждого предмета цену за килограмм и отсортируем их по возрастанию этого показателя.
- Для каждого предмета будем брать максимум и переходить к следующему, пока рюкзак не заполнится.

```python
n, total = list(map(int,input().split()))
box = []
for i in range(n):
    c,w = list(map(int,input().split()))
    prop = c/w
    box.append((c,w,prop))

---

def fill_pack(box,total):
    box.sort(key = lambda x: x[2],reverse=True)
    cnt = 0
    gain = 0
    i = 0
    while i <= len(box)-1 and gain < total:
        if box[i][1] <= (total-gain):
            gain += box[i][1]
            cnt += box[i][0]
            i += 1
        else:
            cnt += (total-gain)*box[i][2]
            gain += (total - gain)
            i += 1
    return f'{cnt:.3f}'
```

*Этот алгоритм эффективен и его сложность равна сложности используемой в нем сортировки, то есть ~n log(n).*

### Пример с разбиением на различные слагаемые

“Дано натуральное число 1 ≤ n ≤ 10^9. Нужно найти максимальное число k, для которого n можно представить как сумму k разных натуральных слагаемых. Нужно вернуть число k и полученный набор слагаемых.”

**Идея:**

1. Последовательно берем натуральные числа, начиная с 1. Пока i меньше, чем половина от n, добавляем к ответу i и уменьшаем n на i.
2. Когда i переходит за половину от текущего n, добавляем к ответу n и выходим из цикла.

```python
def decay(n):
    ans = []
    i = 1
    while n > 0:
        if n > 2*i:
            ans.append(i)
            n = n - i
        else:
            ans.append(n)
            n = 0
        i += 1
    return(len(ans),ans)
```

### Коды Хаффмана

Это совокупность алгоритмов, предназначенных для двоичного кодирования некоторой последовательности символов. Они используются для сжатия файлов, например, в архивах.

**Коды фиксированной длины:** 

Самый простой вариант - присвоить каждому символу в алфавите код одинаковой длины.

**Например:**

a : 00, b : 01, c : 10, d : 11

**Строка:** abacabad

**Закодированная строка:** 0001001000010011

Однако этот вариант не очень эффективен, поскольку какие-то символы встречаются в тексте чаще, а другие - реже.

**Коды переменной длины:**

**Идея:**

1. Минимизировать количество используемых в закодированной последовательности битов, присвоив более частным символам более короткие коды.
2. Сделать код беспрефиксным, то есть убедиться в том, что никакой код символа не является префиксом другого кода. Это необходимо, чтобы закодированная последовательность расшифровывалась однозначно.

**Например:**

a : 0, b : 10, c : 110, d : 111

**Строка:** abacabad

**Закодированная строка:** 01001100100111 (на 2 бита эффективнее)

Если коды составлены правильно, то их можно представить в виде дерева:

a : 0, b : 10, c : 110, d : 111

![Untitled](Разработка/Алгоритмы/Untitled%206.png)

Тогда, читая закодированную последовательность, мы можем просто двигаться из корня дерева и, попадая в лист, записывать соответствующий ему символ.

Для каждого двоичного кода длина кодирования в битах символа а ∈ Σ равна глубине узла
с меткой a в соответствующем дереве, где Σ - данный алфавит.

Задача составления оптимального беспрефиксного кода:

Для составления оптимального беспрефиксного кода, нам необходимо минимизировать следующую функцию:

$$
L(T,p) = \sum_{a \in \Sigma} p(a) \times \text{глубина листа с пометкой } a \text{ в } T
$$

Бинарное дерево - дерево, в котором у каждой вершины либо 0, либо двое детей.

T - бинарное дерево, в котором листья помечены в однозначном соответствии с символами алфавита Σ.

p(a) - частота символа a, то есть количество раз, которое соответствующая a вершина будет посещена в процессе кодировки/декодировки.

Глубина листа - количество ребер от вершины до соответствующего листа.

L(T,p) - средняя длина кодирования кода, который соответствует T.

### Идея кучи (очереди с приоритетами)

Очередь с приоритетами - это структура данных, которая должна обладать следующими функциями:

![Untitled](Разработка/Алгоритмы/Untitled%207.png)

Куча позволяет реализовывать все операции очереди с приоритетами за логарифмическое время.

Кучу можно представить как бинарное дерево:

![Untitled](Разработка/Алгоритмы/Untitled%208.png)

**Свойства кучи:**

- Значение каждой вершины ≤ значениям ее детей (или наоборот)
- Все ряды кроме последнего всегда заполнены

**Реализация функций:**

1. Добавление: подвешиваем новый элемент в произвольное место снизу и просеиваем его вверх, пока не будут выполнены все свойства кучи.

```python
def heap_push(heap,x):
    heap.append(x)
    pos = len(heap) - 1
		# пока элемент меньше меньше родителя
    while pos > 0 and heap[pos] < heap[(pos-1)//2]:
				# меняем элемент и родителя местами 
        heap[pos], heap[(pos-1)//2] = heap[(pos-1)//2], heap[pos]
        pos = (pos-1)//2
```

1. Извлечение минимума: извлекаем корень дерева как минимум и ставим на его место любой из листов. Затем просеиваем его вниз, меняя местами с минимальным из сыновей, пока не будут выполнены все свойства кучи.

```python
def heap_pop(heap):
		# забираем минимум
    ans = heap[0]
    heap[0] = heap[-1]
    pos = 0
    while 2*pos + 1 < len(heap) - 1:
				# находим меньшего ребенка
        min_son_ind = 2*pos + 1 if heap[2*pos + 1] < heap[2*pos + 2] else 2*pos + 2
				# меняем элемент и меньшего ребенка местами, пока не выполнятся свойства
        if heap[pos] > heap[min_son_ind]:
            heap[pos], heap[min_son_ind] = heap[min_son_ind], heap[pos]
            pos = min_son_ind
        else:
            break
		# удаляем лишний элемент
    heap.pop()
    return ans
```

### Решение задачи оптимизации

**Идея:**

- По аналогии с тем, как листья дерева помечены входными частотами, будем считать частоты внутренних вершин дерева равными сумме частот их детей.
- Существует оптимальное решение, в котором двумя наименьшими частотами помечены листья на нижнем уровне.
- **Надежный шаг:** выбрать две минимальные частоты p(i), p(j). Сделать их детьми новой вершины с пометкой p(i) + p(j). Выкинуть частоты p(i), p(j) и добавить p(i) + p(j).
- Будем повторять этот процесс до тех пор, пока у нас не останется только одна частота, которая станет корнем для нашего дерева.

![Untitled](Разработка/Алгоритмы/Untitled%209.png)

![Untitled](Разработка/Алгоритмы/Untitled%2010.png)

![Untitled](Разработка/Алгоритмы/Untitled%2011.png)

![Untitled](Разработка/Алгоритмы/Untitled%2012.png)

### Пример оптимального кодирования строки

![Untitled](Разработка/Алгоритмы/Untitled%2013.png)

```python
line = input()
libr = {}
for l in line:
    if l not in libr:
        libr[l] = 0
    libr[l] += 1

# класс для реализации указателей на детей
class Node:
    def __init__(self,ch,p):
        self.ch = ch
        self.p = p
        self.left = None
        self.right = None

    def get_info(self):
        return (self.ch,self.p)

# добавление в кучу
def heap_push(heap,x):
    heap.append(x)
    pos = len(heap) - 1
    while pos > 0 and heap[pos].p < heap[(pos-1)//2].p:
        heap[pos], heap[(pos-1)//2] = heap[(pos-1)//2], heap[pos]
        pos = (pos-1)//2

# извлечение минимума из кучи
def heap_pop(heap):
    ans = heap[0]
    heap[0] = heap[-1]
    pos = 0
    while 2*pos + 1 < len(heap) - 1:
        min_son_ind = 2*pos + 1 if heap[2*pos + 1].p < heap[2*pos + 2].p else 2*pos + 2
        if heap[pos].p > heap[min_son_ind].p:
            heap[pos], heap[min_son_ind] = heap[min_son_ind], heap[pos]
            pos = min_son_ind
        else:
            break
    heap.pop()
    return ans

# составление оптимального дерева по Хаффману:
# в результате, остается только корень, у которого
# есть указатели на своих детей
def make_huff_tree(libr):
    heap = []
    for l in libr:
        heap_push(heap,Node(l,libr[l]))

    while len(heap) > 1:
        left = heap_pop(heap)
        right = heap_pop(heap)
        merged = Node(None, left.p + right.p)
        merged.left = left
        merged.right = right
        heap_push(heap,merged)
    return heap[0]

# рекурсивный проход по всем нодам, начиная с корня
# если мы попадаем в лист, то добавляем в словарь нужный код
def assign_codes(node,current_code,codes):
    if node is None:
        return

    if node.ch is not None:
        codes[node.ch] = current_code

    assign_codes(node.left, current_code + "0", codes)
    assign_codes(node.right, current_code + "1", codes)

# создание словаря с кодами 
def translate(libr):
    heap_root = make_huff_tree(libr)
    codes = {}
    if len(libr) > 1:
        assign_codes(heap_root, "", codes)
    else:
        assign_codes(heap_root, "0", codes)
    return codes

code_libr = translate(libr)
print(len(libr),len(''.join([code_libr[ch] for ch in line])))
for k,v in code_libr.items():
    print(f'{k}: {v}')
print(''.join([code_libr[ch] for ch in line]))
```

### Пример декодирования строки

![Untitled](Разработка/Алгоритмы/Untitled%2014.png)

```python
k,l = list(map(int,input().split()))
libr = {}
for l in range(k):
    k,v = list(map(str,input().split(':')))
    libr[v.strip()] = k.strip()
line = input()

def decode(line):
    cur_code = ''
    pos = 0
    ans = ''
    while pos < len(line):
        cur_code += line[pos]
        if cur_code in libr:
            ans += libr[cur_code]
            cur_code = ''
        pos += 1
    return ans

print(decode(line))
```

## Разделяй и властвуй

Это парадигма решения задач с использованием трех основных шагов:

1. Разделить входные данные на более мелкие подзадачи.
2. Решить подзадачи рекурсивным методом.
3. Объединить решения подзадач в решение исходной задачи.

### Пример с бинпоиском

Самым простым примером является двоичный поиск заданного ключа в отсортированном массиве.

![Untitled](Разработка/Алгоритмы/Untitled%2015.png)

**Левый бинпоиск:**

```python
def leftbin(l,r,check,checkparam):
    while l<r:
        m = (l+r)//2
        if check(m,checkparam):
            r = m
        else:
            l = m+1
    return l
```

**Правый бинпоиск:**

```python
def rightbin(l,r,check,checkparam):
    while l<r:
        m = (l+r+1)//2
        if check(m,checkparam):
            l = m
        else:
            r = m-1
    return l
```

**Пример:**

```python
box = [(2,'Коля'),(3,'Женя'),(3,'Веник'),(3,'Борис'),(7,'Маша'),(9,'Витя'),
       (9,'Некоглай'),(17,'Миша'),(19,'Дэн'),(31,'Пут'),(32,'Давг'),
       (40,'Гена'),(52,'Бояршинов'),(52,'Рыбников')]

def check(m,box,lim):
		box,lim = checkparam
    return box[m][0] <= lim

ans = rightbin(0,len(box),check,[box,30])
if ans < len(box):
    print(box[ans])
else:
    print(-1)

ans = leftbin(0,len(box),check,[box,30])
if ans < len(box):
    print(box[ans])
else:
    print(-1)

''' Результат: 
		
		-> (19, 'Дэн')
		-> (2, 'Коля')

'''
```

Время работы бинпоиска - O(log(n)).

Данный алгоритм относится к категории “Разделяй и властвуй”, поскольку мы каждый раз сужаем круг поиска и повторяем для него подзадачу:

![Untitled](Разработка/Алгоритмы/Untitled%2016.png)

Конкретно этот алгоритм реализован не рекурсивно, но его идею можно представить и в виде рекурсии.

### Пример с умножением чисел

Иногда, для того, чтобы перемножить два числа в двоичной записи, недостаточно просто использовать стандартную функцию умножения, ведь эти числа могут быть очень большими и не влезать в стандартные типы данных.

Для решения этой проблемы используют алгоритм Карацубы. Он базируется на идее, что число можно представить как сумму его половинок следующего вида:

![Untitled](Разработка/Алгоритмы/Untitled%2017.png)

Тогда:

![Untitled](Разработка/Алгоритмы/Untitled%2018.png)

Чтобы посчитать Xl, Yl, Xr, Yr для пары длинных чисел, нужно сделать 3 рекурсивных вызова для нахождения:

![Untitled](Разработка/Алгоритмы/Untitled%2019.png)

Поскольку:

![Untitled](Разработка/Алгоритмы/Untitled%2020.png)

Тогда алгоритм будет выглядеть так:

![Untitled](Разработка/Алгоритмы/Untitled%2021.png)

И будет иметь сложность ~О(N^1.6)

*См. также Алгоритм Штрассена для умножения матриц*

### Алгоритмы сортировки

Идея многих алгоритмов сортировки тоже подчиняется идее “Разделяй и властвуй”. 

Для начала приведем пример наивной сортировки, которая работает за О(N^2):  

```python
def insert_sort(line):
		# идем по массиву и для каждого числа, смотрим,
		# отсортирован ли массив от начала до него
    for i in range(2,len(line)):
        j = i
				# если нет, тогда сдвигаем число на нужную позицию
        while j > 0 and line[j] < line[j-1]:
            line[j], line[j - 1] = line[j-1], line[j]
            j -= 1
    return line
		# таким образом, мы на кажом шаге уверены,
		# что пройденная часть массива отсортирована
```

Далее рассмотрим несколько более эффективных подходов к сортировке: 

### MergeSort (сортировка слиянием)

**Идея:** рекурсивно делить массив пополам, пока не останется только по одному элементу в каждом результирующем массиве, а затем также рекурсивно сливать получившиеся массивы, на каждом шаге делая из двух отсортированных массивов один.

```python
def merge(a,b):
'''
осуществляет слияние двух отсортированных массивов в один:
пока оба массива не пройдены, добавляет в ответ меньший 
из первых элементов, потом добавляет оставшиеся элементы 
из второго массива:
'''
    pos_a = 0
    pos_b = 0
    ans = []
    while pos_a < len(a) and pos_b < len(b):
        if a[pos_a] < b[pos_b]:
            ans.append(a[pos_a])
            pos_a += 1
        else:
            ans.append(b[pos_b])
            pos_b += 1
    if pos_a >= len(a):
        ans += b[pos_b:]
    else:
        ans += a[pos_a:]
    return ans

def merge_sort(line):
'''
реализует саму сортировку:
'''
    if len(line) > 1:
        m = len(line)//2
        return merge(merge_sort(line[:m]),merge_sort(line[m:]))
    else:
        return line
```

Сложность этого алгоритма O(n log(n))

MergeSort можно также реализовать итеративно при помощи очереди:

![Untitled](Разработка/Алгоритмы/Untitled%2022.png)

Алгоритм оптимален по времени, но требует O(n) памяти, то есть не может отсортировать массив “на месте”. 

### Бонус: решение задачи на поиск числа инверсий:

![Untitled](Разработка/Алгоритмы/Untitled%2023.png)

```python
def merge_and_count(a,b):
    pos_a = 0
    pos_b = 0
    ans = []
    cnt_inv = 0
    len_a = len(a)
    while pos_a < len(a) and pos_b < len(b):
        if a[pos_a] <= b[pos_b]:
            ans.append(a[pos_a])
            pos_a += 1
        else:
            ans.append(b[pos_b])
            pos_b += 1
            cnt_inv += (len_a - pos_a)
    if pos_a >= len(a):
        ans += b[pos_b:]
    else:
        ans += a[pos_a:]
    return ans, cnt_inv

def sort_and_count(line):
    if len(line) > 1:
        m = len(line)//2
        a,left_cnt = sort_and_count(line[:m])
        b,right_cnt = sort_and_count(line[m:])
        c,split_cnt = merge_and_count(a,b)
        return c, left_cnt + right_cnt + split_cnt
    else:
        return line,0

l = list(map(int,input().split()))
line,cnt = sort_and_count(l)
print(cnt)
```

Идея  заключается в том, чтобы при слиянии каждый раз, когда элемент из правой половины массива добавляется в результирующий массив, увеличивать счетчик на число элементов, которые все еще остаются в левой половине массива. 

### Быстрая сортировка

Этот вид сортировки построен на принципе случайности, которая позволяет ему отрабатывать в среднем за O(n log(n)) вне зависимости от входных данных. Однако его случайная природа приводит к тому, что в худшем случае на любом массиве он может отработать за O(n^2).

```python
import numpy as np

def partition(line,l,r):
    rnd = np.random.randint(l, r)
    line[l], line[rnd] = line[rnd], line[l]
    x = line[l]
    j = l
    for i in range(l+1,r):
        if line[i] <= x:
            j += 1
            line[j],line[i] = line[i],line[j]
    line[l],line[j] = line[j],line[l]
    return j

def quick_sort(line,l,r):
    print(line)
    if l >= r:
        return
    m = partition(line,l,r)
    quick_sort(line, l, m)
    quick_sort(line, m+1, r)

ln = list(map(int,input().split()))
quick_sort(ln,0,len(ln))
print(ln)
```

**Идея:** мы случайным образом выбираем опорный элемент и двигаемся по массиву, делая так, чтобы левее опорного элемента в массиве оказались только элементы меньше него, а правее - больше. Затем мы рекурсивно повторяем то же самое для левой и правой части массива.